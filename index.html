<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="语料库、数据集及工具资源和教程">
<meta property="og:type" content="website">
<meta property="og:title" content="世界语言资源平台">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="世界语言资源平台">
<meta property="og:description" content="语料库、数据集及工具资源和教程">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="世界语言资源平台">
<meta name="twitter:description" content="语料库、数据集及工具资源和教程">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>世界语言资源平台</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">世界语言资源平台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/23/刘唯_中文句结构树资料库/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/23/刘唯_中文句结构树资料库/" itemprop="url">中文句结构树资料库</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-23T23:35:20+05:00">
                2018-04-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="链接：http-turing-iis-sinica-edu-tw-treesearch"><a href="#链接：http-turing-iis-sinica-edu-tw-treesearch" class="headerlink" title="链接：http://turing.iis.sinica.edu.tw/treesearch/"></a>链接：<a href="http://turing.iis.sinica.edu.tw/treesearch/" target="_blank" rel="noopener">http://turing.iis.sinica.edu.tw/treesearch/</a></h1><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>中文句结构树资料库检索工具 3.0 版，是由中文词识库小组（CKIP）设计完成，该系统是基于Internet的Web平台，使用者只要透过网际网路浏览器，即可操作本系统。该系统可以帮忙研究者，找到符合相关条件的中文剖析树，而进行研究。并以图文的方式让使用者可以清础地瞭解剖析树的内容。而不用去一个一个的找寻，大大地省去找寻的时间。本系统提供使用者对Sinica Treebank进行检索的动作，以阶层式查询来完成使用者的需求。透过相关查询的结果，使用者可以瞭解到中文句结构树中的词的语意角色与词组语法的标记方式。系统在主层检索中提供关键词查询与句型结构查询功能，对于查询后的结果可再依指定范围进行过滤与统计的动作。其范围包含同词组、同句子、左右距离与同关连关系的匹配词范围；统计包含有句型、词类、词、语意角色统计。</p>
<h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><p>进入中文剖析树检索系统后，本系统提供使用者可以「关键词」或「句型」的条件方式搜寻相关的中文剖析树，并对搜寻后的结果可以再次设定条件搜寻。因为，分为第一层搜寻与再过滤（即第Ｎ层搜寻）二个部份。</p>
<p>##依关键词搜索<br>有词／词类／角色／特征的项目供使用者填入，使用者可以依需求填入必要的项目。举例来说，如果要查「我们」，就在词的部份填入「我们」即可；如果要查「我们」词类为「Nhaa」的话，在词的部份填入「我们」，并在词类的部份填入「Nhaa」即可；总而言之，它是复合式条件的输入，但看使用者的而求而定。另外，如果使用者对词类不熟，可以「%」代表万用字元。比如说，使用者想查 “Nh” 开头的词类，可以在词类类的栏位键入「Nh%」即可。</p>
<p>##依句型搜索<br>以「句型」为搜寻剖析树结构的方式，其中包含「专业用法」、「标准结构」和「文字输入」，三种方式。以想要查询 “S(experiencer:NP|Head:VL1:爱|goal:NP)” 句型为例专业用法的搜寻表达方式如下，<br>S &lt; ((/experiencer:NP/) $.. ((/Head:VL1/ &lt; 爱) $.. ((/goal:NP/))))<br>特别说明：<br>A &lt; B    —&gt; A(B)<br>A $.. B  —&gt; A|B<br>/A/ &lt; B  —&gt; A*(B)<br>请在输入完毕后，按下 [更新] 按钮，可以检视其它输入方式的内容。<br>而标准结构的搜寻则是输入：<br>S(experiencer:NP|Head:VL1:爱|goal:NP)<br>同样的请在输入完毕后，按下 [更新] 按钮，可以检视其它输入方式的内容。<br>假设你都不知道要输入什麽的结构，可以输入文字，进行线上剖析，会显示其剖析结果，再加以修改。<br>输入：我爱你　　按下 [剖析] 按钮<br>输出：S(experiencer:NP(Head:Nhaa:我)|Head:VL1:爱|goal:NP(Head:Nhaa:你)) </p>
<p>##再处理<br>再处理的部份，主要再缩小范围，找到更符合条件的树或查看其统计频率讯息。系统提供使用者对查询后的结果进行统计与过滤的动作。<br>首要任务就是先设定好处理的范围，系统提供五种范围设定：全句、同关键词词组、关键词左右范围、搭配词，接下来是依使用者的需求而定，如果要进行过滤的动作（也就是对经由第一层查询后的结果，再进行过滤分析的动作）系统提供：搭配词过滤、句型过滤。另外的统计部份，系统提供以下的统计：句型、角色/词类/词、角色、词类、词，并且可以设定频率下限，内定值为2。</p>
<p>##过滤<br>若过滤的对像是「搭配词」，记得在搭配词上打勾。搜寻对象为「词类」、「语义角色」、「特徵」可点选各自右方的 ，即可得到剖析树所有的词类和语义角色，以便查询，至于各词类及论旨角色的特性和分类原则，可参考「词库小组技术报告93-05中文词类分析」，里面有详细分析和说明。或自行依不同类别，作不同的输入。<br>若过滤的对象是「句型」，其条件的输入方式同第一层的句型输入方式。只是，如果使用者是再「句型」查询后进入再处理的动作，操作方式都是一样的。</p>
<p>##统计<br>在统计的部份，接着前一次查询「我们」的结果，假设想查询「我们」有哪些词类，可以在范围里设定，起与迄可以是正负值。并点选统计左侧的选项，再点选词类的项，在按执行按钮之后，就会出现统计的结果。</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Susan J. Blalock,Carri Casteel,Mary T. Roth,Stefanie Ferreri,Karen B. Demby,Viswanathan Shankar. Impact of enhanced pharmacologic care on the prevention of falls: A randomized controlled trial[J]. American Journal of Geriatric Pharmacotherapy,2010,8(5).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/23/刘唯_COCA语料库/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/23/刘唯_COCA语料库/" itemprop="url">COCA语料库</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-23T23:35:16+05:00">
                2018-04-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h1><p><a href="http://corpus/byu.edu/coca" target="_blank" rel="noopener">http://corpus/byu.edu/coca</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>美国当代英语语料库（Corpus of Contemporary American English)由美国Brigham Young University的Mark Davies教授开发，目前单词容量为4.25亿，是美国目前最新的当代英语语料库，同时也是当今世界上最大的英语平衡语料库。该语料库的语料来自1990——2011年，每年更新，检索功能强大，因此它是最佳的英语学习助手。有了一定英语基础的学习者都应学会使用它，它也是英语教师最好的教学资源之一。</p>
<p>#使用攻略</p>
<p>#查单词<br>直接输入<br>对于具有不同词性的单词，可带上相应的标签。如welcome一词，若查名词用法，可输入welcome.[NN1]；若查形容词用法，可输入welcome[JJ];若查动词用法，可输入welcome.[VVO].</p>
<p>#查短语<br>直接输入</p>
<p>#查句子<br>直接输入</p>
<p>#查前缀<br>可借助通配符<em>，如输入dis</em>,be*等</p>
<p>#查后缀<br>可借助通配符<em>，如输入</em>less</p>
<p>#查具有相同字母的某些单词<br>可借助通配符<em>，如输入tedte</em></p>
<p>#查词根<br>可借助通配符<em>，如输入re</em>re</p>
<p>#查同义词<br>可借助方括号和等号，如输入[=give]<br>比较同义词，可点击COMPARE-WORDS，然后再WORDS输入同义词比较的同义词</p>
<p>#查搭配<br>比如若想查看invent后接的名词宾语，输入invent，然后POS LIST对话框选择noun.ALL</p>
<p>#相关论文<br>[1]汪兴富,Mark Davies,刘国辉.美国当代英语语料库(COCA)——英语教学与研究的良好平台[J].外语电化教学,2008(05):27-33.<br>[2]冯恩玉,吴蕾.基于COCA语料库的英语近义词差异性研究——以confess等近义词为例[J].西安航空学院学报,2016,34(02):25-28+59.<br>[3]彭程.短语学视角下的二语同义词组习得对比——一项基于CLEC及COCA语料库的研究[J].北京第二外国语学院学报,2016,38(04):55-67+133.<br>[4]王大鹏.基于COCA语料库的英语同义词辨析——以obtain等同义词为例[J].渤海大学学报(哲学社会科学版),2013,35(01):72-74.<br>[5]张艳敏.美国多元媒介中的江苏国际形象研究——基于COCA语料库的实证分析[J].江苏科技大学学报(社会科学版),2016,16(03):86-94.<br>[6]曹巍,王珊,覃雄派,王秋月.面向不同数据分布的多维直方图算法COCA-Hist[J].计算机学报,2008(06):1013-1024.<br>[7]兰丽珍.基于COCA语料库的英语近义词研究——以careful和cautious为例[J].内蒙古财经大学学报,2017,15(06):107-110.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/21/卢梦依_The 20 Newsgroups data set 新闻组数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/21/卢梦依_The 20 Newsgroups data set 新闻组数据集/" itemprop="url">The 20 Newsgroups data set 新闻组数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-21T21:47:46+05:00">
                2018-04-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依<br>下载地址：<a href="http://qwone.com/~jason/20Newsgroups/" target="_blank" rel="noopener">http://qwone.com/~jason/20Newsgroups/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>该数据集包含着新闻组相关的文本数据信息。这二十个新闻组数据集合收集了大约20,000新闻组文档，均匀的分布在20个不同的集合。这些文档具有新闻的典型特征：主题，作者和引述。</p>
<h1 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h1><p> 大小：20 MB<br> 类型：txt文本<br> 数量：来自20个新闻组的20,000条消息</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Kim Y. Convolutional Neural Networks for Sentence Classification[J]. Eprint Arxiv, 2014.<br>2.Joulin A, Grave E, Bojanowski P, et al. Bag of Tricks for Efficient Text Classification[J]. 2016:427-431.<br>3.Zhang Y, Wallace B. A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification[J]. Computer Science, 2015.<br>4.Ji Y L, Dernoncourt F. Sequential Short-Text Classification with Recurrent and Convolutional Neural Networks[J]. 2016:515-520.<br>5.Chen G, Ye D, Xing Z, et al. Ensemble application of convolutional and recurrent neural networks for multi-label text categorization[C]// International Joint Conference on Neural Networks. IEEE, 2017:2377-2383.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/21/卢梦依_SQuAD The Stanford Question Answering Dataset 问答数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/21/卢梦依_SQuAD The Stanford Question Answering Dataset 问答数据集/" itemprop="url">SQuAD The Stanford Question Answering Dataset 问答数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-21T21:47:46+05:00">
                2018-04-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依<br>下载地址：<a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="noopener">https://rajpurkar.github.io/SQuAD-explorer/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>斯坦福问题回答数据集(SQuAD)是一种新的阅读理解数据集，由一组维基百科文章的工作者提出的问题组成，<br>其中每个问题的答案都是从相应阅读段落中截取的一段文字。<br>在500+的文章中，有100,000+的问题-答案对，SQuAD显着大于以前的阅读理解数据集。</p>
<h1 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h1><p> 训练集30M<br> 验证集5M</p>
<h1 id="数量"><a href="#数量" class="headerlink" title="数量"></a>数量</h1><p> 约30,000,000个句子及其翻译</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Rajpurkar P, Zhang J, Lopyrev K, et al. SQuAD: 100,000+ Questions for Machine Comprehension of Text[J]. 2016:2383-2392.<br>2.Wang Z, Mi H, Hamza W, et al. Multi-Perspective Context Matching for Machine Comprehension[J]. 2016.<br>3.Kim S, Park D, Choi Y, et al. A Pilot Study of Biomedical Text Comprehension using an Attention-Based Deep Neural Reader: Design and Experimental Analysis.[J]. Jmir Medical Informatics, 2018, 6(1):e2.<br>4.Reutebuch C K, Zein F E, Min K K, et al. Investigating a reading comprehension intervention for high school students with autism spectrum disorder: A pilot study[J]. Research in Autism Spectrum Disorders, 2015, 9:96-111.<br>5.Yin W, Ebert S, Schütze H. Attention-Based Convolutional Neural Network for Machine Comprehension[J]. 2016.<br>6.Cui Y, Chen Z, Wei S, et al. Attention-over-Attention Neural Networks for Reading Comprehension[C]// Meeting of the Association for Computational Linguistics. 2017:593-602.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/21/卢梦依_Sentiment140/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/21/卢梦依_Sentiment140/" itemprop="url">Sentiment140 - A Twitter Sentiment Analysis Tool 情感分析数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-21T21:47:46+05:00">
                2018-04-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依<br>下载地址：<a href="http://help.sentiment140.com/for-students/" target="_blank" rel="noopener">http://help.sentiment140.com/for-students/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>Sentiment140是一个可用于情感分析的数据集。<br>数据集具有以下6个特征：</p>
<ul>
<li>推文的感情色彩（polarity）</li>
<li>推文的ID</li>
<li>推文的日期</li>
<li>查看记录</li>
<li>推特（tweeter）的用户名</li>
<li>推文的文本内容</li>
</ul>
<h1 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h1><p> 大小：80 MB（压缩包）</p>
<h1 id="数量"><a href="#数量" class="headerlink" title="数量"></a>数量</h1><p> 160,000条推文</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Zhang X, Zhao J, Lecun Y. Character-level Convolutional Networks for Text Classification[J]. 2015:649-657.<br>2.Severyn, A., &amp; Moschitti, A. UNITN: Training Deep Convolutional Neural Network for TwitterSentiment Classification.<br>3.Xu, J., Wang, P., Tian, G., Xu, B., Zhao, J., Wang, F., &amp; Hao, H. (2015,June). Short TextClustering via Convolutional Neural Networks. In Proceedings of NAACL-HLT (pp.62-69).<br>4.Wang, P., Xu, J., Xu, B., Liu, C. L., Zhang, H., Wang, F., &amp; Hao, H.(2015). SemanticClustering and Convolutional Neural Network for Short Text Categorization.In Proceedings of the 53rd Annual Meeting of the Association forComputational Linguistics and the 7th International Joint Conference on NaturalLanguage Processing (Vol.2, pp. 352-357).<br>5.Liu, Y., Liu, Z., Chua, T. S., &amp; Sun, M. (2015, February). Topical Word Embeddings.In Twenty-Ninth AAAI Conference on Artificial Intelligence.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/21/卢梦伊_Machine Translation of Various Languages 机器翻译数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/21/卢梦伊_Machine Translation of Various Languages 机器翻译数据/" itemprop="url">Machine Translation of Various Languages 机器翻译数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-21T21:47:46+05:00">
                2018-04-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依<br>下载地址：<a href="http://statmt.org/wmt18/translation-task.html#download" target="_blank" rel="noopener">http://statmt.org/wmt18/translation-task.html#download</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>该数据集包含四种欧洲语言的训练数据。可用于改进当前的翻译方法。有以下语言互译可供参考：</p>
<ul>
<li>英汉和汉英</li>
<li>英语 - 捷克语和捷克语 - 英语</li>
<li>英语 - 爱沙尼亚语和爱沙尼亚语 - 英语</li>
<li>英语 - 芬兰语和芬兰语 - 英语</li>
<li>英语 - 德语和德语 - 英语</li>
<li>英语 - 哈萨克语和哈萨克语 - 英语</li>
<li>英文 - 俄文和俄文 - 英文</li>
<li>英语 - 土耳其语和土耳其语 - 英语</li>
</ul>
<h1 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h1><p> 约15 GB</p>
<h1 id="数量"><a href="#数量" class="headerlink" title="数量"></a>数量</h1><p> 约30,000,000个句子及其翻译</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Gehring J, Auli M, Grangier D, et al. Convolutional Sequence to Sequence Learning[J]. 2017.<br>2.Wu Y, Schuster M, Chen Z, et al. Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation[J]. 2016..<br>3.Luong M T, Manning C D. Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models[J]. 2016:1054-1063.<br>4.Lee J, Cho K, Hofmann T. Fully Character-Level Neural Machine Translation without Explicit Segmentation[J]. 2016.<br>5.Chung J, Cho K, Bengio Y. A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation[J]. 2016.<br>6.Firat O, Cho K, Bengio Y. Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism[J]. 2016:866-875.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/刘晓_genia tagger/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/刘晓_genia tagger/" itemprop="url">GENIA Tagger</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="http://www.nactem.ac.uk/tsujii/GENIA/tagger/" title="http://www.nactem.ac.uk/tsujii/GENIA/tagger/" target="_blank" rel="noopener">http://www.nactem.ac.uk/tsujii/GENIA/tagger/</a></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>GENIA Tagger对生物医学文本进行标记、浅解析和命名实体识别。<br>GENIA标记器分析英语句子并输出基本形式，词性标记，块标记和命名实体标记。标记器专门针对生物医学文本（如MEDLINE摘要）进行了调整。如果需要从生物医学文档中提取信息，该标记器可能是一个有用的预处理工具。可以尝试<a href="http://text0.mib.man.ac.uk/software/geniatagger/" target="_blank" rel="noopener">演示页面</a>上的标记器。  </p>
<h2 id="使用教程"><a href="#使用教程" class="headerlink" title="使用教程"></a>使用教程</h2><p><strong>安装：</strong>  </p>
<ul>
<li>下载地址：<a href="http://www.nactem.ac.uk/tsujii/GENIA/tagger/geniatagger-3.0.2.tar.gz" target="_blank" rel="noopener">http://www.nactem.ac.uk/tsujii/GENIA/tagger/geniatagger-3.0.2.tar.gz</a>  </li>
<li>解压文档：tar xvzf geniatagger.tar.gz  </li>
<li><p>Make:  </p>
<pre><code>cd geniatagger  
make
</code></pre></li>
<li><p>标记句子：准备一个每行包含一个句子的文本文件，然后  </p>
</li>
</ul>
<pre><code>./geniatagger &lt; RAWTEXT &gt; TAGGEDTEXT
</code></pre><table>
<thead>
<tr>
<th>word</th>
<th>base</th>
<th>POStag</th>
<th>chunktag</th>
<th>NEtag</th>
</tr>
</thead>
<tbody>
<tr>
<td>word1</td>
<td>base1</td>
<td>POStag1</td>
<td>chunktag1</td>
<td>NEtag1</td>
</tr>
<tr>
<td>word2</td>
<td>base2</td>
<td>POStag2</td>
<td>chunktag2</td>
<td>NEtag2</td>
</tr>
<tr>
<td>  :</td>
<td>:</td>
<td>:</td>
<td>:</td>
<td>:</td>
</tr>
</tbody>
</table>
<p>标记器以以上制表符分隔的格式输出基本形式，词性（POS）标记，块标记和命名实体（NE）标记。<br>块以IOB2格式表示（B表示BEGIN，I表示内部，O表示外部）。</p>
<p><strong>示例：</strong>  </p>
<pre><code>echo &quot;Inhibition of NF-kappaB activation reversed the anti-apoptotic effect of isochamaejasmin.&quot; | ./geniatagger
</code></pre><table>
<thead>
<tr>
<th>word</th>
<th>base</th>
<th>POStag</th>
<th>chunktag</th>
<th>NEtag</th>
</tr>
</thead>
<tbody>
<tr>
<td>Inhibition</td>
<td>Inhibition</td>
<td>NN</td>
<td>B-NP</td>
<td>O</td>
</tr>
<tr>
<td>of</td>
<td>of</td>
<td>IN</td>
<td>B-PP</td>
<td>O</td>
</tr>
<tr>
<td>NF-kappaB</td>
<td>NF-kappaB</td>
<td>NN</td>
<td>B-NP</td>
<td>B-protein</td>
</tr>
<tr>
<td>activation</td>
<td>activation</td>
<td>NN</td>
<td>I-NP</td>
<td>O</td>
</tr>
<tr>
<td>reversed</td>
<td>reverse</td>
<td>VBD</td>
<td>B-VP</td>
<td>O</td>
</tr>
<tr>
<td>the</td>
<td>the</td>
<td>DT</td>
<td>B-NP</td>
<td>O</td>
</tr>
<tr>
<td>anti-apoptotic</td>
<td>anti-apoptotic</td>
<td>JJ</td>
<td>I-NP</td>
<td>O</td>
</tr>
<tr>
<td>effect</td>
<td>effect</td>
<td>NN</td>
<td>I-NP</td>
<td>O</td>
</tr>
<tr>
<td>of</td>
<td>of</td>
<td>IN</td>
<td>B-PP</td>
<td>O</td>
</tr>
<tr>
<td>isochamaejasmin</td>
<td>isochamaejasmin</td>
<td>NN</td>
<td>B-NP</td>
<td>O</td>
</tr>
<tr>
<td>.</td>
<td>.</td>
<td>.</td>
<td>O</td>
<td>O</td>
</tr>
</tbody>
</table>
<p>通过查看块标签，您可以从该输出中轻松提取四个名词短语（“抑制”，“NF-kappaB激活”，“抗凋亡效应”和“isochamaejasmin”）。您还可以使用指定的实体标签查找蛋白质名称。</p>
<h2 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h2><p>[1] S. Kulick, A. Bies, M. Liberman, M. Mandel, R. McDonald, M. Palmer, A. Schein and L. Ungar. Integrated Annotation for Biomedical Information Extraction, HLT/NAACL 2004 Workshop: Biolink 2004, pp. 61-68.<br>[2] Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim, Tomoko Ohta, John McNaught, Sophia Ananiadou, and Jun’ichi Tsujii, Developing a Robust Part-of-Speech Tagger for Biomedical Text, Advances in Informatics - 10th Panhellenic Conference on Informatics, LNCS 3746, pp. 382-392, 2005 (pdf)<br>[3] Yoshimasa Tsuruoka and Jun’ichi Tsujii, Bidirectional Inference with the Easiest-First Strategy for Tagging Sequence Data, Proceedings of HLT/EMNLP 2005, pp. 467-474. (pdf)</p>
<p>上文来源：<a href="http://www.nactem.ac.uk/GENIA/tagger/" target="_blank" rel="noopener">http://www.nactem.ac.uk/GENIA/tagger/</a></p>
<p>GENIA Tagger Demo：<a href="http://text0.mib.man.ac.uk/software/geniatagger/" target="_blank" rel="noopener">http://text0.mib.man.ac.uk/software/geniatagger/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/刘晓_百度自然语言处理API服务/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/刘晓_百度自然语言处理API服务/" itemprop="url">百度自然语言处理API服务</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="http://ai.baidu.com/tech/nlp" target="_blank" rel="noopener">http://ai.baidu.com/tech/nlp</a> </p>
<h2 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h2><p>百度自然语言处理：<a href="http://ai.baidu.com/tech/nlp" target="_blank" rel="noopener">http://ai.baidu.com/tech/nlp</a><br>SDK下载地址：<a href="http://ai.baidu.com/sdk#nlp" target="_blank" rel="noopener">http://ai.baidu.com/sdk#nlp</a>  </p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Python SDK文档，主要针对Python开发者描述百度自然语言处理接口服务的相关技术内容。 </p>
<p><strong>接口能力：</strong>  </p>
<ul>
<li>接口名称：     接口能力简要描述  </li>
<li>词法分析：        分词、词性标注、专名识别  </li>
<li>依存句法分析：    自动分析文本中的依存句法结构信息  </li>
<li>词向量表示：    查询词汇的词向量，实现文本的可计算  </li>
<li>DNN语言模型：    判断一句话是否符合语言表达习惯，输出分词结果并给出每个词在句子中的概率值  </li>
<li>词义相似度：    计算两个给定词语的语义相似度  </li>
<li>短文本相似度：    判断两个文本的相似度得分  </li>
<li>评论观点抽取：    提取一个句子观点评论的情感属性  </li>
<li>情感倾向分析：    对包含主观观点信息的文本进行情感极性类别（积极、消极、中性）的判断，并给出相应的置信度  </li>
<li>中文分词：     切分出连续文本中的基本词汇序列（已合并到词法分析接口）  </li>
<li>词性标注：     为自然语言文本中的每个词汇赋予词性（已合并到词法分析接口）  </li>
</ul>
<p>版本更新：<br>2018.01.25    2.2.0    新增文本标签API<br>2017.12.22    2.0.0    SDK代码重构<br>2017.5.11    1.0.0    自然语言处理服务上线</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><strong>安装自然语言处理 Python SDK</strong>  </p>
<p>自然语言处理 Python SDK目录结构：</p>
<p>|── README.md  </p>
<p>├── aip                   //SDK目录  </p>
<p>│   ├── <strong>init</strong>.py          //导出类  </p>
<p>│   ├── base.py           //aip基类  </p>
<p>│   ├── http.py           //http请求  </p>
<p>│   └── nlp.py //自然语言处理  </p>
<p>└── setup.py              //setuptools安装  </p>
<p><strong>支持Python版本：2.7.+ ,3.+</strong></p>
<p><strong>安装使用Python SDK有如下方式：</strong></p>
<p>如果已安装pip：  </p>
<pre><code>pip install baidu-aip  
</code></pre><p>如果已安装setuptools:  </p>
<pre><code>python setup.py install  
</code></pre><h2 id="使用教程"><a href="#使用教程" class="headerlink" title="使用教程"></a>使用教程</h2><p><strong>新建AipNlp</strong>    </p>
<p>AipNlp是自然语言处理的Python SDK客户端，为使用自然语言处理的开发人员提供了一系列的交互方法。  </p>
<p>参考如下代码新建一个AipNlp：</p>
<pre><code>from aip import AipNlp

&quot;&quot;&quot; 你的 APPID AK SK &quot;&quot;&quot;
APP_ID = &apos;你的 App ID&apos;
API_KEY = &apos;你的 Api Key&apos;
SECRET_KEY = &apos;你的 Secret Key&apos;

client = AipNlp(APP_ID, API_KEY, SECRET_KEY)  
</code></pre><p>在上面代码中，常量APP_ID在百度云控制台中创建，常量API_KEY与SECRET_KEY是在创建完毕应用后，系统分配给用户的，均为字符串，用于标识用户，为访问做签名验证，可在AI服务控制台中的应用列表中查看。</p>
<p>注意：如您以前是百度云的老用户，其中API_KEY对应百度云的“Access Key ID”，SECRET_KEY对应百度云的“Access Key Secret”。</p>
<p><strong>配置AipNlp</strong>  </p>
<p>如果用户需要配置AipNlp的网络请求参数(一般不需要配置)，可以在构造AipNlp之后调用接口设置参数，目前只支持以下参数：  </p>
<table>
<thead>
<tr>
<th>接口</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>setConnectionTimeoutInMillis</td>
<td>建立连接的超时时间（单位：毫秒  </td>
</tr>
<tr>
<td>setSocketTimeoutInMillis</td>
<td>通过打开的连接传输数据的超时时间（单位：毫秒）</td>
</tr>
</tbody>
</table>
<h2 id="接口说明"><a href="#接口说明" class="headerlink" title="接口说明"></a>接口说明</h2><p><strong>词法分析</strong><br>词法分析接口向用户提供分词、词性标注、专名识别三大功能；能够识别出文本串中的基本词汇（分词），对这些词汇进行重组、标注组合后词汇的词性，并进一步识别出命名实体。    </p>
<pre><code>text = &quot;百度是一家高科技公司&quot;

&quot;&quot;&quot; 调用词法分析 &quot;&quot;&quot;
client.lexer(text);  
</code></pre><ul>
<li>参数 –&gt; text : 必选，string类型，是一个待分析文本（目前仅支持GBK编码），长度不超过65536字节。   </li>
</ul>
<ul>
<li>返回参数分析：  </li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>必需</th>
<th>详细说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>string</td>
<td>是</td>
<td>原始单条请求文本</td>
</tr>
<tr>
<td>items</td>
<td>array(object)</td>
<td>是</td>
<td>词汇数组，每个元素对应结果中的一个词</td>
</tr>
<tr>
<td>+item</td>
<td>string</td>
<td>是</td>
<td>词汇的字符串</td>
</tr>
<tr>
<td>+ne</td>
<td>string</td>
<td>是</td>
<td>命名实体类型，命名实体识别算法使用。词性标注算法中，此项为空串</td>
</tr>
<tr>
<td>+pos</td>
<td>string</td>
<td>是</td>
<td>词性，词性标注算法使用。命名实体识别算法中，此项为空串</td>
</tr>
<tr>
<td>+byte_offset</td>
<td>int</td>
<td>是</td>
<td>在text中的字节级offset（使用GBK编码）</td>
</tr>
<tr>
<td>+byte_length</td>
<td>int</td>
<td>是</td>
<td>字节级length（使用GBK编码）</td>
</tr>
<tr>
<td>+uri</td>
<td>string</td>
<td>否</td>
<td>链指到知识库的URI，只对命名实体有效。对于非命名实体和链接不到知识库的命名实体，此项为空串</td>
</tr>
<tr>
<td>+formal</td>
<td>string</td>
<td>否</td>
<td>词汇的标准化表达，主要针对时间、数字单位，没有归一化表达的，此项为空串</td>
</tr>
<tr>
<td>+basic_words</td>
<td>array(string)</td>
<td>是</td>
<td>基本词成分</td>
</tr>
<tr>
<td>+loc_details</td>
<td>array(object)</td>
<td>否</td>
<td>地址成分，非必需，仅对地址型命名实体有效，没有地址成分的，此项为空数组。</td>
</tr>
<tr>
<td>++type</td>
<td>string</td>
<td>是</td>
<td>成分类型，如省、市、区、县</td>
</tr>
<tr>
<td>++byte_offset</td>
<td>int</td>
<td>是</td>
<td>在item中的字节级offset（使用GBK编码）</td>
</tr>
<tr>
<td>++byte_length</td>
<td>nt</td>
<td>是</td>
<td>字节级length（使用GBK编码）  </td>
</tr>
</tbody>
</table>
<ul>
<li><p>词法分析返回示例：    </p>
<pre><code> {
     &quot;status&quot;:0,
     &quot;version&quot;:&quot;ver_1_0_1&quot;,
     &quot;results&quot;:[
     {
       &quot;retcode&quot;:0,
       &quot;text&quot;:&quot;百度是一家高科技公司&quot;,
      &quot;items&quot;:[
     {
        &quot;byte_length&quot;:4,
        &quot;byte_offset&quot;:0,
        &quot;formal&quot;:&quot;&quot;,
        &quot;item&quot;:&quot;百度&quot;,
        &quot;ne&quot;:&quot;ORG&quot;,
        &quot;pos&quot;:&quot;&quot;,
        &quot;uri&quot;:&quot;&quot;,
        &quot;loc_details&quot;:[ ],
        &quot;basic_words&quot;:[&quot;百度&quot;]
      },
      {
        &quot;byte_length&quot;:2,
        &quot;byte_offset&quot;:4,
        &quot;formal&quot;:&quot;&quot;,
        &quot;item&quot;:&quot;是&quot;,
        &quot;ne&quot;:&quot;&quot;,
        &quot;pos&quot;:&quot;v&quot;,
        &quot;uri&quot;:&quot;&quot;,
        &quot;loc_details&quot;:[ ],
        &quot;basic_words&quot;:[&quot;是&quot;]
      },
      {
        &quot;byte_length&quot;:4,
        &quot;byte_offset&quot;:6,
        &quot;formal&quot;:&quot;&quot;,
        &quot;item&quot;:&quot;一家&quot;,
        &quot;ne&quot;:&quot;&quot;,
        &quot;pos&quot;:&quot;m&quot;,
        &quot;uri&quot;:&quot;&quot;,
        &quot;loc_details&quot;:[ ],
        &quot;basic_words&quot;:[&quot;一&quot;,&quot;家&quot;]
       },
       {
        &quot;byte_length&quot;:6,
        &quot;byte_offset&quot;:10,
        &quot;formal&quot;:&quot;&quot;,
        &quot;item&quot;:&quot;高科技&quot;,
        &quot;ne&quot;:&quot;&quot;,
        &quot;pos&quot;:&quot;n&quot;,
        &quot;uri&quot;:&quot;&quot;,
        &quot;loc_details&quot;:[ ],
        &quot;basic_words&quot;:[&quot;高&quot;,&quot;科技&quot;]
       },
       {
       &quot;byte_length&quot;:4,
       &quot;byte_offset&quot;:16,
       &quot;formal&quot;:&quot;&quot;,
       &quot;item&quot;:&quot;公司&quot;,
       &quot;ne&quot;:&quot;&quot;,
       &quot;pos&quot;:&quot;n&quot;,
       &quot;uri&quot;:&quot;&quot;,
       &quot;loc_details&quot;:[ ],
       &quot;basic_words&quot;:[&quot;公司&quot;]
       }
      ]
   }
  ]
}
</code></pre></li>
</ul>
<ul>
<li>词性缩略说明：  </li>
</ul>
<table>
<thead>
<tr>
<th>词性</th>
<th>含义</th>
<th>词性</th>
<th>含义</th>
<th>词性</th>
<th>含义</th>
<th>词性</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>n</td>
<td>普通名词</td>
<td>f</td>
<td>方位名词</td>
<td>s</td>
<td>处所名词</td>
<td>t</td>
<td>时间名词</td>
</tr>
<tr>
<td>nr</td>
<td>人名</td>
<td>ns</td>
<td>地名</td>
<td>nt</td>
<td>机构团体名</td>
<td>nw</td>
<td>作品名</td>
</tr>
<tr>
<td>nz</td>
<td>其他专名</td>
<td>v</td>
<td>普通动词</td>
<td>vd</td>
<td>动副词</td>
<td>vn</td>
<td>名动词</td>
</tr>
<tr>
<td>a</td>
<td>形容词</td>
<td>ad</td>
<td>副形词</td>
<td>an</td>
<td>名形词</td>
<td>d</td>
<td>副词</td>
</tr>
<tr>
<td>m</td>
<td>数量词</td>
<td>q</td>
<td>量词</td>
<td>r</td>
<td>代词</td>
<td>p</td>
<td>介词</td>
</tr>
<tr>
<td>c</td>
<td>连词</td>
<td>u</td>
<td>助词</td>
<td>xc</td>
<td>其他虚词</td>
<td>w</td>
<td>标点符号  </td>
</tr>
</tbody>
</table>
<ul>
<li>专名识别缩略词含义:</li>
</ul>
<table>
<thead>
<tr>
<th>缩略词</th>
<th>含义</th>
<th>缩略词</th>
<th>含义</th>
<th>缩略词</th>
<th>含义</th>
<th>缩略词</th>
<th>含义  </th>
</tr>
</thead>
<tbody>
<tr>
<td>PER</td>
<td>人名</td>
<td>LOC</td>
<td>地名</td>
<td>ORG</td>
<td>机构名</td>
<td>TIME</td>
<td>时间  </td>
</tr>
</tbody>
</table>
<p><strong>词法分析（定制版）</strong><br>词法分析接口向用户提供分词、词性标注、专名识别三大功能；能够识别出文本串中的基本词汇（分词），对这些词汇进行重组、标注组合后词汇的词性，并进一步识别出命名实体。定制版接口的使用教程请看链接：<a href="http://ai.baidu.com/forum/topic/show/496975" target="_blank" rel="noopener">http://ai.baidu.com/forum/topic/show/496975</a></p>
<pre><code>text = &quot;百度是一家高科技公司&quot;

&quot;&quot;&quot; 调用词法分析（定制版） &quot;&quot;&quot;
client.lexerCustom(text);
</code></pre><ul>
<li>词法分析（定制版） 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>待分析文本（目前仅支持GBK编码），长度不超过65536字节</td>
</tr>
</tbody>
</table>
<ul>
<li>词法分析（定制版） 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>必需</th>
<th>详细说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>string</td>
<td>是</td>
<td>原始单条请求文本</td>
</tr>
<tr>
<td>items</td>
<td>array(object)</td>
<td>是</td>
<td>词汇数组，每个元素对应结果中的一个词</td>
</tr>
<tr>
<td>+item</td>
<td>string</td>
<td>是</td>
<td>词汇的字符串</td>
</tr>
<tr>
<td>+ne</td>
<td>string</td>
<td>是</td>
<td>命名实体类型，命名实体识别算法使用。词性标注算法中，此项为空串</td>
</tr>
<tr>
<td>+pos</td>
<td>string</td>
<td>是</td>
<td>词性，词性标注算法使用。命名实体识别算法中，此项为空串</td>
</tr>
<tr>
<td>+byte_offset</td>
<td>int</td>
<td>是</td>
<td>在text中的字节级offset（使用GBK编码）</td>
</tr>
<tr>
<td>+byte_length</td>
<td>int</td>
<td>是</td>
<td>字节级length（使用GBK编码）</td>
</tr>
<tr>
<td>+uri</td>
<td>string</td>
<td>否</td>
<td>链指到知识库的URI，只对命名实体有效。对于非命名实体和链接不到知识库的命名实体，此项为空串</td>
</tr>
<tr>
<td>+formal</td>
<td>string</td>
<td>否</td>
<td>词汇的标准化表达，主要针对时间、数字单位，没有归一化表达的，此项为空串</td>
</tr>
<tr>
<td>+basic_words</td>
<td>array(string)</td>
<td>是</td>
<td>基本词成分</td>
</tr>
<tr>
<td>+loc_details</td>
<td>array(object)</td>
<td>否</td>
<td>地址成分，非必需，仅对地址型命名实体有效，没有地址成分的，此项为空数组。</td>
</tr>
<tr>
<td>++type</td>
<td>string</td>
<td>是</td>
<td>成分类型，如省、市、区、县</td>
</tr>
<tr>
<td>++byte_offset</td>
<td>int</td>
<td>是</td>
<td>在item中的字节级offset（使用GBK编码）</td>
</tr>
<tr>
<td>++byte_length</td>
<td>int</td>
<td>是</td>
<td>字节级length（使用GBK编码）  </td>
</tr>
</tbody>
</table>
<p><strong>依存句法分析</strong>  </p>
<p>依存句法分析接口可自动分析文本中的依存句法结构信息，利用句子中词与词之间的依存关系来表示词语的句法结构信息（如“主谓”、“动宾”、“定中”等结构关系），并用树状结构来表示整句的结构（如“主谓宾”、“定状补”等）。  </p>
<pre><code>text = &quot;张飞&quot;

&quot;&quot;&quot; 调用依存句法分析 &quot;&quot;&quot;
client.depParser(text);

&quot;&quot;&quot; 如果有可选参数 &quot;&quot;&quot;
options = {}
options[&quot;mode&quot;] = 1

&quot;&quot;&quot; 带参数调用依存句法分析 &quot;&quot;&quot;
client.depParser(text, options)  
</code></pre><ul>
<li>依存句法分析 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>待分析文本（目前仅支持GBK编码），长度不超过256字节</td>
</tr>
<tr>
<td>mode</td>
<td>否</td>
<td>string</td>
<td>模型选择。默认值为0，可选值mode=0（对应web模型）；mode=1（对应query模型）</td>
</tr>
</tbody>
</table>
<ul>
<li>依存句法分析 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>详细说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>uint64</td>
<td>随机数，本次请求的唯一标识码</td>
</tr>
<tr>
<td>id</td>
<td>number</td>
<td>词的ID</td>
</tr>
<tr>
<td>word</td>
<td>string</td>
<td>词</td>
</tr>
<tr>
<td>postag</td>
<td>string</td>
<td>词性，请参照API文档中的词性（postag)取值范围</td>
</tr>
<tr>
<td>head</td>
<td>int</td>
<td>词的父节点ID</td>
</tr>
<tr>
<td>+deprel</td>
<td>string</td>
<td>词与父节点的依存关系，请参照API文档的依存关系标识</td>
</tr>
</tbody>
</table>
<ul>
<li><p>依存句法分析 返回示例    </p>
<pre><code>{
&quot;log_id&quot;: 12345,
&quot;text&quot;:&quot;今天天气怎么样&quot;,
&quot;items&quot;:[
{
&quot;id&quot;:&quot;1&quot;, //id
&quot;word&quot;:&quot;今天&quot;, //word
&quot;postag&quot;:&quot;t&quot;, //POS tag
&quot;head&quot;:&quot;2&quot;, //id of current word&apos;s parent
&quot;deprel&quot;:&quot;ATT&quot;  //depend relations between current word and parent
},
{
&quot;id&quot;:&quot;2&quot;,
&quot;word&quot;:&quot;天气&quot;,
&quot;postag&quot;:&quot;n&quot;,
&quot;head&quot;:&quot;3&quot;,
&quot;deprel&quot;:&quot;SBV&quot;,
},
{
&quot;id&quot;:&quot;3&quot;,
&quot;word&quot;:&quot;怎么样&quot;,
&quot;postag&quot;:&quot;r&quot;,
&quot;head&quot;:&quot;0&quot;,
&quot;deprel&quot;:&quot;HED&quot;,
}
]
}  
</code></pre></li>
</ul>
<p><strong>词向量表示</strong>  </p>
<p>词向量表示接口提供中文词向量的查询功能。</p>
<pre><code>word = &quot;张飞&quot;

&quot;&quot;&quot; 调用词向量表示 &quot;&quot;&quot;
client.wordEmbedding(word);
</code></pre><ul>
<li>词向量表示 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<p>word    是    string    文本内容（GBK编码），最大64字节</p>
<ul>
<li>词向量表示 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>描述  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>uint64</td>
<td>请求唯一标识码</td>
</tr>
<tr>
<td>word</td>
<td>string</td>
<td>查询词</td>
</tr>
<tr>
<td>vec</td>
<td>float</td>
<td>词向量结果表示</td>
</tr>
</tbody>
</table>
<ul>
<li><p>词向量表示 返回示例  </p>
<pre><code>{
  &quot;word&quot;: &quot;张飞&quot;,
  &quot;vec&quot;: [
0.233962,
0.336867,
0.187044,
0.565261,
0.191568,
0.450725,
...
0.43869,
-0.448038,
0.283711,
-0.233656,
0.555556
  ]
}  
</code></pre></li>
</ul>
<p><strong> DNN语言模型 </strong></p>
<p>中文DNN语言模型接口用于输出切词结果并给出每个词在句子中的概率值,判断一句话是否符合语言表达习惯。</p>
<pre><code>text = &quot;床前明月光&quot;

&quot;&quot;&quot; 调用DNN语言模型 &quot;&quot;&quot;
client.dnnlm(text);
</code></pre><ul>
<li>DNN语言模型 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>文本内容（GBK编码），最大512字节，不需要切词  </td>
</tr>
</tbody>
</table>
<ul>
<li>DNN语言模型 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>uint64</td>
<td>请求唯一标识码</td>
</tr>
<tr>
<td>word</td>
<td>string</td>
<td>句子的切词结果</td>
</tr>
<tr>
<td>prob</td>
<td>float</td>
<td>该词在句子中的概率值,取值范围[0,1]</td>
</tr>
<tr>
<td>ppl</td>
<td>float</td>
<td>描述句子通顺的值：数值越低，句子越通顺</td>
</tr>
</tbody>
</table>
<pre><code>{
  &quot;text&quot;: &quot;床前明月光&quot;,
  &quot;items&quot;: [
    {
      &quot;word&quot;: &quot;床&quot;,
      &quot;prob&quot;: 0.0000385273
    },
    {
      &quot;word&quot;: &quot;前&quot;,
      &quot;prob&quot;: 0.0289018
    },
    {
      &quot;word&quot;: &quot;明月&quot;,
      &quot;prob&quot;: 0.0284406
    },
    {
      &quot;word&quot;: &quot;光&quot;,
      &quot;prob&quot;: 0.808029
    }
  ],
  &quot;ppl&quot;: 79.0651
}  
</code></pre><p><strong>词义相似度</strong></p>
<p>输入两个词，得到两个词的相似度结果。</p>
<pre><code>word1 = &quot;北京&quot;

word2 = &quot;上海&quot;

&quot;&quot;&quot; 调用词义相似度 &quot;&quot;&quot;
client.wordSimEmbedding(word1, word2);

&quot;&quot;&quot; 如果有可选参数 &quot;&quot;&quot;
options = {}

&quot;&quot;&quot; 带参数调用词义相似度 &quot;&quot;&quot;
client.wordSimEmbedding(word1, word2, options)
</code></pre><ul>
<li>词义相似度 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>word_1</td>
<td>是</td>
<td>string</td>
<td>词1（GBK编码），最大64字节</td>
</tr>
<tr>
<td>word_2</td>
<td>是</td>
<td>string</td>
<td>词1（GBK编码），最大64字节  </td>
</tr>
</tbody>
</table>
<ul>
<li>词义相似度 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>描述  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>number</td>
<td>请求唯一标识码,随机数</td>
</tr>
<tr>
<td>score</td>
<td>number</td>
<td>相似度分数</td>
</tr>
<tr>
<td>words</td>
<td>array</td>
<td>输入的词列表</td>
</tr>
<tr>
<td>+word_1</td>
<td>string</td>
<td>输入的word1参数</td>
</tr>
<tr>
<td>+word_2</td>
<td>string</td>
<td>输入的word2参数  </td>
</tr>
</tbody>
</table>
<ul>
<li><p>词义相似度 返回示例    </p>
<pre><code>{
    &quot;score&quot;: 0.456862,
    &quot;words&quot;: {
    &quot;word_1&quot;: &quot;北京&quot;,
    &quot;word_2&quot;: &quot;上海&quot;
    }
}
</code></pre></li>
</ul>
<p><strong>短文本相似度</strong></p>
<p>短文本相似度接口用来判断两个文本的相似度得分。</p>
<pre><code>text1 = &quot;浙富股份&quot;

text2 = &quot;万事通自考网&quot;

&quot;&quot;&quot; 调用短文本相似度 &quot;&quot;&quot;
client.simnet(text1, text2);

&quot;&quot;&quot; 如果有可选参数 &quot;&quot;&quot;
options = {}
options[&quot;model&quot;] = &quot;CNN&quot;

&quot;&quot;&quot; 带参数调用短文本相似度 &quot;&quot;&quot;
client.simnet(text1, text2, options)
</code></pre><ul>
<li>短文本相似度 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>可选值范围</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text_1</td>
<td>是</td>
<td>string</td>
<td></td>
<td>待比较文本1（GBK编码），最大512字节</td>
</tr>
<tr>
<td>text_2</td>
<td>是</td>
<td>string</td>
<td></td>
<td>待比较文本2（GBK编码），最大512字节</td>
</tr>
<tr>
<td>model</td>
<td>否</td>
<td>string</td>
<td>BOW /CNN /GRNN</td>
<td>默认为”BOW”，可选”BOW”、”CNN”与”GRNN”  </td>
</tr>
</tbody>
</table>
<ul>
<li>短文本相似度 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>描述  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>number</td>
<td>请求唯一标识</td>
</tr>
<tr>
<td>score</td>
<td>number</td>
<td>两个文本相似度得分</td>
</tr>
<tr>
<td>texts</td>
<td>array</td>
<td>输入文本</td>
</tr>
<tr>
<td>+text_1</td>
<td>string</td>
<td>第一个短文本</td>
</tr>
<tr>
<td>+text_2</td>
<td>string</td>
<td>第二个短文本  </td>
</tr>
</tbody>
</table>
<ul>
<li><p>短文本相似度 返回示例</p>
<pre><code>{
    &quot;log_id&quot;: 12345,
    &quot;texts&quot;:{
    &quot;text_1&quot;:&quot;浙富股份&quot;,
    &quot;text_2&quot;:&quot;万事通自考网&quot;
    },
   &quot;score&quot;:0.3300237655639648 //相似度结果
},  
</code></pre></li>
</ul>
<p><strong>评论观点抽取</strong></p>
<p>评论观点抽取接口用来提取一条评论句子的关注点和评论观点，并输出评论观点标签及评论观点极性。</p>
<pre><code>text = &quot;三星电脑电池不给力&quot;

&quot;&quot;&quot; 调用评论观点抽取 &quot;&quot;&quot;
client.commentTag(text);

&quot;&quot;&quot; 如果有可选参数 &quot;&quot;&quot;
options = {}
options[&quot;type&quot;] = 13

&quot;&quot;&quot; 带参数调用评论观点抽取 &quot;&quot;&quot;
client.commentTag(text, options)
</code></pre><ul>
<li>评论观点抽取 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>可选值范围</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td></td>
<td>评论内容（GBK编码），最大10240字节</td>
</tr>
<tr>
<td>type</td>
<td>否</td>
<td>string</td>
<td>1 - 酒店 2 - KTV 3 - 丽人 4 - 美食餐饮 5 - 旅游 6 - 健康 7 - 教育 8 - 商业 9 - 房产 10 - 汽车 11 - 生活 12 - 购物 13 - 3C</td>
<td>评论行业类型，默认为4（餐饮美食）</td>
</tr>
</tbody>
</table>
<ul>
<li>评论观点抽取 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>uint64</td>
<td>请求唯一标识码</td>
</tr>
<tr>
<td>prop</td>
<td>string</td>
<td>匹配上的属性词</td>
</tr>
<tr>
<td>adj</td>
<td>string</td>
<td>匹配上的描述词</td>
</tr>
<tr>
<td>sentiment</td>
<td>int</td>
<td>该情感搭配的极性（0表示消极，1表示中性，2表示积极）</td>
</tr>
<tr>
<td>begin_pos</td>
<td>int</td>
<td>该情感搭配在句子中的开始位置</td>
</tr>
<tr>
<td>end_pos</td>
<td>int</td>
<td>该情感搭配在句子中的结束位置</td>
</tr>
<tr>
<td>abstract</td>
<td>string</td>
<td>对应于该情感搭配的短句摘要</td>
</tr>
</tbody>
</table>
<ul>
<li><p>评论观点抽取 返回示例</p>
<pre><code>{
    &quot;items&quot;: [
    {
    &quot;prop&quot;:&quot;电池&quot;,
    &quot;adj&quot;: &quot;不给力&quot;,
    &quot;sentiment&quot;: 0,
    &quot;begin_pos&quot;: 8,
    &quot;end_pos&quot;: 18,
    &quot;abstract&quot;:&quot;三星电脑&lt;span&gt;电池不给力&lt;/span&gt;&quot;
    }
    ]
}  
</code></pre></li>
</ul>
<p><strong>情感倾向分析</strong></p>
<p>对包含主观观点信息的文本进行情感极性类别（积极、消极、中性）的判断，并给出相应的置信度。</p>
<pre><code>text = &quot;苹果是一家伟大的公司&quot;

&quot;&quot;&quot; 调用情感倾向分析 &quot;&quot;&quot;
client.sentimentClassify(text);
</code></pre><ul>
<li>情感倾向分析 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>文本内容（GBK编码），最大2048字节  </td>
</tr>
</tbody>
</table>
<ul>
<li>情感倾向分析 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>是否必须</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>输入的文本内容</td>
</tr>
<tr>
<td>items</td>
<td>是</td>
<td>array</td>
<td>输入的词列表</td>
</tr>
<tr>
<td>+sentiment</td>
<td>是</td>
<td>number</td>
<td>表示情感极性分类结果, 0:负向，1:中性，2:正向</td>
</tr>
<tr>
<td>+confidence</td>
<td>是</td>
<td>number</td>
<td>表示分类的置信度</td>
</tr>
<tr>
<td>+positive_prob</td>
<td>是</td>
<td>number</td>
<td>表示属于积极类别的概率</td>
</tr>
<tr>
<td>+negative_prob</td>
<td>是</td>
<td>number</td>
<td>表示属于消极类别的概率</td>
</tr>
</tbody>
</table>
<ul>
<li><p>情感倾向分析 返回示例</p>
<pre><code>{
    &quot;text&quot;:&quot;苹果是一家伟大的公司&quot;,
    &quot;items&quot;:[
    {
    &quot;sentiment&quot;:2,//表示情感极性分类结果
    &quot;confidence&quot;:0.40, //表示分类的置信度
    &quot;positive_prob&quot;:0.73, //表示属于积极类别的概率
    &quot;negative_prob&quot;:0.27  //表示属于消极类别的概率
    }
    ]
}
</code></pre></li>
</ul>
<p><strong>文章标签</strong> </p>
<p>文章标签服务能够针对网络各类媒体文章进行快速的内容理解，根据输入含有标题的文章，输出多个内容标签以及对应的置信度，用于个性化推荐、相似文章聚合、文本内容分析等场景。</p>
<pre><code>title = &quot;iphone手机出现“白苹果”原因及解决办法，用苹果手机的可以看下&quot;

content = &quot;如果下面的方法还是没有解决你的问题建议来我们门店看下成都市锦江区红星路三段99号银石广场24层01室。&quot;

&quot;&quot;&quot; 调用文章标签 &quot;&quot;&quot;
client.keyword(title, content);
</code></pre><ul>
<li>文章标签 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>title</td>
<td>是</td>
<td>string</td>
<td>篇章的标题，最大80字节</td>
</tr>
<tr>
<td>content</td>
<td>是</td>
<td>string</td>
<td>篇章的正文，最大65535字节  </td>
</tr>
</tbody>
</table>
<ul>
<li>文章标签 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>是否必选</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>items</td>
<td>是</td>
<td>array(object)</td>
<td>关键词结果数组，每个元素对应抽取到的一个关键词</td>
</tr>
<tr>
<td>+tag</td>
<td>是</td>
<td>string</td>
<td>关注点字符串</td>
</tr>
<tr>
<td>+score</td>
<td>是</td>
<td>number</td>
<td>权重(取值范围0~1)  </td>
</tr>
</tbody>
</table>
<ul>
<li>文章标签 返回示例</li>
</ul>
<pre><code>{
    &quot;log_id&quot;: 4457308639853058292,
    &quot;items&quot;: [
    {
        &quot;score&quot;: 0.997762,
        &quot;tag&quot;: &quot;iphone&quot;
    },
    {
        &quot;score&quot;: 0.861775,
        &quot;tag&quot;: &quot;手机&quot;
    },
    {
        &quot;score&quot;: 0.845657,
        &quot;tag&quot;: &quot;苹果&quot;
    },
    {
        &quot;score&quot;: 0.83649,
        &quot;tag&quot;: &quot;苹果公司&quot;
    },
    {
        &quot;score&quot;: 0.797243,
        &quot;tag&quot;: &quot;数码&quot;
    }
    ]
}  
</code></pre><p><strong>文章分类</strong>  </p>
<p>对文章按照内容类型进行自动分类，首批支持娱乐、体育、科技等26个主流内容类型，为文章聚类、文本内容分析等应用提供基础技术支持。</p>
<pre><code>title = &quot;欧洲冠军杯足球赛&quot;

content = &quot;欧洲冠军联赛是欧洲足球协会联盟主办的年度足球比赛，代表欧洲俱乐部足球最高荣誉和水平，被认为是全世界最高素质、最具影响力以及最高水平的俱乐部赛事，亦是世界上奖金最高的足球赛事和体育赛事之一。&quot;

&quot;&quot;&quot; 调用文章分类 &quot;&quot;&quot;
client.topic(title, content);
</code></pre><ul>
<li>文章分类 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>title</td>
<td>是</td>
<td>string</td>
<td>篇章的标题，最大80字节</td>
</tr>
<tr>
<td>content</td>
<td>是</td>
<td>string</td>
<td>篇章的正文，最大65535字节</td>
</tr>
</tbody>
</table>
<ul>
<li>文章分类 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>详细说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>item</td>
<td>object</td>
<td>分类结果，包含一级与二级分类</td>
</tr>
<tr>
<td>+lv1_tag_list</td>
<td>array of objects</td>
<td>一级分类结果</td>
</tr>
<tr>
<td>+lv2_tag_list</td>
<td>array of objects</td>
<td>二级分类结果</td>
</tr>
<tr>
<td>++score</td>
<td>float</td>
<td>类别标签对应得分，范围0-1</td>
</tr>
<tr>
<td>++tag</td>
<td>string</td>
<td>类别标签</td>
</tr>
</tbody>
</table>
<ul>
<li><p>文章分类 返回示例</p>
<pre><code>{
    &quot;log_id&quot;: 5710764909216517248,
    &quot;item&quot;: {
    &quot;lv2_tag_list&quot;: [
    {
    &quot;score&quot;: 0.895467,
    &quot;tag&quot;: &quot;足球&quot;
    },
    {
    &quot;score&quot;: 0.794878,
    &quot;tag&quot;: &quot;国际足球&quot;
    }
    ],
    &quot;lv1_tag_list&quot;: [
    {
    &quot;score&quot;: 0.88808,
    &quot;tag&quot;: &quot;体育&quot;
    }
    ]
    }
}
</code></pre></li>
</ul>
<p>错误信息</p>
<p><strong>错误返回格式</strong>  </p>
<p>若请求错误，服务器将返回的JSON文本包含以下参数：</p>
<ul>
<li>error_code：错误码。</li>
<li>error_msg：错误描述信息，帮助理解和解决发生的错误。  </li>
</ul>
<p><strong>错误码</strong>  </p>
<table>
<thead>
<tr>
<th>错误码</th>
<th>错误信息</th>
<th>描述  </th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>Open api request limit reached</td>
<td>集群超限额</td>
</tr>
<tr>
<td>14</td>
<td>IAM Certification failed</td>
<td>IAM鉴权失败，建议用户参照文档自查生成sign的方式是否正确，或换用控制台中ak sk的方式调用</td>
</tr>
<tr>
<td>17</td>
<td>Open api daily request limit reached</td>
<td>每天流量超限额</td>
</tr>
<tr>
<td>18</td>
<td>Open api qps request limit reached</td>
<td>QPS超限额</td>
</tr>
<tr>
<td>19</td>
<td>Open api total request limit reached</td>
<td>请求总量超限额</td>
</tr>
<tr>
<td>100</td>
<td>Invalid parameter</td>
<td>无效参数</td>
</tr>
<tr>
<td>110</td>
<td>Access token invalid or no longer valid</td>
<td>Access Token失效</td>
</tr>
<tr>
<td>111</td>
<td>Access token expired</td>
<td>Access token过期</td>
</tr>
<tr>
<td>282000</td>
<td>internal error</td>
<td>服务器内部错误，请再次请求， 如果持续出现此类错误，请通过QQ群（632426386）或工单联系技术支持团队。</td>
</tr>
<tr>
<td>282002</td>
<td>input encoding error</td>
<td>编码错误，请使用GBK编码</td>
</tr>
<tr>
<td>282004</td>
<td>invalid parameter(s)</td>
<td>请求中包含非法参数，请检查后重新尝试</td>
</tr>
<tr>
<td>282130</td>
<td>no result</td>
<td>当前查询无结果返回，出现此问题的原因一般为：参数配置存在问题，请检查后重新尝试</td>
</tr>
<tr>
<td>282131</td>
<td>input text too long</td>
<td>输入长度超限，请查看文档说明</td>
</tr>
<tr>
<td>282133</td>
<td>param {参数名} not exist</td>
<td>接口参数缺失</td>
</tr>
<tr>
<td>282300</td>
<td>word error</td>
<td>word不在算法词典中</td>
</tr>
<tr>
<td>282301</td>
<td>word_1 error</td>
<td>word_1提交的词汇暂未收录，无法比对相似度</td>
</tr>
<tr>
<td>282302</td>
<td>word_2 error</td>
<td>word_2提交的词汇暂未收录，无法比对相似度</td>
</tr>
<tr>
<td>282303</td>
<td>word_1&amp;word_2 error</td>
<td>word_1和word_2暂未收录，无法比对相似度</td>
</tr>
</tbody>
</table>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/刘晓_pynlpir/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/刘晓_pynlpir/" itemprop="url">pynlpir</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="http://ictclas.nlpir.org/" target="_blank" rel="noopener">http://ictclas.nlpir.org/</a></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>PyNLPIR是NLPIR / ICTCLAS中文分词软件的Python包装器<br>NLPIR汉语分词系统(又名ICTCLAS2013),主要功能包括中文分词；词性标注；命名实体识别；用户词典功能；支持GBK编码、UTF8编码、BIG5编码。新增微博分词、新词发现与关键词提取。<br>本文主要介绍Python版本—<a href="http://pynlpir.readthedocs.io/en/latest/" target="_blank" rel="noopener">PyNLPIR</a>  。</p>
<p>PyNLPIR允许使用NLPIR轻松地对中文文本进行分类，NLPIR是最受人们关注的中文文本分析器之一。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>PyNLPIR被设计为在Python 2.7或3上运行。由于包含了NLPIR库文件，它只能在Windows，GNU / Linux或macOS上运行。  </p>
<p><strong>Pip 安装：</strong>  </p>
<pre><code>$ pip install pynlpir
$ pynlpir update
</code></pre><p><strong>从源代码安装：</strong>  </p>
<p>如果你想手动安装PyNLPIR：  </p>
<ul>
<li>从<a href="https://pypi.org/project/PyNLPIR/" target="_blank" rel="noopener">https://pypi.org/project/PyNLPIR/</a>页面下载最新版本。</li>
<li>解压文件。</li>
<li>从目录PyNLPIR-XX中，运行python setup.py install</li>
<li>运行pynlpir 更新以下载最新的许可证文件。  </li>
</ul>
<p>这会在Python 站点包目录中安装PyNLPIR 。  </p>
<p><strong>安装开发版本：</strong>  </p>
<p><a href="https://github.com/tsroten/pynlpir" target="_blank" rel="noopener">PyNLPIR的代码</a>托管在GitHub上。首先安装开发版，确保安装了Git 。然后运行：  </p>
<pre><code>$ git clone git：//github.com/tsroten/pynlpir.git
$ pip install -e pynlpir
$ pynlpir update
</code></pre><p>这会将PyNLPIR目录链接到你的站点包 目录。pynlpir 更新将从NLPIR项目下载最新的许可证。  </p>
<p><strong>运行测试：</strong>  </p>
<p>运行测试很容易。下载并解压缩PyNLPIR的源代码后，从PyNLPIR的源代码目录中运行以下代码：</p>
<pre><code>$ python setup.py 测试  
</code></pre><p>如果要使用不同版本的Python运行测试，请安装并运行tox：</p>
<pre><code>$ pip安装tox
 $ tox
</code></pre><h2 id="使用教程"><a href="#使用教程" class="headerlink" title="使用教程"></a>使用教程</h2><p>有两种使用PyNLPIR的方法：直接使用PyNLPIR提供的ctypes接口或使用PyNLPIR的辅助函数。该ctypes的界面更广泛，更严格。辅助函数很容易使用，但不提供对每个NLPIR函数的访问。也可以使用这两种方法的混合。首先，让我们看看辅助函数。  </p>
<p><strong>PyNLPIR助手函数</strong><br>辅助函数位于PyNLPIR的<strong>init</strong>.py文件中，因此可以通过直接导入pynlpir来访问它们。</p>
<p><strong>初始化NLPIR</strong><br>导入PyNLPIR会自动加载NLPIR API库：  </p>
<pre><code>import pynlpir  
</code></pre><p>一旦它被导入，调用open（）来告诉NLPIR打开数据文件并初始化API。有关指定其他数据目录的信息，请参阅open（）的文档。  </p>
<pre><code>pynlpir.open()  
</code></pre><p>默认情况下，输入被假定为unicode或UTF-8编码。如果您想使用不同的编码（例如GBK或BIG5），请在调用open（）时使用encoding关键字参数：  </p>
<pre><code>pynlpir.open(encoding=&apos;big5&apos;)  
#Tip:无论指定什么编码，都可以将unicode字符串传递给 pynlpir函数。  
</code></pre><p>PyNLPIR的辅助函数总是返回unicode字符串。<br>一旦初始化了NLPIR，就可以开始分割和分析文本。   </p>
<p><strong>细分文本：</strong><br>让我们分段一个冗长的句子：   </p>
<pre><code>s = &apos;NLPIR分词系统前身为2000年发布的ICTCLAS词法分析系统，从2009年开始，为了和以前工作进行大的区隔，并推广NLPIR自然语言处理与信息检索共享平台，调整命名为NLPIR分词系统。&apos;
pynlpir.segment(s)

# Sample output: [(&apos;NLPIR&apos;, &apos;noun&apos;), (&apos;分词&apos;, &apos;verb&apos;), (&apos;系统&apos;, &apos;noun&apos;), (&apos;前身&apos;, &apos;noun&apos;), (&apos;为&apos;, &apos;preposition&apos;), (&apos;2000年&apos;, &apos;time word&apos;), (&apos;发布&apos;, &apos;verb&apos;), . . . ]
</code></pre><p>如果不想词性标注，segment（）中的参数pos_tagging设置为False：</p>
<pre><code>pynlpir.segment(s, pos_tagging=False)

# Sample output: [&apos;NLPIR&apos;, &apos;分词&apos;, &apos;系统&apos;, &apos;前身&apos;, &apos;为&apos;, &apos;2000年&apos;, &apos;发布&apos;, . . . ]  
</code></pre><p>还可以自定义如何显示词性标签。默认情况下，只使用最通用的词性名称部分，即父母（例如 ‘名词’，而不是’转录地名’）。如果希望使用最具体的演讲名称部分，即儿童，请将pos_names设置 为’child’：  </p>
<pre><code>pynlpir.segment(s, pos_names=&apos;child&apos;)
</code></pre><p>如果你想要了解关于词性标签的更多信息，你可以设置 pos_names为’all’，并且返回一个词性层次结构（例如， ‘noun：toponym：transcribed toponym’）：  </p>
<pre><code>pynlpir.segment(s, pos_names=&apos;all&apos;)
</code></pre><p>默认情况下，词性标记以英语返回。如果您希望看到中文（例如’名词’而不是’名词’），请将pos_english设置为False：  </p>
<pre><code>pynlpir.segment(s, pos_english=False)  
</code></pre><p><strong>获取关键词:</strong><br>另一个有用的函数是get_key_words（）：</p>
<pre><code>pynlpir.get_key_words(s, weighted=True)
[(&apos;NLPIR&apos;, 2.08), (&apos;系统&apos;, 1.74)]  
</code></pre><p>get_key_words（）分析给定的中文文本字符串并返回NLPIR认为关键字的单词。如果权重为 True，则关键字的权重也作为浮点数返回。  </p>
<p><strong>关闭API:</strong><br>现在我们已经看了PyNLPIR辅助函数的简要介绍，让我们看看如何关闭API。</p>
<p>当使用PyNLPIR时，你可以通过调用close（）来释放分配的内存 ：  </p>
<pre><code>pynlpir.close()    
</code></pre><p><strong>ctypes NLPIR接口:</strong>  </p>
<p>pynlpir.nlpir通过 ctypes提供对NLPIR’C函数的访问。你可以直接调用它们，而不用担心上面的辅助函数。这些函数的工作方式与C语言的对应函数几乎完全相同。</p>
<p>pynlpir.nlpir包含由NLPIR导出的调用其许多函数（例如编码和词性常量）所需的模块级常量。有关更多信息，请参阅 pynlpir.nlpir上的API页面。</p>
<p>以下各节不提供关于如何使用NLPIR的全面说明。NLPIR有它自己的文档。以下部分提供了有关如何开始使用PyNLPIR的基本信息，前提是您熟悉NLPIR。如果你不是，请务必查看下面链接的文档。  </p>
<p><strong>分词与词性标注示例：</strong><br>需要注意的是，使用pynlpir的时候，首先要初始化，也就是需要先open（pynlpir.open()），当执行完成后需要对应的关闭（pynlpir.close()）<br>代码示例：</p>
<pre><code># coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( &quot;utf-8&quot; )

import pynlpir

pynlpir.open()
s = &apos;因为我比较懒,所以我就只是修改了这句话,代码还是原博客的&apos;
segments = pynlpir.segment(s)
for segment in segments:
     print segment[0], &apos;\t&apos;, segment[1]

pynlpir.close()  
</code></pre><p>运行结果:  </p>
<pre><code>因为  preposition
我   pronoun
比较  adverb
懒   adjective
,   punctuation mark
所以  conjunction
我   pronoun
就   adverb
只   adverb
是   verb
修改  verb
了   particle
这   pronoun
句   classifier
话   noun
,   punctuation mark
代码  noun
还   adverb
是   verb
原   distinguishing word
博客  noun
的   particle

Process finished with exit code 0  
</code></pre><p>NLPIR还可以更加详细的输出词性信息，做如下修改：</p>
<pre><code>segments = pynlpir.segment(s)
改为：
segments = pynlpir.segment(s,pos_names=&apos;all&apos;)
你可以在segment时同时配置如下参数，调整结果，请自行选择：
pos_names=&apos;all&apos; / &apos;child&apos; / &apos;parent&apos; #默认是parent， 表示获取该词性的最顶级词性，child表示获取该词性的最具体的信息，all表示获取该词性相关的所有词性信息，相当于从其顶级词性到该词性的一条路径
pos_english=False # 词性标注结果以中文的形式显示
pos_tagging=False # 只做分词，而不显示词性
</code></pre><p>运行后可以得到更加详细的结果：</p>
<pre><code>因为  preposition
我   pronoun:personal pronoun
比较  adverb
懒   adjective
,   punctuation mark:comma
所以  conjunction
我   pronoun:personal pronoun
就   adverb
只   adverb
是   verb:verb 是
修改  verb
了   particle:particle 了/喽
这   pronoun:demonstrative pronoun:predicate demonstrative pronoun
句   classifier
话   noun
,   punctuation mark:comma
代码  noun
还   adverb
是   verb:verb 是
原   distinguishing word
博客  noun:other proper noun
的   particle:particle 的/底  
</code></pre><p><strong>关键词提取代码：</strong></p>
<pre><code># coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( &quot;utf-8&quot; )

import pynlpir

pynlpir.open()
s = &apos;因为我比较懒,所以我就只是修改了这句话,代码还是原博客的&apos;
print &apos;关键词测试:\n&apos;
key_words = pynlpir.get_key_words(s, weighted=True)
for key_word in key_words:
    print key_word[0], &apos;\t&apos;, key_word[1]

pynlpir.close()
</code></pre><p>运行后提取出来的关键词应该是：</p>
<pre><code>关键词测试:

修改  2.0
代码  2.0
博客  2.0

Process finished with exit code 0
</code></pre><p>本篇工具介绍参考：<br><a href="https://blog.csdn.net/MebiuW/article/details/52232562?locationNum=12" target="_blank" rel="noopener">https://blog.csdn.net/MebiuW/article/details/52232562?locationNum=12
</a><br><a href="http://www.shareditor.com/blogshow/?blogId=74" title="http://www.shareditor.com/blogshow/?blogId=74" target="_blank" rel="noopener">http://www.shareditor.com/blogshow/?blogId=74</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/刘晓_Keras/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/刘晓_Keras/" itemprop="url">Keras</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="https://keras.io/#installation" target="_blank" rel="noopener">https://keras.io/#installation</a>  </p>
<h2 id="Keras-简介"><a href="#Keras-简介" class="headerlink" title="Keras 简介"></a>Keras 简介</h2><p>Keras 最初是作为 ONEIROS 项目（开放式神经电子智能机器人操作系统）研究工作的一部分而开发的。Keras是一个高层神经网络API，纯Python编写而成并基Tensorflow、Theano以及CNTK后端。Keras 为支持快速实验而生，能够把你的idea迅速转换为结果，如果你有如下需求，请选择Keras：  </p>
<ul>
<li>简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性）  </li>
<li>支持CNN和RNN，或二者的结合  </li>
<li>无缝CPU和GPU切换  </li>
</ul>
<p>Keras适用的Python版本是：Python 2.7-3.6      </p>
<p><a href="https://keras.io/" target="_blank" rel="noopener">Keras官方英文文档</a>  </p>
<p><a href="https://keras.io/zh/" target="_blank" rel="noopener">Keras官方中文文档</a>  </p>
<p><a href="https://github.com/keras-team" target="_blank" rel="noopener">Keras GitHub</a></p>
<h2 id="Keras-安装"><a href="#Keras-安装" class="headerlink" title="Keras 安装"></a>Keras 安装</h2><p>在安装 Keras 之前，请安装以下后端引擎之一：TensorFlow，Theano，或者 CNTK。官方推荐 <strong>TensorFlow 后端</strong> 。  </p>
<ul>
<li><a href="https://www.tensorflow.org/install/" target="_blank" rel="noopener">TensorFlow 安装指引 </a> </li>
<li><a href="http://deeplearning.net/software/theano/install.html#install" target="_blank" rel="noopener">Theano 安装指引 </a> </li>
<li><a href="https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine" target="_blank" rel="noopener">CNTK 安装指引</a></li>
</ul>
<p>还可以考虑安装一下可选依赖：</p>
<ul>
<li>cuDNN (如果你计划在 GPU 上运行 Keras，建议安装)。  </li>
<li>HDF5 和 h5py (如果你需要将 Keras 模型保存到磁盘，则需要这些)。  </li>
<li>graphviz 和 pydot (被可视化工具用来绘制模型图)。  </li>
</ul>
<p><strong>安装 Keras</strong>  ，有两种方法：  </p>
<ol>
<li><p>使用 PyPI 安装 Keras (推荐)  </p>
<pre><code>sudo pip install keras  
pip install keras   # virtualenv 虚拟环境下
</code></pre></li>
</ol>
<ol>
<li><p>使用 Github 源码安装 Keras：<br>使用 git 来克隆 Keras：</p>
<pre><code>git clone https://github.com/keras-team/keras.git    
</code></pre></li>
</ol>
<p>然后，cd 到 Keras 目录并且运行安装命令：  </p>
<pre><code>cd keras  
sudo python setup.py install  
</code></pre><h2 id="Keras-快速使用"><a href="#Keras-快速使用" class="headerlink" title="Keras 快速使用"></a>Keras 快速使用</h2><p>Keras 的核心数据结构是 model，一种组织网络层的方式。最简单的模型是 <strong>Sequential</strong> 顺序模型，它是由多个网络层线性堆叠的栈。对于更复杂的结构，应该使用 Keras 函数式 API，它允许构建任意的神经网络图。<br><strong>Sequential </strong>顺序模型如下所示：  </p>
<pre><code>from keras.models import Sequential  
model = Sequential()  
</code></pre><p>可以简单地使用 .add() 来堆叠模型：  </p>
<pre><code>from keras.layers import Dense
model.add(Dense(units=64, activation=&apos;relu&apos;, input_dim=100))
model.add(Dense(units=10, activation=&apos;softmax&apos;))  
</code></pre><p>在完成了模型的构建后, 可以使用 .compile() 来配置学习过程：  </p>
<pre><code>model.compile(loss=&apos;categorical_crossentropy&apos;, optimizer=&apos;sgd&apos;, metrics=[&apos;accuracy&apos;])  
</code></pre><p>如果需要，你还可以进一步地配置优化器。Keras 的一个核心原则是使事情变得相当简单，同时又允许用户在需要的时候能够进行完全的控制（终极的控制是源代码的易扩展性）。</p>
<pre><code>model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))    
</code></pre><p>现在，你可以批量地在训练数据上进行迭代了：  </p>
<pre><code># x_train 和 y_train 是 Numpy 数组 -- 就像在 Scikit-Learn API 中一样。
model.fit(x_train, y_train, epochs=5, batch_size=32)
</code></pre><p>或者，你可以手动地将批次的数据提供给模型：</p>
<pre><code>model.train_on_batch(x_batch, y_batch)    
</code></pre><p>只需一行代码就能评估模型性能：</p>
<pre><code>loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)    
</code></pre><p>或者对新的数据生成预测：</p>
<pre><code>classes = model.predict(x_test, batch_size=128)    
</code></pre><p>构建一个问答系统，一个图像分类模型，一个神经图灵机，或者其他的任何模型，就是这么的快。</p>
<h2 id="相关例子"><a href="#相关例子" class="headerlink" title="相关例子"></a>相关例子</h2><p>在Keras代码包的examples文件夹中，你将找到使用真实数据的示例模型：</p>
<ul>
<li>CIFAR10 小图片分类：使用CNN和实时数据提升  </li>
<li>IMDB 电影评论观点分类：使用LSTM处理成序列的词语  </li>
<li>Reuters（路透社）新闻主题分类：使用多层感知器（MLP）  </li>
<li>MNIST手写数字识别：使用多层感知器和CNN  </li>
<li>字符级文本生成：使用LSTM </li>
<li>基于多层感知器的softmax多分类：</li>
</ul>
<h2 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h2><p>涉及使用Keras实现的算法及论文后续补上</p>
<p><strong>小知识：</strong> Keras (κέρας) 在希腊语中意为 号角 。它来自古希腊和拉丁文学中的一个文学形象，首先出现于 《奥德赛》 中， 梦神 (Oneiroi, singular Oneiros) 从这两类人中分离出来：那些用虚幻的景象欺骗人类，通过象牙之门抵达地球之人，以及那些宣告未来即将到来，通过号角之门抵达之人。 它类似于文字寓意，κέρας (号角) / κραίνω (履行)，以及 ἐλέφας (象牙) / ἐλεφαίρομαι (欺骗)。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CNLR</p>
              <p class="site-description motion-element" itemprop="description">语料库、数据集及工具资源和教程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">46</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CNLR</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
