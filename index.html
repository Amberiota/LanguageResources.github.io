<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="语料库、数据集及工具资源和教程">
<meta property="og:type" content="website">
<meta property="og:title" content="世界语言资源平台">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="世界语言资源平台">
<meta property="og:description" content="语料库、数据集及工具资源和教程">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="世界语言资源平台">
<meta name="twitter:description" content="语料库、数据集及工具资源和教程">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>世界语言资源平台</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">世界语言资源平台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/05/刘晓_FigureQA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/05/刘晓_FigureQA/" itemprop="url">FigureQA</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-05T19:45:00+05:00">
                2018-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>下载地址：<a href="https://datasets.maluuba.com/FigureQA/dl" target="_blank" rel="noopener">https://datasets.maluuba.com/FigureQA/dl</a>  </p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Maluuba推出了一个用于推理的可视化数据集FigureQA，并将研究相关论文《FigureQA: An Annotated Figure Dataset for Visual Reasoning》发布在ArXiv上。  </p>
<p>在关系推理最新研究的启发下，研究人员推出了FigureQA数据集，其中包含了基于10多张图表的100多万对问答，用于研究机器理解和推理方面的问题。</p>
<p>FigureQA数据集中有五种常见的图表模型，这些图表能显示连续的和分类信息，分别为折线图、点图、垂直柱状图、水平条形图和饼图。而其中的问答对，会涉及到图表中元素一对一和一对多的关系，例如：X是中位数吗？X与Y相交吗？得出正确答案需要对多图表中的要素进行推理。</p>
<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><ul>
<li><strong>数据集中包含的5种图表类型</strong></li>
</ul>
<p>数据集中的问题，共有15种类型，涉及到数值大小、最大值、最小值、中值、曲线下面积、平滑度和图像交叉点等信息。<br><img src="https://i.loli.net/2018/05/05/5aedabece531f.jpg" alt=""></p>
<ul>
<li><strong>FigureQA中包含的15类问题</strong></li>
</ul>
<p>问答集中问题均基于上述问题，答案统一为“是”或“否”。<br><img src="https://i.loli.net/2018/05/05/5aedac1a6045c.jpg" alt=""></p>
<ul>
<li><strong>数据集以问答的形式呈现</strong>。<br>Q：Medium Seafoam和Light Gold相交吗？<br>A：是。<br>Q：Medium Seafoam是否有最低值？<br>A：否</li>
</ul>
<p>微软团队在介绍论文中表示：“FigureQA是一个合成的数据集，类似视觉推理相关的CLEVR数据集。虽然数据没有真实环境中那么丰富，但能更大程度控制任务的复杂性，还支持辅助监管信号。此外，通过分析在FigureQA上训练的模型真实数据，还能扩展语料库处理弱项问题。”  </p>
<h1 id="制作过程"><a href="#制作过程" class="headerlink" title="制作过程"></a>制作过程</h1><p>FigureQA数据集的生成制作分阶段进行。</p>
<p>首先，研究人员根据一组经过仔细调整的约束和启发式设计对数值数据进行采样，让使取样数据显得更自然。随后，研究人员用开源可视化库Bokeh绘制图表中的数据，得到定量数据。</p>
<p>此外，研究人员修改了所有图表的Bokeh后端输出的边界信息：包括数据点、坐标轴、坐标轴标签、标记和图注等信息。他们还提供了底层数值数据和一组边界数据作为每张图表的补充信息。</p>
<p>最后，研究人员平衡了每个问题答案中“是”和“否”的比例，这保证模型不会利用回答频率上的偏差来推断结果，而忽略视觉内容。</p>
<h1 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h1><p>在论文中，研究人员表示，FigureQA中测试集的准确率还达不到人类水平。接下来，研究人员计划测试在FigureQA上训练的模型在真实科学数据上的表现，并将数据集扩展到人类编写的自然语言问题上。FigureQA“官方”版的数据集可公开使用，是未来研究的基准。</p>
<p><strong>数据集与人类回答15种问题的准确性对比</strong></p>
<p>研究人员还提供了生成脚本，它们配置容易，使用户能调整生成参数生成自己数据。  </p>
<p>关于FigureQA的介绍我们可以在ArXiv上一探究竟：</p>
<p><a href="https://arxiv.org/abs/1710.07300" target="_blank" rel="noopener">https://arxiv.org/abs/1710.07300</a>  </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Samira Ebrahimi Kahou, Vincent Michalski, Adam Atkinson, Akos Kadar, Adam Trischler, Yoshua Bengio FigureQA: An Annotated Figure Dataset for Visual Reasoning 2017.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/05/刘晓_BIT-Vehicle Dataset/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/05/刘晓_BIT-Vehicle Dataset/" itemprop="url">BIT-Vehicle数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-05T19:45:00+05:00">
                2018-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>下载地址: <a href="http://iitlab.bit.edu.cn/mcislab/vehicledb/" target="_blank" rel="noopener">http://iitlab.bit.edu.cn/mcislab/vehicledb/</a>  </p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>BIT-Vehicle数据集包含9,850个车辆图像。图片中有1600<em>1200和1920</em>1080的图像，它们分别在不同时间和地点的两个摄像头拍摄。这些图像包含了光照条件、尺度、车辆表面颜色和视点的变化。由于捕获延迟和车辆的大小，一些车辆的顶部或底部部分不包括在图像中。在一个图像中可能有一或两辆车，所以每辆车的位置都是预先标注的。数据集也可以用来评估性能。</p>
<h1 id="数据集内容"><a href="#数据集内容" class="headerlink" title="数据集内容"></a>数据集内容</h1><p>6车辆类型，9850张图片  【<a href="http://iitlab.bit.edu.cn/mcislab/vehicledb/startRequestDb.php" target="_blank" rel="noopener">Download</a>】  </p>
<p><img src="https://i.loli.net/2018/05/05/5aedb15d757c9.jpg" alt=""></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] DONG Zhen, WU Yuwei, PEI Mingtao, and JIA Yunde. Vehicle Type Classification Using a Semisupervised Convolutional Neural Network. IEEE Transactions on Intelligent Transportation Systems (T-ITS), 2015(in press).<br>[2] DONG Zhen, PEI Mingtao, HE Yang, LIU Ting, DONG Yanmei, and JIA Yunde. Vehicle Type Classification Using Unsupervised Convolutional Neural Network. IEEE International Conference on Pattern Recognition (ICPR), 2014.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/05/刘晓_SVHN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/05/刘晓_SVHN/" itemprop="url">SVHN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-05T19:45:00+05:00">
                2018-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>下载地址：<a href="http://ufldl.stanford.edu/housenumbers/" target="_blank" rel="noopener">http://ufldl.stanford.edu/housenumbers/</a> </p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>The Street View House Numbers (SVHN) 是一个用于开发机器学习和对象识别算法的真实世界图像数据集，对数据预处理和格式化的要求最低。它可以被视为与MNIST相似(例如，图像是小的被裁剪的数字)，但是合并了一个数量级更多的标签数据(超过60万数字图像)，并且来自一个更加困难的，未解决的，真实的世界问题(在自然场景图像中识别数字和数字)。SVHN是在谷歌街景图片中获得的。</p>
<h1 id="数据集详情"><a href="#数据集详情" class="headerlink" title="数据集详情"></a>数据集详情</h1><table>
<thead>
<tr>
<th>name</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>原始数据名称:</td>
<td>The Street View House Numbers 数据集  </td>
</tr>
<tr>
<td>数据介绍:</td>
<td>The Street View House Numbers (SVHN) 是对图像中阿拉伯数字进行识别的数据集，改数据集中的图像来自真实世界的门牌号数字，图像来自Google街景中所拍摄的门牌号图片，每张图片中包含一组 ‘0-9’ 的阿拉伯数字。训练集中包含 73257 个数字，测试集中包含 26032 个数字，另有 531131 个附加数字。    </td>
</tr>
<tr>
<td>数据来源:</td>
<td><a href="http://ufldl.stanford.edu/housenumbers/" target="_blank" rel="noopener">http://ufldl.stanford.edu/housenumbers/</a></td>
</tr>
<tr>
<td>文件大小:</td>
<td>2.45 Gb</td>
</tr>
<tr>
<td>记录数量：</td>
<td>6,30,420张图片被分布在10个类中。</td>
</tr>
<tr>
<td>SOTA：</td>
<td>虚拟对抗训练的分布平滑</td>
</tr>
<tr>
<td>格式：</td>
<td>1。具有字符级边框的原始图像。2。像mnist一样的32×32的图像以一个字符为中心(许多图像都包含一些干扰)。</td>
</tr>
</tbody>
</table>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011.<br>[2] Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, Kilian Weinberger Deep Networks with Stochastic Depth 2016.<br>[3] Chen-Yu Lee, Saining Xie, Patrick Gallagher, Zhengyou Zhang, Zhuowen Tu  Deeply-Supervised Nets 2014.<br>[4] Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron Courville, Yoshua Bengio Maxout Networks<br>2013<br>[5] Min Lin, Qiang Chen, Shuicheng Yan Network In Network 2013.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/05/刘晓_Object Detection Evaluation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/05/刘晓_Object Detection Evaluation/" itemprop="url">Object Detection Evaluation</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-05T19:45:00+05:00">
                2018-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>下载地址：<a href="http://www.cvlibs.net/datasets/kitti/eval_object.php" target="_blank" rel="noopener">http://www.cvlibs.net/datasets/kitti/eval_object.php</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Object Detection Evaluation 2012，是一个车辆检测或者定位有关的数据集。<br>物体检测和物体方向估计基准包括7481个训练图像和7518个测试图像，共包含80.256个标记物体。所有图像都是彩色的，并保存为PNG。为了评估，我们计算物体检测和定位相似召回（orientation-similarity-recall）的精确回忆曲线，用于联合目标检测和方向估计。在后一种情况下，不仅要正确定位对象二维边界框，而且还要评估鸟瞰图中的方向估计值。为了对方法进行排序，我们计算平均精度和平均方向的相似度。我们要求所有方法对所有测试对使用相同的参数集。我们的开发工具包提供了有关数据格式的详细信息以及用于读取和写入标签文件的MATLAB / C ++实用程序函数。  </p>
<p>使用PASCAL标准和目标检测和方向估计性能评估目标检测性能，使用我们的CVPR 2012出版物中讨论的度量。对于汽车，我们要求重叠70%，而对于行人和骑自行车的人，我们需要50%的重叠来检测。在不关心的区域或探测中发现小于最小尺寸的探测，不被认为是假阳性。难点定义如下:   </p>
<ul>
<li>Easy: Min. bounding box height: 40 Px, Max. occlusion level: Fully visible, Max. truncation: 15 %  </li>
<li>Moderate: Min. bounding box height: 25 Px, Max. occlusion level: Partly occluded, Max. truncation: 30 %  </li>
<li>Hard: Min. bounding box height: 25 Px, Max. occlusion level: Difficult to see, Max. truncation: 50 %  </li>
</ul>
<p>所有的方法都基于中等难度的结果进行排名。值得注意的是，在被提供的边界框中，有2%的边界框没有被人类识别，因此在98%的情况下，上限的召回率为98%。因此，仅供参考。<br>注1:2017年4月25日，我们在对象检测评估脚本中修复了一个bug。到目前为止,提交检测过滤基于最小值边界框的高度为各自的类别,我们一直只做过检测地面真理,从而导致假阳性类别的“简单”25 - 39边界框的高度,Px提交时(为所有类别和假阳性如果边框小于25 Px提交)。<br>在<a href="http://www.cvlibs.net/datasets/kitti/backups/2017_04_23_01_47_47_object.html" target="_blank" rel="noopener">这里</a>可以找到更改之前的最后一个排行榜!  </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Andreas Geiger and Philip Lenz and Raquel Urtasun Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite  2012.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/05/刘唯_20newsgroups/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/05/刘唯_20newsgroups/" itemprop="url">20 newsgroups</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-05T19:11:00+05:00">
                2018-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>20newsgroups数据集是用于文本分类、文本挖据和信息检索研究的国际标准数据集之一。数据集收集了大约20,000左右的新闻组文档，均匀分为20个不同主题的新闻组集合。一些新闻组的主题特别相似(e.g. comp.sys.ibm.pc.hardware/ comp.sys.mac.hardware)，还有一些却完全不相关 (e.g misc.forsale /soc.religion.christian)。</p>
<p>20newsgroups数据集有三个版本。第一个版本19997是原始的并没有修改过的版本。第二个版本bydate是按时间顺序分为训练(60%)和测试(40%)两部分数据集，不包含重复文档和新闻组名（新闻组，路径，隶属于，日期）。第三个版本18828不包含重复文档，只有来源和主题。</p>
<p>20news-19997.tar.gz –原始20 Newsgroups数据集<br>20news-bydate.tar.gz –按时间分类; 不包含重复文档和新闻组名(18846 个文档)<br>20news-18828.tar.gz–  不包含重复文档，只有来源和主题 (18828 个文档)<br>在sklearn中，该模型有两种装载方式，第一种是sklearn.datasets.fetch_20newsgroups，返回一个可以被文本特征提取器（如sklearn.feature_extraction.text.CountVectorizer）自定义参数提取特征的原始文本序列；第二种是sklearn.datasets.fetch_20newsgroups_vectorized，返回一个已提取特征的文本序列，即不需要使用特征提取器。</p>
<h1 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h1><p><a href="http://qwone.com/~jason/20Newsgroups/20news-19997.tar.gz" target="_blank" rel="noopener">http://qwone.com/~jason/20Newsgroups/20news-19997.tar.gz</a><br><a href="http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz" target="_blank" rel="noopener">http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz</a><br><a href="http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz" target="_blank" rel="noopener">http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]David Pinto,Paolo Rosso. Text, Speech and Dialogue[M].Springer Berlin Heidelberg:2007-06-15.<br>[2]Fábio Figueiredo,Leonardo Rocha,Thierson Couto,Thiago Salles,Marcos André Gonçalves,Wagner Meira Jr.. Word co-occurrence features for text classification[J]. Information Systems,2011,36(5).<br>[3]Le Dong,Ning Feng,Pinjie Quan,Gaipeng Kong,Xiuyuan Chen,Qianni Zhang. Optimal kernel choice for domain adaption learning[J]. Engineering Applications of Artificial Intelligence,2016,51.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/05/刘唯_MSLR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/05/刘唯_MSLR/" itemprop="url">MSLR</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-05T19:04:00+05:00">
                2018-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>微软发布的两个规模较大的learning to rank数据集<br>MSLR-WEB30k 30，000个查询query<br>从其中随机采样10，000个形成mslr-web10k </p>
<h1 id="描述"><a href="#描述" class="headerlink" title="描述:"></a>描述:</h1><p>queries 和 urls 由ID来表示.<br>数据集包含了从q-u对中抽取的特征向量以及相关性评价标签<br>(1) 相关性评价来自于 Microsoft Bing,5分制， 从0 (不相关) 到 4 (最相关).</p>
<p>(2) 特征由作者抽取，基本上广泛用于研究社区<br>每行代表一个q-u对，第一栏是相关性分数，第2栏目是queryID,其他栏目是特征<br>The larger value the relevance label has, the more relevant the query-url pair is.<br>每个q-u 对由一个136维的特征向量表示</p>
<p>来自MSLR-WEB10K 的两个样本:</p>
<p>==============================================</p>
<p>0 qid:1 1:3 2:0 3:2 4:2 … 135:0 136:0</p>
<p>2 qid:1 1:3 2:3 3:0 4:0 … 135:0 136:0</p>
<p>==============================================</p>
<h1 id="数据集分割"><a href="#数据集分割" class="headerlink" title="数据集分割:"></a>数据集分割:</h1><p>分成5份一样大小的记为s1,….s5,用于交叉验证<br>建议3个用于训练，另外两个分别用于验证和测试<br>原文如下<br>We have partitioned each dataset into five parts with about the same number of queries, denoted as S1, S2, S3, S4, and S5, for five-fold cross validation. In each fold, we propose using three parts for training, one part for validation, and the remaining part for test (see the following table). The training set is used to learn ranking models. The validation set is used to tune the hyper parameters of the learning algorithms, such as the number of iterations in RankBoost and the combination coefficient in the objective function of Ranking SVM. The test set is used to evaluate the performance of the learned ranking models.</p>
<p> Folds  Training Set Validation Set Test Set<br> Fold1  {S1,S2,S3}  S4  S5<br> Fold2  {S2,S3,S4}  S5  S1<br> Fold3  {S3,S4,S5}  S1  S2<br> Fold4  {S4,S5,S1}  S2  S3<br> Fold5  {S5,S1,S2}  S3  S4</p>
<h1 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h1><p> <a href="https://www.microsoft.com/en-us/research/project/mslr/" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/project/mslr/</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Czernielewski J,Faure M,Schmitt D,Thivolet J. In vitro mixed skin cell lymphocyte culture reaction (MSLR) in man: analysis of the epidermal cell and T cell subpopulations.[J]. Clinical and Experimental Immunology,1982,50(2).<br>[2]Faure M,Czernielewski J,Schmitt D,Thivolet J. Mixed skin cell lymphocyte culture reaction (MSLR) in psoriasis.[J]. Journal of Dermatology,1983,10(6).<br>[3]Cochrum K C,Main R K,Kountz S L. A new matching technique: the mixed skin cell-leukocyte reaction, (MSLR).[J]. Surgery,1971,70(1).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/05/刘唯_moveslens/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/05/刘唯_moveslens/" itemprop="url">movieslens</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-05T18:59:00+05:00">
                2018-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>MovieLens数据集包含多个用户对多部电影的评级数据，也包括电影元数据信息和用户属性信息。</p>
<p>这个数据集经常用来做推荐系统，机器学习算法的测试数据集。尤其在推荐系统领域，很多著名论文都是基于这个数据集的。(PS: 它是某次具有历史意义的推荐系统竞赛所用的数据集)。</p>
<h1 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h1><p><a href="http://files.grouplens.org/datasets/movielens/" target="_blank" rel="noopener">http://files.grouplens.org/datasets/movielens/</a></p>
<h1 id="数据介绍"><a href="#数据介绍" class="headerlink" title="数据介绍"></a>数据介绍</h1><p>1m的数据解压后，可以看到四个主要的csv文件，分别是links.csv,movies.csv,ratings.csv,tags.csv。links介绍了该数据集中的movieId和imdb、tmdb中电影的对应关系。tags是用户的打标签数据。本文的介绍主要基于ratings.csv 和 movies.csv</p>
<p>ratings数据<br>文件里面的内容包含了每一个用户对于每一部电影的评分。数据格式如下：<br>userId, movieId, rating, timestamp<br>userId: 每个用户的id<br>movieId: 每部电影的id<br>rating: 用户评分，是5星制，按半颗星的规模递增(0.5 stars - 5 stars)<br>timestamp: 自1970年1月1日零点后到用户提交评价的时间的秒数<br>数据排序的顺序按照userId，movieId排列的。</p>
<p>movies数据<br>文件里包含了一部电影的id和标题，以及该电影的类别。数据格式如下：<br>movieId, title, genres<br>movieId:每部电影的id<br>title:电影的标题<br>genres:电影的类别（详细分类见readme.txt）</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Harmanjeet Kaur,Neeraj Kumar,Shalini Batra. An efficient multi-party scheme for privacy preserving collaborative filtering for healthcare recommender system[J]. Future Generation Computer Systems,2018.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/05/刘唯_Chars74K/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/05/刘唯_Chars74K/" itemprop="url">Chars74K</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-05T18:51:00+05:00">
                2018-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h1><p><a href="http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/" target="_blank" rel="noopener">http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Chars74K数据集是一个经典的字符识别数据集，主要包括了英文字符与坎那达语（Kannada）字符。数据集一共有74K幅图像，所以叫Chars74K。</p>
<p>英文数据集依据图像采集方式分为三个类别：</p>
<ol>
<li>自然环境下采集的字符图像数据集；</li>
<li>手写字符图像数据集；</li>
<li>计算机不同字体合成的字符图像数据集。</li>
</ol>
<p>这里只介绍英文手写字符数据集。该数据集包含了52个字符类别（A-Z，a-z）和10个数字类别（0-9）一共62个类别，3410副图像，由55个志愿者手写完成。</p>
<h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><p>该数据集在EnglishHnd.tgz这个文件中（English Hand writing），图像主要在Img这个文件夹下，按照Samples001-Samples062的命名方式存储在62个子文件夹下，每个子文件夹有55张图像，都为PNG格式，分辨率为1200*900，三通道RGB图像。</p>
<p>数据集作者提供了matlab的读入方式，在Lists.tgz文件里的English/Hnd文件夹下有个lists_var_size.MAT文件来进行数据读入，但该文件只是建立了一个结构体（struct），提供了相关信息，图像的实际数据还是要自己写代码读入。</p>
<p>数据集作者已经将训练数据与测试数据分成了30个不同的子集，就是以上的TRNind和TSTind，这里面存储的是图像的索引（Index），但这里要注意的是有些训练数据子集不是930个，后面有些数据是0。</p>
<p>以下的matlab代码在作者提供的mat文件基础上，将一个子集的训练数据、测试数据以及标签（实际分类）等信息读入，图像数据读入为cell数组，标签数据读入为uint16数组（需要注意的是标签1代表实际的数字0，标签2代表实际的数字1，依此类推）。</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Character Recognition in Natural.Teófilo Emídio de Campos, Bodla Rakesh Babu, Manik Varma.<br>2.Images.[C]// Visapp 2009 - Proceedings of the Fourth International Conference on Computer Vision Theory and Applications, Lisboa, Portugal, February. 2009:273-280.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/05/杜成玉_PASCAL VOC数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/05/杜成玉_PASCAL VOC数据集/" itemprop="url">PASCAL VOC数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-05T15:37:46+05:00">
                2018-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：杜成玉<br>下载地址:<a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html" target="_blank" rel="noopener">http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="数据来源：http-www-52ml-net-20458-html"><a href="#数据来源：http-www-52ml-net-20458-html" class="headerlink" title="数据来源：http://www.52ml.net/20458.html"></a>数据来源：<a href="http://www.52ml.net/20458.html" target="_blank" rel="noopener">http://www.52ml.net/20458.html</a></h2><p>PASCAL VOC挑战赛是视觉对象的分类识别和检测的一个基准测试，提供了检测算法和学习性能的标准图像注释数据集和标准的评估系统。PASCAL VOC图片集包括20个目录：人类；动物（鸟、猫、牛、狗、马、羊）；交通工具（飞机、自行车、船、公共汽车、小轿车、摩托车、火车）；室内（瓶子、椅子、餐桌、盆栽植物、沙发、电视）。PASCAL VOC挑战赛在2012年后便不再举办，但其数据集图像质量好，标注完备，非常适合用来测试算法性能。<br>数据集大小：2GB</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Vicente S, Carreira J, Agapito L, et al. Reconstructing pascal voc[C]//Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. IEEE, 2014: 41-48.<br>[2]Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 3431-3440.<br>[3]Razavian A S, Azizpour H, Sullivan J, et al. CNN features off-the-shelf: an astounding baseline for recognition[C]//Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference on. IEEE, 2014: 512-519.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/05/朱述承_IcePaHC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/05/朱述承_IcePaHC/" itemprop="url">IcePaHC</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-05T09:37:00+05:00">
                2018-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：朱述承</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>冰岛语解析历史语料库（IcePaHC）是一个历史语料库，具有从12世纪到现代所有时期的冰岛语书面语样本。该语料库大多与UPenn开发的历史英语语料库兼容。对于历史文本来说，这里的现代化拼写是为了适应音位变化。</p>
<h1 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h1><p><a href="http://www.linguist.is/icelandic_treebank/Download" target="_blank" rel="noopener">http://www.linguist.is/icelandic_treebank/Download</a></p>
<h1 id="第9版内容"><a href="#第9版内容" class="headerlink" title="第9版内容"></a>第9版内容</h1><p>共计1,002,390词<br>1150: Fyrsta málfræðiritgerðin (The First Grammatical Treatise) (4422 words)<br>1150: Íslensk hómilíubók (Icelandic book of homilies) (40943 words)<br>1210: Jarteinabók (10328 words)<br>1210: Þorláks saga helga (10868 words)<br>1250: Íslendinga saga (22805 words)<br>1250: Þetubrot Egils Sögu (Theta manuscript of Egils Saga) (3461 words)<br>1260: Jómsvíkinga saga (21133 words)<br>1270: Grágás. Lagasafn íslenska þjóðveldisins. (6203 words)<br>1275: Morkinskinna (25064 words)<br>1300: Alexanders saga (23356 words)<br>1310: ﻿Grettis saga Ásmundarsonar (20563 words)<br>1325: Árna saga biskups (19968 words)<br>1350: Bandamanna saga (Möðruvallabók text) (13618 words)<br>1350: Finnboga saga ramma (23036 words)<br>1350: Mörtu saga og Maríu Magdalenu (17241 words)<br>1400: Gunnars saga Keldugnúpsfífls (8770 words)<br>1400: Gunnars saga Keldugnúpsfífls - Part 2 (3164 words)<br>1400: Víglundar saga (13453 words)<br>1450: Bandamanna saga (Konungsbók text) (11560 words)<br>1450: Ectors saga (21063 words)<br>1450: Júditarbók (6562 words)<br>1450: Vilhjálms saga Sjóðs (23132 words)<br>1475: Miðaldaævintýri (18084 words)<br>1480: Jarlmanns saga og Hermanns (14482 words)<br>1525: Erasmus saga (Reykjahólabók) (8589 words)<br>1525: Georgíus saga (Reykjahólabók) (20092 words)<br>1540: Nýja Testamenti Odds Gottskálkssonar (The New Testament of Oddur Gottskálksson), Postulanna Gjörningar (Acts of the Apostles) (16550 words)<br>1540: Nýja Testamenti Odds Gottskálkssonar (The New Testament of Oddur Gottskálksson), S. Jóhannis Guðspjöll (Gospel of St. John) (20925 words)<br>1593: Eintal sálarinnar við sjálfa sig (23327 words)<br>1611: Okur (15481 words)<br>1628: Reisubók séra Ólafs Egilssonar (17199 words)<br>1630: Fimmtíu heilagar hugvekjur Meditationes sacrae (12698 words)<br>1650: Illuga saga Tagldarbana (20921 words)<br>1659: Píslarsaga séra Jóns Magnússonar (9825 words)<br>1661: Reisubók Jóns Ólafssonar Indíafara (23031 words)<br>1675: Móðars þáttur (3845 words)<br>1675: Söguþáttur af Ármanni og Þorsteini gála (11228 words)<br>1675: Um ætt Magnúsar Jónssonar (3187 words)<br>1680: Sögu-þáttur um Skálholts biskupa fyrir og um siðaskiptin. (10281 words)<br>1720: Vídalínspostilla (23016 words)<br>1725: Biskupasögur Jóns prófasts Halldórssonar í Hítardal (22297 words)<br>1745: Nikulás Klím (22038 words)<br>1790: Fimmbræðra saga (18860 words)<br>1791: Ævisaga síra Jóns Steingrímssonar (22369 words)<br>1830: Hellismanna saga (14988 words)<br>1835: Um eðli og uppruna jarðarinnar (On the Nature and Origin of the Earth) (3257 words)<br>1850: Piltur og stúlka (17844 words)<br>1859: Fimtíu hugvekjur út af pínu og dauða Drottins vors Jesú Krists (20530 words)<br>1861: Sagan af Heljarslóðarorrustu (20336 words)<br>1882: Brynjólfur Sveinsson biskup (27342 words)<br>1883: Hans Vöggur (1927 words)<br>1888: Grímur kaupmaður deyr (7241 words)<br>1888: Vordraumur (10753 words)<br>1902: Upp við fossa (20647 words)<br>1907: Leysing (20613 words)<br>1908: Ofurefli (20262 words)<br>1920: Árin og eilífðin. Prédikanir eftir Harald Níelsson (21234 words)<br>1985: Margsaga (22295 words)<br>1985: Sagan öll (20980 words)<br>2008: Ofsi (21144 words)<br>2008: Segðu mömmu að mér líði vel - saga um ástir - (21958 words)</p>
<h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><p>如果您使用Windows，最简单的方法就是下载IcePaHC for Windows并按照屏幕上的说明进行操作。适用于Windows的IcePaHC使用CorpusSearch运行查询，因此除了此网页外，还请阅读CorpusSearch文档。如果您使用IcePaHC for Windows，则无需输入启动程序的命令，只需单击桌面上的IcePaHC图标即可。如果您没有安装Java，安装将引导您进入Java下载页面。</p>
<p>由于语料库使用标记的包围格式，因此它与采用这种注释的程序兼容。我们推荐使用由UPenn的Beth Randall开发的CorpusSearch程序。如果您已将语料库复制到目录“/ home / chomsky / icepahc”并将CorpusSearch jar文件保存在“/ home / chomsky / corpussearch”中，则可以使用以下命令来使用语料库中的查询来搜索语料库名为datsubj.q的文本文件。</p>
<p>java -classpath /home/chomsky/corpussearch/CS_2.002.75.jar csearch/CorpusSearch datsubj.q /home/chomsky/icepahc/*.psd</p>
<p>让我们假设datsubj.q是一个查询，它挑选出所有的和主语。该文件可能如下所示：</p>
<p>node: IP*</p>
<p>query: (IP<em> idoms NP-SBJ) AND (NP-SBJ idoms </em>-D)</p>
<p>果使用这样的文件运行上面的命令，CorpusSearch将返回一个名为datsubj.out的文件，其语料库中的所有语句都包含配词主题。阅读语料库的CorpusSearch文档和注释准则，了解如何做更多。</p>
<p>请注意，将会有方法通过创建别名等来简化命令，但这在不同的操作系统上会有所不同。阅读CorpusSearch文档入门以获取更多信息。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CNLR</p>
              <p class="site-description motion-element" itemprop="description">语料库、数据集及工具资源和教程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">78</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CNLR</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
