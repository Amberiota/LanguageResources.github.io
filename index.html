<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="语料库、数据集及工具资源和教程">
<meta property="og:type" content="website">
<meta property="og:title" content="世界语言资源平台">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="世界语言资源平台">
<meta property="og:description" content="语料库、数据集及工具资源和教程">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="世界语言资源平台">
<meta name="twitter:description" content="语料库、数据集及工具资源和教程">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>世界语言资源平台</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">世界语言资源平台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/12/刘唯_Caltech-256/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/12/刘唯_Caltech-256/" itemprop="url">Caltech-256</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-12T18:19:00+05:00">
                2018-05-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Caltech-256 是一个图像物体识别数据集，包含 30608 张图片，256个物体类别，每类图片最少80张，最多827张。</p>
<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a href="http://www.vision.caltech.edu/Image_Datasets/Caltech256/" target="_blank" rel="noopener">http://www.vision.caltech.edu/Image_Datasets/Caltech256/</a></p>
<h1 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h1><p>1.10 Gb</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Kangshun Li,Fubin Wang,Lixia Zhang. A new algorithm for image recognition and classification based on improved Bag of Features algorithm[J]. Optik - International Journal for Light and Electron Optics,2016,127(11).<br>[2]Dong Seon Cheng,Francesco Setti,Nicola Zeni,Roberta Ferrario,Marco Cristani. Semantically-driven automatic creation of training sets for object recognition[J]. Computer Vision and Image Understanding,2015,131.<br>[3]Sean Ryan Fanello,Carlo Ciliberto,Nicoletta Noceti,Giorgio Metta,Francesca Odone. Visual recognition for humanoid robots[J]. Robotics and Autonomous Systems,2016.<br>[4]David Hutchison,Takeo Kanade,Josef Kittler,Jon M. Kleinberg,Friedemann Mattern,John C. Mitchell,Moni Naor,Oscar Nierstrasz,C. Pandu Rangan,Bernhard Steffen,Madhu Sudan,Demetri Terzopoulos,Doug Tygar,Moshe Y. Vardi,Gerhard Weikum. Computer Vision – ECCV 2010[M].Springer Berlin Heidelberg:2010-06-15.<br>[5]Bao-Di Liu,Yu-Xiong Wang,Bin Shen,Yu-Jin Zhang,Martial Hebert. Self-explanatory Sparse Representation for Image Classification[M].Springer International Publishing:2014-06-15.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/12/刘唯_STL-10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/12/刘唯_STL-10/" itemprop="url">PASCAL Visual Object Classes Challenge 2010</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-12T18:02:00+05:00">
                2018-05-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>STL-10 是一个图像数据集，包含 10 类物体的图片，每类 1300 张图片，500 张训练，800 张测试，每张图片分辨率为 96x96。除了具有类别标签的图片之外，还有 100000 张无类别信息的图片。</p>
<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a href="https://cs.stanford.edu/~acoates/stl10/" target="_blank" rel="noopener">https://cs.stanford.edu/~acoates/stl10/</a></p>
<h1 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h1><p>2.46 Gb</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Yoshihiro Shima. Image Augmentation for Object Image Classification Based On Combination of Pre-Trained CNN and SVM[J]. Journal of Physics: Conference Series,2018,1004(1).<br>[2]Yazhou Yao,Jian Zhang,Fumin Shen,Xiansheng Hua,Jingsong Xu,Zhenmin Tang. A new web-supervised method for image dataset constructions[J]. Neurocomputing,2016.<br>[3]Kristo,Chin Seng Chua. Cost effective window arrangement for spatial pyramid matching[J]. Journal of Visual Communication and Image Representation,2015,29.<br>[4]Yunong Wang,Nenghai Yu,Taifeng Wang. Ada-Sal Network: emulate the Human Visual System[J]. Signal Processing: Image Communication,2016,47.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/12/刘唯_PASCAL Visual Object Classes Challenge 2010/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/12/刘唯_PASCAL Visual Object Classes Challenge 2010/" itemprop="url">PASCAL Visual Object Classes Challenge 2010</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-12T18:02:00+05:00">
                2018-05-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>PASCAL Visual Object Classes Challenge 2010年的图像数据集。PASCAL Visual Object Classes 是一个图像物体识别竞赛，用来从真实世界的图像中识别特定对象物体，共包括 4 大类 20 小类物体的识别。其类别信息如下。 Person: person Animal: bird, cat, cow, dog, horse, sheep Vehicle: aeroplane, bicycle, boat, bus, car, motorbike, train Indoor: bottle, chair, dining table, potted plant, sofa, tv/monitor</p>
<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2010/index.html" target="_blank" rel="noopener">http://host.robots.ox.ac.uk/pascal/VOC/voc2010/index.html</a></p>
<h1 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h1><p>1.25 Gb</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Mark Everingham,Andrew Zisserman,Christopher K.I. Williams,Luc Gool,Moray Allan,Christopher M. Bishop,Olivier Chapelle,Navneet Dalal,Thomas Deselaers,Gyuri Dorkó,Stefan Duffner,Jan Eichhorn,Jason D.R. Farquhar,Mario Fritz,Christophe Garcia,Tom Griffiths,Frederic Jurie,Daniel Keysers,Markus Koskela,Jorma Laaksonen,Diane Larlus,Bastian Leibe,Hongying Meng,Hermann Ney,Bernt Schiele,Cordelia Schmid,Edgar Seemann,John Shawe-Taylor,Amos Storkey,Sandor Szedmak,Bill Triggs,Ilkay Ulusoy,Ville Viitaniemi,Jianguo Zhan. Machine Learning Challenges[M].Springer Berlin Heidelberg:2006-04-07.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/12/刘唯_CIFAR-100/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/12/刘唯_CIFAR-100/" itemprop="url">CIFAR-100</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-12T17:45:00+05:00">
                2018-05-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>CIFAR-100 是一个图像数据集，包含 60000 张 32x32 分辨率的彩色图像，根据图像内容被分为 100 个小类别，包括：airplane、automobile、bird、cat、deer、dog、frog、horse、ship、truck，10个大类下的10个小类，类别之间的交集为空。</p>
<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a href="http://www.cs.utoronto.ca/~kriz/cifar.html" target="_blank" rel="noopener">http://www.cs.utoronto.ca/~kriz/cifar.html</a></p>
<h1 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h1><p>380.52 Mb</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Nishant Shrivastava,Vipin Tyagi. An efficient technique for retrieval of color images in large databases[J]. Computers and Electrical Engineering,2015,46.<br>[2]Feng Liu,Yongzhen Huang,Liang Wang,Wankou Yang,Changyin Sun. Spatial modeling via feature co-pooling and SG grafting[J]. Neurocomputing,2014,139.<br>[3]Zenglin Shi,Yangdong Ye,Yunpeng Wu. Rank-based pooling for deep convolutional neural networks[J]. Neural Networks,2016,83.<br>[4]Leena Mary Francis,N. Sreenath. TEDLESS – Text detection using least-square SVM from natural scene[J]. Journal of King Saud University - Computer and Information Sciences,2017.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/刘晓_Visual7W 图像数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/刘晓_Visual7W 图像数据/" itemprop="url">Visual7W 图像数据</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T17:37:46+05:00">
                2018-05-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>下载地址：<a href="http://web.stanford.edu/~yukez/visual7w/" target="_blank" rel="noopener">http://web.stanford.edu/~yukez/visual7w/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Visual7W 图像数据是一个图像内容理解的数据集，通过对图像区域的文字描述和互相之间的关联，进行视觉问答（Visual Question Answering）任务，数据集中不仅包含图像本身，还包括图像内容的区域内容的问答。Visual7W是Visual Genome的一个子集，包含47,300张图像。Visual7W的问题主要由What, Where, How, When, Who,Why, and Which构成。Visual7W的问题是多选问题，每个问题都有四个候选答案。  </p>
<p><img src="https://i.loli.net/2018/05/11/5af59a6e24fb7.jpg" alt=""></p>
<h1 id="文件类型"><a href="#文件类型" class="headerlink" title="文件类型"></a>文件类型</h1><p>多文件压缩包  </p>
<p>#文件大小<br>1.77Gb  </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Yuke Zhu, Oliver Groth, Michael Bernstein and Li Fei-Fei, Visual7W: Grounded Question Answering in Images</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/刘晓_Caltech-UCSD Birds 200 鸟类图像数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/刘晓_Caltech-UCSD Birds 200 鸟类图像数据/" itemprop="url">Caltech-UCSD Birds 200 鸟类图像数据</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T17:37:46+05:00">
                2018-05-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>下载地址:<a href="http://www.vision.caltech.edu/visipedia/CUB-200-2011.html" target="_blank" rel="noopener">http://www.vision.caltech.edu/visipedia/CUB-200-2011.html</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Caltech-UCSD Birds 200 是一个鸟类图片数据集，包含 200 不同种鸟类，共计 11788 张图片。<br>Caltech-UCSD Birds-200-2011 (CUB-200-2011)是CUB-200数据集的扩展版本，每个类的图像数量大约是两倍，新的部分位置标注。有关数据集的详细信息，请参见下面链接的技术报告。  </p>
<ul>
<li>种类数量： 200  </li>
<li>图像数量：11,788  </li>
<li>每个图像的注释:15部分位置，312个二进制属性，1个边界框。</li>
</ul>
<p><img src="https://i.loli.net/2018/05/11/5af59444719b4.jpg" alt="">   </p>
<h1 id="文件类型"><a href="#文件类型" class="headerlink" title="文件类型"></a>文件类型</h1><p>多文件压缩包  </p>
<h1 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h1><p>1.12Gb  </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Wah C., Branson S., Welinder P., Perona P., Belongie S. “The Caltech-UCSD Birds-200-2011 Dataset.” Computation &amp; Neural Systems Technical Report, CNS-TR-2011-001. <a href="http://www.vision.caltech.edu/visipedia/papers/CUB_200_2011.pdf" target="_blank" rel="noopener">download pdf</a><br>[2] Goering, C., Rodner, E., Freytag, A., Denzler, J., “Nonparametric Part Transfer for Fine-grained Recognition”, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2014.<br>[3] Wah, C., Van Horn, G., Branson, S., Maji, S., Perona, P., Belongie, S., “Similarity Comparisons for Interactive Fine-Grained Categorization”, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2014.<br>[4] Berg T., Belhumeur P., “POOF: Part-Based One-vs-One Features for Fine-Grained Categorization, Face Verification, and Attribute Estimation”, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2013.<br>[5] Chai, Y., Lempitsky, V., Zisserman, A., “Symbiotic Segmentation and Part Localization for Fine-Grained Categorization”, IEEE International Conference on Computer Vision (ICCV), Sydney, Australia, 2013.<br>[6] Gavves E., Fernando B., Snoek C., Smeulders A., Tuytelaars T., “Fine-Grained Categorization by Alignments”, IEEE International Conference on Computer Vision (ICCV), Sydney, Australia, 2013.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/刘晓_COIL-20/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/刘晓_COIL-20/" itemprop="url">COIL-20 数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T17:37:46+05:00">
                2018-05-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>下载地址：<a href="http://www.cs.columbia.edu/CAVE/software/softlib/coil-20.php" target="_blank" rel="noopener">http://www.cs.columbia.edu/CAVE/software/softlib/coil-20.php</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>COIL-20 数据集是彩色图片集合，包含对 20 个物体从不同角度的拍摄，每隔 5 度拍摄一副图像，每个物体 72 张图像。每张图像大小进行了统一处理为 128x128。数据集包含两个子集。第一组 包含 10 个对象的总共 720 张未处理图像。第二组包含 20 个对象处理后的总共 1440 张图像。<br><img src="https://i.loli.net/2018/05/11/5af5910ed488d.jpg" alt=""></p>
<h1 id="数据集大小"><a href="#数据集大小" class="headerlink" title="数据集大小"></a>数据集大小</h1><p>12.40 Mb  </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] C Rate ， C Retrieval, Columbia Object Image Library (COIL-20) ,《Computer》 , 2011<br>[2]TV Hoang ， S Tabbone, Generic R-transform for invariant pattern representation, International Workshop on Content-based Multime… , 2011 :157-162</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/刘晓_NORB v1.0 图像数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/刘晓_NORB v1.0 图像数据/" itemprop="url">NORB v1.0 图像数据</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T17:37:46+05:00">
                2018-05-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>下载地址：<a href="http://cs.nyu.edu/~ylclab/data/norb-v1.0/" target="_blank" rel="noopener">http://cs.nyu.edu/~ylclab/data/norb-v1.0/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>NORB 是 3D 物体图像识别数据集。从不同的角度对 5 大类别（四条腿的动物、人像、飞机、卡车、小汽车）中的 50 个玩具模型进行图像拍摄。拍摄采用了 2 个照相机，6 种不同的光照条件，9 个特定的拍摄角度， 18 个仰角。 训练集合中包括每个类别的 5 个实例，余下 5 个实例为测试集。该数据库用于研究目的。它不能被出售。  </p>
<h1 id="数据集内容"><a href="#数据集内容" class="headerlink" title="数据集内容"></a>数据集内容</h1><p>文件便于下载已被处理成压缩。在未压缩之后，它们是一个简单的二进制矩阵格式，带有文件后缀“.mat”。文件格式将在后面的部分中解释。“-dat”文件存储图像序列。“-cat”文件存储图像的相应类别。每个“-dat”文件存储了29,160个图像对(6个类别，5个实例，6个lightings, 9个特定的拍摄角度，18个方位角)。第6类是没有对象的图像，可以用来训练系统拒绝图像，因为这5个对象类别都没有。每个对应的“-cat”文件包含29,160个类别标签(动物为0，人为1，飞机为2，卡车为3，汽车为4，空白为5)。<br>每个“-info”文件存储了29,160个10维向量，其中包含了关于相应图像的额外信息。向量的前四个元素是:  </p>
<ul>
<li>类别中的实例(0到9)  </li>
<li>高程(0到8，意味着摄像机分别为30、35、40、45、50、55、60、65、70度)  </li>
<li>3。方位角(0、2、4,……，34，乘以10，得到角度的方位角)  </li>
<li>4。照明条件(0至5)  </li>
</ul>
<p>接下来的6个元素描述了在一个杂乱的背景上叠加在物体上的微扰。  </p>
<h1 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a>文件格式</h1><p>这些文件存储在所谓的“二进制矩阵”文件格式中，这是一种简单的矢量格式和各种元素类型的多维矩阵。二进制矩阵文件首先是一个文件头，它描述了矩阵的类型和大小，然后是矩阵的二进制图像。<br>注意，当矩阵小于3维时，比如说，它是一维向量，然后是dim[1]和dim[2]都是1。当矩阵有超过3个维度时，标题将被进一步的尺寸信息。否则，在文件头出现后，将在最后一个维度中以索引存储的矩阵数据变化最快。  </p>
<p>这是一张 “norb-5x46789x9x18x6x2x108x108-training-10-dat.mat”文件中前30张图片的截图。，按顺序排列，从左到右(列主要)。下面的标题显示了相应的 “-cat.mat” 和 “-info.mat” 的内容。它们是”category / instance / elevation / azimuth / lighting”。对于背景图像，后面的4个数字都是-1。    </p>
<p><img src="https://i.loli.net/2018/05/11/5af598679d179.jpg" alt="">  </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Y. LeCun, F.J. Huang, L. Bottou, Learning Methods for Generic Object Recognition with Invariance to Pose and Lighting. CVPR 2004</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/10/朱述承_The Quranic Arabic Corpus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/10/朱述承_The Quranic Arabic Corpus/" itemprop="url">The Quranic Arabic Corpus</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-10T09:37:00+05:00">
                2018-05-10
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：朱述承</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>古兰经阿拉伯语语料库涵盖了带注释的语料资源，它显示了古兰经中每个词的阿拉伯语语法，句法和形态。语料库提供了三个层次的分析：词法注释，句法树库和语义本体。树库是汇集句法树的语言资源。这些是人工和计算机可以读取的句子的人工注释分析，不同的树库采用不同的语法理论。最近的阿拉伯语计算研究侧重于现代标准阿拉伯语，而古兰经的古典阿拉伯语则相对尚未探索。尽管数个世纪以来有关于这个主题的许多着作，但几乎没有人注意到传统的阿拉伯语语法特征。该网站的语法部分为希望贡献力量的注释者提供了一套指导方针。所使用的语法方法是传统的阿拉伯语语法，称为i’rāb（إعراب）。这是研究阿拉伯文句法的自然方法，并且在阿拉伯语言学方面已有1000多年的历史。</p>
<h1 id="访问地址"><a href="#访问地址" class="headerlink" title="访问地址"></a>访问地址</h1><p><a href="http://corpus.quran.com" target="_blank" rel="noopener">http://corpus.quran.com</a></p>
<h1 id="独特性"><a href="#独特性" class="headerlink" title="独特性"></a>独特性</h1><p>古兰经阿拉伯语语料库在三个重要方面与其他阿拉伯语树库不同：</p>
<p>源文本是阿拉伯语的一种不同形式。古兰经的语言被认为是古典阿拉伯语，不同于今天使用的现代标准阿拉伯语。作为一个中央宗教文本，古兰经也与其他阿拉伯树库中注释的报纸文章类型不同。鉴于古兰经对全世界伊斯兰教的重要性，在注释文本以确保公认的历史准确性时需要特别注意，因为语法分析可能意味着有其他的意义。幸运的是，有许多书籍使用传统的语法提供阿拉伯语古兰经的完整语法分析，鼓励注释者使用它来验证他们的注释。</p>
<p>该文本包含变音符号并被元音化。 “古兰经”的阿拉伯文本包含明确的变音符号，因此完全属于音位。现代标准的阿拉伯语是不带变音符号的，所以读者推断变位，而不是作为正字法的一部分。变音符号首次引入古兰经的阿拉伯语，以减少任何可能的含义模糊，并保持口头传统。这简化了文本的形态和句法分析。</p>
<p>使用i’rāb（إعراب）的传统语法。用于注释古兰经语法的语法框架是传统的阿拉伯语语法，用图形表示使用依赖关系图。所用的注释和术语完全符合古兰经现有的历史语法分析。这与遵循不同语法框架的其他阿拉伯语树库形成鲜明对比。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/10/朱述承_LIVAC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/10/朱述承_LIVAC/" itemprop="url">LIVAC</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-10T09:37:00+05:00">
                2018-05-10
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：朱述承</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>LIVAC汉语共时语料库(Linguistic Variation in Chinese Speech Communities)与众不同，因为它以严紧、恒常与“共时”方式，搜索和处理了超常的大量汉语具代表性报章语料，并通过精密的技术，累积了泛华语地区众多精确的统计数据。本语料库最大特点是采用“共时性”视窗模式，剖析来自香港，北京，上海，台湾，澳门，新加坡等多地的定量华语媒体语料。直至2016年，LIVAC已处理逾6.0亿字，累积并持续提炼出约两百万词条。LIVAC所收集各地语用数据，可供各种比较研究，并方便有关的信息科技发展与应用。此外，语料库又兼顾了“历时性”，方便各界以专词配合语用范围搜索(KWIC)，以便客观地观察与研究20年视窗内有代表性的语用发展全面动态。经过协调与配合个别需求，例如针对性以地区、时段或范畴，LIVAC曾为多个公、私营机构提供服务，包括语言工程，资讯服务，词典编著，媒体分析与教育各方面机构等。LIVAC由香港城市大学语言资讯科学研究中心开发和推展，由城大企业有限公司旗下麒麟（香港）有限公司提供技术支援。2010年至2013年期间，LIVAC曾挂靠于香港教育学院语言资讯科学研究中心。自2013年7月起，LIVAC由麒麟（香港）有限公司独家维护和开发。</p>
<h1 id="访问地址"><a href="#访问地址" class="headerlink" title="访问地址"></a>访问地址</h1><p><a href="http://www.livac.org/" target="_blank" rel="noopener">http://www.livac.org/</a></p>
<h1 id="语料处理"><a href="#语料处理" class="headerlink" title="语料处理"></a>语料处理</h1><p>1.来自媒体、自行输入、登录<br>2.统一为文字版，简转繁，储存Big5及Unicode两版本<br>3.电脑自动切词，电脑自动校对<br>4.人工校对、复校，词类标注<br>5.提取词语，加入各地词库<br>6.各地词库组合为LIVAC大语库</p>
<h1 id="标注及应用"><a href="#标注及应用" class="headerlink" title="标注及应用"></a>标注及应用</h1><p>a. 多种分类，如一般名词与专用名词，例如人名；地名；专名(人名、姓氏、半称谓、地名、机构专名、商用专名、其他专名、时间词、方位词、处所词等)；叠词；外文词；套装词；数词等。<br>b. 设人名库、地名库、专名库<br>c. 提供“专名榜”、“新词榜”、“名人榜”、“地名榜”，覆合词及匹配词<br>d. 其他标注，如一般名词；数词；量词；多类动词；多类形容词；代词；副词；介词；连词；多类助词；语气词；拟声词；叹词；不完整词等。</p>
<h1 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h1><p>由于LIVAC语料是多方面平行“共时”、“同步”方式搜集语料，语料来源涵盖整个泛华语地区，故可协助搜索资料及作分析，是目前有别于其他任何汉语语料库或同类型研究。这点，特别得到语文界及其他方面专家、学者的认同和重视。同时，由于语料库历时十九年，因此“共时性”以外又兼顾了“历时性”，方便研究人员客观地探究到视窗内的有代表性的语言发展全面动态。LIVAC所提供的不仅是语言资料，还同时提供共时的社会、文化档案资料，犹如一个系列性的时间锦囊。</p>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><p>1、LIVAC提供于编纂多本泛华语词典的依据，如近年推出的《新华新词语词典》 (提供词条，北京商务印书馆2003年出版)；《21世纪华语新词语词典》(上海复旦大学出版社2007年出版简体字本，台湾丽文文化事业股份有限公司2008年出版繁体字本)；《全球华语新词语典》(北京商务印书馆，2010年出版)；《汉英大词典》(提供新词词条，牛津大学出版社，2010年出版)；及正在编纂中的逆序词典、法律词典、专利词典等。<br>2、LIVAC可为研究各地华语语言与文化比较，例如词语在各地的使用及演变。<br>3、LIVAC还可为语言教学研究和开展，例如对各华语地区学生中文程度的测试、与香港卫生署合作制定香港（粤语）口语能力量表(COLAS)、汉语拼音教学网页的建立等等。<br>4、LIVAC目前最大的一个用途就是应用于资讯科技发展研究，例如用于互联网上的专名检索、手提电话中文字频词频的排列和输入、语音文字的自动转换等。<br>5、多年来为多家国际企业和政府机构合作，提供语料库研究后勤及开发服务，如中国教育部、香港特区政府卫生署、香港特区政府司法机构、NOKIA(北京)、Tegic(ERICSSON，美国)、YAHOO(香港)、Microsoft(台湾)、NTT Docomo (日本)、BASIS(美国)、无敌科技(台湾、中国大陆)、欧洲Matrixware公司、北京商务印书馆、上海复旦大学出版社、牛津大学出版社等。<br>6、其他: 年度新闻风云人物榜(<a href="http://www.livac.org/celebrity)、年度新词榜(www.livac.org/newword.php?lang=tc)、中外人名对照表、雅歌汇-" target="_blank" rel="noopener">www.livac.org/celebrity)、年度新词榜(www.livac.org/newword.php?lang=tc)、中外人名对照表、雅歌汇-</a> 汉语文白对照的机器辅助处理及检索平台、成语填字坊网上游戏 (<a href="http://qie.livac.org/xwordlite)。" target="_blank" rel="noopener">http://qie.livac.org/xwordlite)。</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1、邹嘉彦、黎邦洋、陈伟光、王士元（编）（1998），《汉语计量与计算研究》，香港，香港城市大学语言资讯科学研究中心。<br>2、邹嘉彦、游汝杰（编）（2007），《21世纪华语新词语词典》（简体字版），上海，复旦大学出版社。<br>3、邹嘉彦、游汝杰（编）（2008），《21世纪华语新词语词典》（繁体字版），台湾，丽文出版社。<br>4、邹嘉彦、游汝杰（编）（2010），《全球华语新词语词典》，北京，商务印书馆。<br>5、Tsou, B. K., Kwong, O.Y. (Eds). (2015). (Linguistic Corpus and Corpus Linguistics in the Chinese Context ) Journal of Chinese Linguistics Monograph Series Number 25, 2015邹嘉彦、邝蔼儿(编)《汉语语料库及语料库语言学》《中国语言学报》专刊第25期, Hong Kong: The Chinese University Press<br>6、Chin, Chi-on Andy and Kwok, Bit-chee and Tsou, Benjamin K., (Eds). (2016). Commemorative Essays for Professor Yuen-Ren Chao: Father of Modern Chinese Linguistics. Taiwan: Crane Publishing.<br>7、邹嘉彦、黎邦洋（2003），〈汉语共时语料库与资讯开发〉，徐波、孙茂松、靳光瑾编《中文资讯处理若干重要问题》〔《973计划国家语言自然语言理解与知识扢掘》总体刊物〕（页147-165），北京，科学出版社。<br>8、Tsou, Benjamin. (2004). “Chinese Language Processing at the Dawn of the 21st Century” in C R Huang and W Lenders (eds) Language and Linguistics Monograph Series B: Frontiers in Linguistics I, pp189-207. Institute of Linguistics, Academia Sinica.<br>9、邹嘉彦（2005），〈21世纪初的中文处理〉（吕学强翻译），俞士汶、黄居仁编《计算语言学前瞻》（页209-258），北京，商务印书馆。<br>10、邹嘉彦、莫宇航（2013），〈汉语书面语的历史与现状：海峡两岸汉语书面语近年演变：以语料库为出发点〉，冯胜利编《汉语书面语的历史与现状》（页58-75），北京，北京大学出版社。<br>11、Tsou, Benjamin, and Kwong, Olivia. (2015). LIVAC as a Monitoring Corpus for Tracking Trends beyond Linguistics. In Tsou, Benjamin, and Kwong, Olivia., (eds.), Linguistic Corpus and Corpus Linguistics in the Chinese Context (Journal of Chinese Linguistics Monograph Series No.25). Hong Kong: The Chinese University Press, pp. 447-471.<br>12、Tsou, Benjamin. (2016). Skipantism Revisited: Along with Neologisms and Terminological Truncation. In Chin, Chi-on Andy and Kwok, Bit-chee and Tsou, Benjamin K., (eds.), Commemorative Essays for Professor Yuen-Ren Chao: Father of Modern Chinese Linguistics. Taiwan: Crane Publishing. pp. 343-357.<br>13、Tsou, B. K. (2017). Loanwords in Mandarin Through Other Chinese Dialects. In R. Sybesma, W. Behr, Y. Gu, Z. Handel, C.-T. Huang &amp; J. Myers (Eds.), The Encyclopaedia of Chinese Language and Linguistics(Vol. 2, pp. 641-647). Leiden; Boston: BRILL.<br>14、Tsou, Benjamin, Lin, H.-L., Chan, T., Hu, J.-P., Chew, C.-H. and Tse, J. (1997). “A Synchronous Chinese Language Corpus from Different Speech Communities: Construction and Application” International Journal of Computational Linguistics and Chinese Language Processing, 2(1), pp.91-104.<br>15、Kwong, Olivia. Tsou, Benjamin, and Lai, Tom. (2004). “Alignment and Extraction of Bilingual Legal Terminology from Context Profiles.” Terminology, 10(1), pp.81-99.<br>16、Kwong, Olivia, and Tsou, Benjamin. (2004). “A Synchronous Corpus-Based Study of Verb-Noun Fluidity in Chinese.” Journal of Chinese Language and Computing, 13(3), pp.227-278.<br>17、Kwong, Olivia, and Tsou, Benjamin. (2005). “A Synchronous Corpus-Based Study on the Usage and Perception of Judgement Terms in the Pan-Chinese Context.” International Journal of Computational Linguistics and Chinese Language Processing, 10(4), pp.519-532.<br>18、Kwong, Olivia, and Tsou, Benjamin. (2006). “Feasibility of Enriching a Chinese Synonym Dictionary with a Synchronous Chinese Corpus”. Lecture Notes in Computer Science, 4139, pp.322-332.<br>19、邹嘉彦、邝蔼儿、路斌、蔡永富（2011），〈汉语共时语料库与追踪语料库: 语料库语言学的新方向〉，《中文信息学报: 庆祝中国中文信息学会成立三十周年纪念论文集》，25（6），38-45。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CNLR</p>
              <p class="site-description motion-element" itemprop="description">语料库、数据集及工具资源和教程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">100</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CNLR</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
