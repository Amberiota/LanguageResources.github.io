<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="语料库、数据集及工具资源和教程">
<meta property="og:type" content="website">
<meta property="og:title" content="世界语言资源平台">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="世界语言资源平台">
<meta property="og:description" content="语料库、数据集及工具资源和教程">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="世界语言资源平台">
<meta name="twitter:description" content="语料库、数据集及工具资源和教程">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>世界语言资源平台</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">世界语言资源平台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/21/卢梦依_The 20 Newsgroups data set 新闻组数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/21/卢梦依_The 20 Newsgroups data set 新闻组数据集/" itemprop="url">The 20 Newsgroups data set 新闻组数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-21T21:47:46+05:00">
                2018-04-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依<br>下载地址：<a href="http://qwone.com/~jason/20Newsgroups/" target="_blank" rel="noopener">http://qwone.com/~jason/20Newsgroups/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>该数据集包含着新闻组相关的文本数据信息。这二十个新闻组数据集合收集了大约20,000新闻组文档，均匀的分布在20个不同的集合。这些文档具有新闻的典型特征：主题，作者和引述。</p>
<h1 id="文件："><a href="#文件：" class="headerlink" title="文件："></a>文件：</h1><p> 大小：20 MB<br> 类型：txt文本<br> 数量：来自20个新闻组的20,000条消息</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Kim Y. Convolutional Neural Networks for Sentence Classification[J]. Eprint Arxiv, 2014.<br>2.Joulin A, Grave E, Bojanowski P, et al. Bag of Tricks for Efficient Text Classification[J]. 2016:427-431.<br>3.Zhang Y, Wallace B. A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification[J]. Computer Science, 2015.<br>4.Ji Y L, Dernoncourt F. Sequential Short-Text Classification with Recurrent and Convolutional Neural Networks[J]. 2016:515-520.<br>5.Chen G, Ye D, Xing Z, et al. Ensemble application of convolutional and recurrent neural networks for multi-label text categorization[C]// International Joint Conference on Neural Networks. IEEE, 2017:2377-2383.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/21/卢梦依_SQuAD The Stanford Question Answering Dataset 问答数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/21/卢梦依_SQuAD The Stanford Question Answering Dataset 问答数据集/" itemprop="url">SQuAD The Stanford Question Answering Dataset 问答数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-21T21:47:46+05:00">
                2018-04-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依<br>下载地址：<a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="noopener">https://rajpurkar.github.io/SQuAD-explorer/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>斯坦福问题回答数据集(SQuAD)是一种新的阅读理解数据集，由一组维基百科文章的工作者提出的问题组成，<br>其中每个问题的答案都是从相应阅读段落中截取的一段文字。<br>在500+的文章中，有100,000+的问题-答案对，SQuAD显着大于以前的阅读理解数据集。</p>
<h1 id="文件大小："><a href="#文件大小：" class="headerlink" title="文件大小："></a>文件大小：</h1><p> 训练集30M<br> 验证集5M</p>
<h1 id="数量："><a href="#数量：" class="headerlink" title="数量："></a>数量：</h1><p> 约30,000,000个句子及其翻译</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Rajpurkar P, Zhang J, Lopyrev K, et al. SQuAD: 100,000+ Questions for Machine Comprehension of Text[J]. 2016:2383-2392.<br>2.Wang Z, Mi H, Hamza W, et al. Multi-Perspective Context Matching for Machine Comprehension[J]. 2016.<br>3.Kim S, Park D, Choi Y, et al. A Pilot Study of Biomedical Text Comprehension using an Attention-Based Deep Neural Reader: Design and Experimental Analysis.[J]. Jmir Medical Informatics, 2018, 6(1):e2.<br>4.Reutebuch C K, Zein F E, Min K K, et al. Investigating a reading comprehension intervention for high school students with autism spectrum disorder: A pilot study[J]. Research in Autism Spectrum Disorders, 2015, 9:96-111.<br>5.Yin W, Ebert S, Schütze H. Attention-Based Convolutional Neural Network for Machine Comprehension[J]. 2016.<br>6.Cui Y, Chen Z, Wei S, et al. Attention-over-Attention Neural Networks for Reading Comprehension[C]// Meeting of the Association for Computational Linguistics. 2017:593-602.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/21/卢梦依_Sentiment140/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/21/卢梦依_Sentiment140/" itemprop="url">Sentiment140 - A Twitter Sentiment Analysis Tool 情感分析数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-21T21:47:46+05:00">
                2018-04-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依<br>下载地址：<a href="http://help.sentiment140.com/for-students/" target="_blank" rel="noopener">http://help.sentiment140.com/for-students/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>Sentiment140是一个可用于情感分析的数据集。<br>数据集具有以下6个特征：</p>
<ul>
<li>推文的感情色彩（polarity）</li>
<li>推文的ID</li>
<li>推文的日期</li>
<li>查看记录</li>
<li>推特（tweeter）的用户名</li>
<li>推文的文本内容</li>
</ul>
<h1 id="文件大小："><a href="#文件大小：" class="headerlink" title="文件大小："></a>文件大小：</h1><p> 大小：80 MB（压缩包）</p>
<h1 id="数量："><a href="#数量：" class="headerlink" title="数量："></a>数量：</h1><p> 160,000条推文</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Zhang X, Zhao J, Lecun Y. Character-level Convolutional Networks for Text Classification[J]. 2015:649-657.<br>2.Severyn, A., &amp; Moschitti, A. UNITN: Training Deep Convolutional Neural Network for TwitterSentiment Classification.<br>3.Xu, J., Wang, P., Tian, G., Xu, B., Zhao, J., Wang, F., &amp; Hao, H. (2015,June). Short TextClustering via Convolutional Neural Networks. In Proceedings of NAACL-HLT (pp.62-69).<br>4.Wang, P., Xu, J., Xu, B., Liu, C. L., Zhang, H., Wang, F., &amp; Hao, H.(2015). SemanticClustering and Convolutional Neural Network for Short Text Categorization.In Proceedings of the 53rd Annual Meeting of the Association forComputational Linguistics and the 7th International Joint Conference on NaturalLanguage Processing (Vol.2, pp. 352-357).<br>5.Liu, Y., Liu, Z., Chua, T. S., &amp; Sun, M. (2015, February). Topical Word Embeddings.In Twenty-Ninth AAAI Conference on Artificial Intelligence.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/21/卢梦伊_Machine Translation of Various Languages 机器翻译数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/21/卢梦伊_Machine Translation of Various Languages 机器翻译数据/" itemprop="url">Machine Translation of Various Languages 机器翻译数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-21T21:47:46+05:00">
                2018-04-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依<br>下载地址：<a href="http://statmt.org/wmt18/translation-task.html#download" target="_blank" rel="noopener">http://statmt.org/wmt18/translation-task.html#download</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>该数据集包含四种欧洲语言的训练数据。可用于改进当前的翻译方法。有以下语言互译可供参考：</p>
<ul>
<li>英汉和汉英</li>
<li>英语 - 捷克语和捷克语 - 英语</li>
<li>英语 - 爱沙尼亚语和爱沙尼亚语 - 英语</li>
<li>英语 - 芬兰语和芬兰语 - 英语</li>
<li>英语 - 德语和德语 - 英语</li>
<li>英语 - 哈萨克语和哈萨克语 - 英语</li>
<li>英文 - 俄文和俄文 - 英文</li>
<li>英语 - 土耳其语和土耳其语 - 英语</li>
</ul>
<h1 id="文件大小："><a href="#文件大小：" class="headerlink" title="文件大小："></a>文件大小：</h1><p> 约15 GB</p>
<h1 id="数量："><a href="#数量：" class="headerlink" title="数量："></a>数量：</h1><p> 约30,000,000个句子及其翻译</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Gehring J, Auli M, Grangier D, et al. Convolutional Sequence to Sequence Learning[J]. 2017.<br>2.Wu Y, Schuster M, Chen Z, et al. Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation[J]. 2016..<br>3.Luong M T, Manning C D. Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models[J]. 2016:1054-1063.<br>4.Lee J, Cho K, Hofmann T. Fully Character-Level Neural Machine Translation without Explicit Segmentation[J]. 2016.<br>5.Chung J, Cho K, Bengio Y. A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation[J]. 2016.<br>6.Firat O, Cho K, Bengio Y. Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism[J]. 2016:866-875.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/刘晓_Keras/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/刘晓_Keras/" itemprop="url">Keras</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="https://keras.io/#installation" target="_blank" rel="noopener">https://keras.io/#installation</a>  </p>
<h2 id="Keras-简介"><a href="#Keras-简介" class="headerlink" title="Keras 简介"></a>Keras 简介</h2><p>Keras 最初是作为 ONEIROS 项目（开放式神经电子智能机器人操作系统）研究工作的一部分而开发的。Keras是一个高层神经网络API，纯Python编写而成并基Tensorflow、Theano以及CNTK后端。Keras 为支持快速实验而生，能够把你的idea迅速转换为结果，如果你有如下需求，请选择Keras：  </p>
<ul>
<li>简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性）  </li>
<li>支持CNN和RNN，或二者的结合  </li>
<li>无缝CPU和GPU切换  </li>
</ul>
<p>Keras适用的Python版本是：Python 2.7-3.6      </p>
<p><a href="https://keras.io/" target="_blank" rel="noopener">Keras官方英文文档</a>  </p>
<p><a href="https://keras.io/zh/" target="_blank" rel="noopener">Keras官方中文文档</a>  </p>
<p><a href="https://github.com/keras-team" target="_blank" rel="noopener">Keras GitHub</a></p>
<h2 id="Keras-安装"><a href="#Keras-安装" class="headerlink" title="Keras 安装"></a>Keras 安装</h2><p>在安装 Keras 之前，请安装以下后端引擎之一：TensorFlow，Theano，或者 CNTK。官方推荐 <strong>TensorFlow 后端</strong> 。  </p>
<ul>
<li><a href="https://www.tensorflow.org/install/" target="_blank" rel="noopener">TensorFlow 安装指引 </a> </li>
<li><a href="http://deeplearning.net/software/theano/install.html#install" target="_blank" rel="noopener">Theano 安装指引 </a> </li>
<li><a href="https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine" target="_blank" rel="noopener">CNTK 安装指引</a></li>
</ul>
<p>还可以考虑安装一下可选依赖：</p>
<ul>
<li>cuDNN (如果你计划在 GPU 上运行 Keras，建议安装)。  </li>
<li>HDF5 和 h5py (如果你需要将 Keras 模型保存到磁盘，则需要这些)。  </li>
<li>graphviz 和 pydot (被可视化工具用来绘制模型图)。  </li>
</ul>
<p><strong>安装 Keras</strong>  ，有两种方法：  </p>
<ol>
<li><p>使用 PyPI 安装 Keras (推荐)  </p>
<pre><code>sudo pip install keras  
pip install keras   # virtualenv 虚拟环境下
</code></pre></li>
</ol>
<ol>
<li><p>使用 Github 源码安装 Keras：<br>使用 git 来克隆 Keras：</p>
<pre><code>git clone https://github.com/keras-team/keras.git    
</code></pre></li>
</ol>
<p>然后，cd 到 Keras 目录并且运行安装命令：  </p>
<pre><code>cd keras  
sudo python setup.py install  
</code></pre><h2 id="Keras-快速使用"><a href="#Keras-快速使用" class="headerlink" title="Keras 快速使用"></a>Keras 快速使用</h2><p>Keras 的核心数据结构是 model，一种组织网络层的方式。最简单的模型是 <strong>Sequential</strong> 顺序模型，它是由多个网络层线性堆叠的栈。对于更复杂的结构，应该使用 Keras 函数式 API，它允许构建任意的神经网络图。<br><strong>Sequential </strong>顺序模型如下所示：  </p>
<pre><code>from keras.models import Sequential  
model = Sequential()  
</code></pre><p>可以简单地使用 .add() 来堆叠模型：  </p>
<pre><code>from keras.layers import Dense
model.add(Dense(units=64, activation=&apos;relu&apos;, input_dim=100))
model.add(Dense(units=10, activation=&apos;softmax&apos;))  
</code></pre><p>在完成了模型的构建后, 可以使用 .compile() 来配置学习过程：  </p>
<pre><code>model.compile(loss=&apos;categorical_crossentropy&apos;, optimizer=&apos;sgd&apos;, metrics=[&apos;accuracy&apos;])  
</code></pre><p>如果需要，你还可以进一步地配置优化器。Keras 的一个核心原则是使事情变得相当简单，同时又允许用户在需要的时候能够进行完全的控制（终极的控制是源代码的易扩展性）。</p>
<pre><code>model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))    
</code></pre><p>现在，你可以批量地在训练数据上进行迭代了：  </p>
<pre><code># x_train 和 y_train 是 Numpy 数组 -- 就像在 Scikit-Learn API 中一样。
model.fit(x_train, y_train, epochs=5, batch_size=32)
</code></pre><p>或者，你可以手动地将批次的数据提供给模型：</p>
<pre><code>model.train_on_batch(x_batch, y_batch)    
</code></pre><p>只需一行代码就能评估模型性能：</p>
<pre><code>loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)    
</code></pre><p>或者对新的数据生成预测：</p>
<pre><code>classes = model.predict(x_test, batch_size=128)    
</code></pre><p>构建一个问答系统，一个图像分类模型，一个神经图灵机，或者其他的任何模型，就是这么的快。</p>
<h2 id="相关例子"><a href="#相关例子" class="headerlink" title="相关例子"></a>相关例子</h2><p>在Keras代码包的examples文件夹中，你将找到使用真实数据的示例模型：</p>
<ul>
<li>CIFAR10 小图片分类：使用CNN和实时数据提升  </li>
<li>IMDB 电影评论观点分类：使用LSTM处理成序列的词语  </li>
<li>Reuters（路透社）新闻主题分类：使用多层感知器（MLP）  </li>
<li>MNIST手写数字识别：使用多层感知器和CNN  </li>
<li>字符级文本生成：使用LSTM </li>
<li>基于多层感知器的softmax多分类：</li>
</ul>
<h2 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h2><p>涉及使用Keras实现的算法及论文后续补上</p>
<p><strong>小知识：</strong> Keras (κέρας) 在希腊语中意为 号角 。它来自古希腊和拉丁文学中的一个文学形象，首先出现于 《奥德赛》 中， 梦神 (Oneiroi, singular Oneiros) 从这两类人中分离出来：那些用虚幻的景象欺骗人类，通过象牙之门抵达地球之人，以及那些宣告未来即将到来，通过号角之门抵达之人。 它类似于文字寓意，κέρας (号角) / κραίνω (履行)，以及 ἐλέφας (象牙) / ἐλεφαίρομαι (欺骗)。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/李华勇_中国哲学电子书计划/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/李华勇_中国哲学电子书计划/" itemprop="url">中国哲学书电子化计划</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="https://ctext.org" target="_blank" rel="noopener">https://ctext.org</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>本网站的目的是提供尽可能精确且便利使用的中国古代原典文献（尤其先秦两汉文献），把这些资料以 恰当结构、可搜索模式来展现，并且广泛使用现代技术作为工具使这些文献更容易学习和研究，因而使更多人有机会接触这些原典文献。</p>
<p>本站提供不同的版本：中文版和英文版，简体字和繁体字。您可以使用任何一页左上边的连接随时转换。</p>
<h1 id="主要功能与内容"><a href="#主要功能与内容" class="headerlink" title="主要功能与内容"></a>主要功能与内容</h1><h2 id="原典资料库"><a href="#原典资料库" class="headerlink" title="原典资料库"></a>原典资料库</h2><p>本网站最主要的部分为古籍资料库，此资料库包含各种从哲学、历史、语言学等角度被视为重要的文献，写作年代以先秦两汉爲主。 本网站的所有资料都存在一个专门设计的数据库，以便读浏览和搜索的方便。 此外，部分原典有附英文或现代汉语翻译，这些翻译是一段一段对照原典而附上的，因此很容易从译文找出对应的原典，或从原典找出对应的译文。</p>
<p>在原典段落的左手边，系统将会显示下列的部份图标；点击这些图标，可以便利享用本站的许多独特功能：</p>
<p><img src="https://i.loli.net/2018/04/19/5ad8454700586.jpg" alt=""></p>
<h2 id="内部字典"><a href="#内部字典" class="headerlink" title="内部字典"></a>内部字典</h2><p>内部汉字字典合并三个来源的信息：统一码联盟（Unicode Consortium）的“Unihan”数据库、上述的原典资料库、以及本网站新开发的CTP字典。 其中Unihan数据库提供有关汉字的基本信息，包括部首、笔画数、异体字、标准字典中的出处、以及英文翻译（但此英文翻译以现代汉语用法爲主）。 原典资料库则给每一个字提供原典中的具体出处。最后，CTP字典试图对汉字的语义和实际运用提供一个尽可能完整的分析。 虽然从汉字的数量上看大多数汉字是单义词，但少数很常用的字却有许多不同的用法，这些不同用法通常有不同语义或读法。 CTP字典把这些不同意义或不同读法的用法分开处理，并且通过原典数据库给每一个不同用法分别提供原典出处。 这一功能是透过一种“语义链接”的手段而实现的，即建立从某篇某段某句中的某字到CTP字典中的相关用法的链接。 建立这些链接需要对文本的理解，因而是一个手动的且耗时的程序；因此CTP字典的范围目前很有限（但日益增加）。 您可以参考CTP字典中对 与、说、故的解释。</p>
<h2 id="词语分析表"><a href="#词语分析表" class="headerlink" title="词语分析表"></a>词语分析表</h2><p>通过内部字典和上述的语义链接，本站还可以对原典数据库中的任何段落提供词语分析表。 词语分析表为段落中的每一个字显示字典中的英文翻译及其它信息，并且对于有语意链接的词语显示词语在此脉络中的意义。 例如，在《论语》的第一段中，系统会显示“乐”的正确读法是“le”而不是“yue”，且该句中“说”的用法跟“悦”的读法、意义相同（请参考《学而》第一段词语分析表）。</p>
<p>建立语意链接的计划正在进行，因此目前也有缺少链接的字。当一个字尚未有语意链接时，系统将会显示此字的基本资料，并提供至完整字典项目的连接。</p>
<h2 id="相似段落资料"><a href="#相似段落资料" class="headerlink" title="相似段落资料"></a>相似段落资料</h2><p>由于种种原因，许多早期文献含有与其它文献相似的片段或较长的段落，足以证明两个著作并非完全独立而形成的。此现象有时表明原作者有意识的抄写了当时已形成的其它著作；有时表明谋一个俗语当时已流行；也有时是由其它的原因造成的。在许多情况下，虽然这些相似的片段具有明显的相似性，并足以保证此相似性并非巧合，与此同时这些片段有时候具有重要且有趣的不同之处。</p>
<p>本站的相似段落功能把这些相似或相同的段落连接起来，且显示相似部份以便对照。任何具有相似段落讯息的段落将会显示图标；点击此图标将会显示此段落、所有相似段落及其连接。</p>
<p>相似段落讯息可以使用下述的“高级搜索”功能来搜索。</p>
<h2 id="原典影印本"><a href="#原典影印本" class="headerlink" title="原典影印本"></a>原典影印本</h2><p>许多早期文献具有不同的现存版本。这些版本的不同有些是因不同的文献历史背景而产生的，也有一些产生于纠正抄写错误，也有部份来自假借字现象而造成的，而另外还有更多造成原因。这些造成原因加起来使得我们很难看出今天的电子版或印刷版的原典是否“正确”；甚至使得我们很难以下定义说什么叫做“正确”的版本，毕竟未必真的曾经存在过所谓“最原始的”由一个作者所写作的版本。</p>
<p>因此，本站为越来越多的原典提供原典扫瞄版，且为原典每一段落提供至扫瞄版的连接。原典数据库中的每一个字应对应于扫瞄版的一个字，而系统能够给使用者显示原典及原典扫瞄版的对照本，以便使用者确定原典与扫瞄本无误。另，因为扫瞄本有可能经过后世的研究而被视为本身有误，因此系统将会注明所有被修改的字词，同时保留原本错误的字以便与扫瞄版对照。</p>
<p>每个具有影印本的原典段落会显示图标；点击此图标将会打开电子版与扫瞄本的对照显示，并突显对应于此段落的部份。</p>
<h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><h2 id="全文搜索"><a href="#全文搜索" class="headerlink" title="全文搜索"></a>全文搜索</h2><p>要进行全文搜索时，先确认浏览器中打开的网页属于网站“原典全文”的部分，然后在左下角的“搜索”框内选择搜索范围并输入所要搜索的字词。（如：学而时习之）且点击“搜索”。全文资料库支持使用多数的搜索条件；在不同搜索条件之间输入半角空格分割（如：学而时 不亦君子），系统将会列出所有同时符合所有搜索条件的段落。若要搜索含有空格的英文词组，在词组外加上英文引号（如：”Mozi said”）。点击“高级搜索”可以使用更有弹性的搜索方式。</p>
<h2 id="辞典搜索"><a href="#辞典搜索" class="headerlink" title="辞典搜索"></a>辞典搜索</h2><p>要进行辞典搜索时，先确认浏览器中打开的网页属于网站“辞典”的部分，然后在左下角的“搜索”框内输入所要查询的字词。（如：学）且点击“搜索”。当输入的文字不作为辞典中的项目时，系统将会以表格的方式为被输入的每一个汉字列出辞典中的资料。</p>
<h2 id="研究资料搜索"><a href="#研究资料搜索" class="headerlink" title="研究资料搜索"></a>研究资料搜索</h2><p>要进行研究资料搜索时，先确认浏览器中打开的网页属于网站“研究资料”的部分，然后在左下角的“搜索”框内输入所要查询的字词。（如：Ethics）且点击“搜索”。点击“高级搜索”可以使用更有弹性的搜索方式。</p>
<h2 id="一般性图标"><a href="#一般性图标" class="headerlink" title="一般性图标"></a>一般性图标</h2><p><img src="https://i.loli.net/2018/04/19/5ad8464eac912.jpg" alt=""></p>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ol>
<li>吴智雄. 由 “数位人文研究法” 探《 皇明经世文编》 所载明初的海洋朝贡议论[J]. 南海学刊, 2016, 2(1): 18-27.</li>
<li>Sturgeon D. 中國哲學書電子化計劃[J]. 網址: <a href="http://ctext" target="_blank" rel="noopener">http://ctext</a>. org, 2011.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/李华勇_OpenNMT/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/李华勇_OpenNMT/" itemprop="url">OpenNMT</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="http://zh.opennmt.net/" target="_blank" rel="noopener">http://zh.opennmt.net/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>海量的数据背景下，人工翻译已经无法承载所有的翻译任务，机器翻译效果并不十分理想，但在有些情况下可以减少理解外语文本所需要的时间和精力。我本人出身英语专业，但是仍然感觉阅读英文文本所花费的时间和精力是中文文本的2-3倍，比如中文一分钟能够阅读600-1000字甚至更多，但英语文章书籍，一般也就200-300单词而已，而且时间长了，大脑更疲劳，难以有效获取信息。所以借助机器翻译，先大致浏览所需理解的外语文本，不失为一种节约时间精力的方式。随着机器翻译的效果越来越好，它的应用场景也越来越广泛，甚至可能彻底改变人类相互沟通的方式。</p>
<p>目前机器翻译已经基本都从传统的统计翻译，变成了神经网络机器翻译，效果有较大的提升，特别是西方语种之间，比如英德互译。而中英互译仍然有差距，不过我想达到令人满意的效果只是时间问题，Google 和 百度 的机器翻译，在某些类型的文档翻译上，已经几乎超过人类，比如科技类的论文，Google 的机器翻译效果尤其好。如果让一个译者去翻译一篇科技类的论文，成本非常高，有很多专业词汇，还有数学符号，懂的人并不多，翻译起来也费时费力，但机器翻译却对这类文本有着很高的效率，十分令人欣喜。</p>
<p>OpenNMT 是一个由 Harvard NLP (哈佛大学自然语言处理研究组) 开源的 Torch 神经网络机器翻译系统。</p>
<p><img src="https://i.loli.net/2018/04/21/5adb2d5ed8bcc.jpg" alt=""></p>
<h1 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h1><ol>
<li><p>简单的通用接口，只需要源/目标文件。</p>
</li>
<li><p>快速高性能GPU训练和内存优化。</p>
</li>
<li><p>提高翻译性能的最新的研究成果。</p>
</li>
<li><p>可配对多种语言的预训练模型（即将推出）。</p>
</li>
<li><p>允许其他序列生成任务的拓展，如汇总和图文生成</p>
</li>
</ol>
<h1 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h1><p>OpenNMT 包含三个命令</p>
<p>1) 数据预处理</p>
<p>th preprocess.lua -train_src data/src-train.txt -train_tgt data/tgt-train.txt -valid_src data/src-val.txt -valid_tgt data/tgt-val.txt -save_data data/demo</p>
<p>2) 模型训练</p>
<p>th train.lua -data data/demo-train.t7 -save_model model</p>
<p>3) 语句翻译</p>
<p>th translate.lua -model model_final.t7 -src data/src-test.txt -output pred.txt</p>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ol>
<li>Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to align and translate[J]. arXiv preprint arXiv:1409.0473, 2014.</li>
<li>Wu Y, Schuster M, Chen Z, et al. Google’s neural machine translation system: Bridging the gap between human and machine translation[J]. arXiv preprint arXiv:1609.08144, 2016.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/李华勇_CN-DBpedia/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/李华勇_CN-DBpedia/" itemprop="url">CN-DBpedia</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="http://kw.fudan.edu.cn/cndbpedia/intro/" target="_blank" rel="noopener">http://kw.fudan.edu.cn/cndbpedia/intro/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>CN-DBpedia是由复旦大学知识工场实验室研发并维护的大规模通用领域结构化百科，其前身是复旦GDM中文知识图谱，是国内最早推出的也是目前最大规模的开放百科中文知识图谱，涵盖数千万实体和数亿级的关系，相关知识服务API累计调用量已达6亿次。</p>
<p>CN-DBpedia以通用百科知识沉淀为主线，以垂直纵深领域图谱积累为支线，致力于为机器语义理解提供了丰富的背景知识，为实现机器语言认知提供必要支撑。</p>
<p>CN-DBpedia已经从百科领域延伸至法律、工商、金融、文娱、科技、军事、教育、医疗等十多个垂直领域，为各类行业智能化应用提供支撑性知识服务，目前已有近百家单位在使用。</p>
<p>CN-DBpedia具有体量巨大、质量精良、实时更新、丰富的API服务等特色。CN-DBpedia已经成为业界开放中文知识图谱的首选。基于CN-DBpedia的知识图谱构建与应用能力已经输出并应用在华为、小I机器人、中国电信、中国移动、同花顺等业界领军企业的产品与解决方案中。</p>
<p>CN-DBpedia提供全套API，并且免费开放使用。</p>
<h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><h2 id="浏览器检索"><a href="#浏览器检索" class="headerlink" title="浏览器检索"></a>浏览器检索</h2><p>直接在网页上search即可。<br>比如输入 北京语言大学 的结果如下：<br><img src="https://i.loli.net/2018/04/19/5ad84af89927d.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84b3f2c647.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84b646724c.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84b792f19f.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84b8e94b19.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84c086f34d.jpg" alt=""></p>
<h2 id="API接口"><a href="#API接口" class="headerlink" title="API接口"></a>API接口</h2><h3 id="api-cndbpedia-ment2ent："><a href="#api-cndbpedia-ment2ent：" class="headerlink" title="api/cndbpedia/ment2ent："></a>api/cndbpedia/ment2ent：</h3><p>输入实体指称项名称(mention name)，返回对应实体(entity)的列表，json格式。</p>
<p>请求参数<br>q：实体指称项名称(mention name)；必填项</p>
<p>apikey：开发者的访问密钥；可选项（注：不加访问密钥会存在访问限制）</p>
<p>返回字段<br>status：本次API访问状态，如果成功返回“ok”，如果失败返回“fail”</p>
<p>ret： 返回entity name list</p>
<p>URL<br><a href="http://shuyantech.com/api/cndbpedia/ment2ent?q=*" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/ment2ent?q=*</a>*</p>
<p><a href="http://shuyantech.com/api/cndbpedia/ment2ent?q=**&amp;apikey=*" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/ment2ent?q=**&amp;apikey=*</a>*</p>
<p>Example<br><a href="http://shuyantech.com/api/cndbpedia/ment2ent?q=红楼梦" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/ment2ent?q=红楼梦</a></p>
<h3 id="api-cndbpedia-avpair："><a href="#api-cndbpedia-avpair：" class="headerlink" title="api/cndbpedia/avpair："></a>api/cndbpedia/avpair：</h3><p>输入实体名，返回实体全部的三元组知识</p>
<p>请求参数<br>q：实体名称(entity name)；必填项</p>
<p>apikey：开发者的访问密钥；可选项（注：不加访问密钥会存在访问限制）</p>
<p>返回字段<br>status：本次API访问状态，如果成功返回“ok”，如果失败返回“fail”</p>
<p>ret： 返回attribute-value pair list, 每个pair也是一个list （[attribute, value]）</p>
<p>URL<br><a href="http://shuyantech.com/api/cndbpedia/avpair?q=*" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/avpair?q=*</a>*</p>
<p><a href="http://shuyantech.com/api/cndbpedia/avpair?q=**&amp;apikey=*" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/avpair?q=**&amp;apikey=*</a>*</p>
<p>Example<br><a href="http://shuyantech.com/api/cndbpedia/avpair?q=复旦大学" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/avpair?q=复旦大学</a></p>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ol>
<li>Bo Xu, Yong Xu, Jiaqing Liang, Chenhao Xie, Bin Liang, Wanyun Cui, and Yanghua Xiao. CN-DBpedia: A Never-Ending Chinese Knowledge Extraction System. In International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, pp. 428-438. Springer, Cham, 2017.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/刘晓_genia tagger/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/刘晓_genia tagger/" itemprop="url">GENIA Tagger</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="http://www.nactem.ac.uk/tsujii/GENIA/tagger/" title="http://www.nactem.ac.uk/tsujii/GENIA/tagger/" target="_blank" rel="noopener">http://www.nactem.ac.uk/tsujii/GENIA/tagger/</a></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>GENIA Tagger对生物医学文本进行标记、浅解析和命名实体识别。<br>GENIA标记器分析英语句子并输出基本形式，词性标记，块标记和命名实体标记。标记器专门针对生物医学文本（如MEDLINE摘要）进行了调整。如果需要从生物医学文档中提取信息，该标记器可能是一个有用的预处理工具。可以尝试<a href="http://text0.mib.man.ac.uk/software/geniatagger/" target="_blank" rel="noopener">演示页面</a>上的标记器。  </p>
<h2 id="使用教程"><a href="#使用教程" class="headerlink" title="使用教程"></a>使用教程</h2><p><strong>安装：</strong>  </p>
<ul>
<li>下载地址：<a href="http://www.nactem.ac.uk/tsujii/GENIA/tagger/geniatagger-3.0.2.tar.gz" target="_blank" rel="noopener">http://www.nactem.ac.uk/tsujii/GENIA/tagger/geniatagger-3.0.2.tar.gz</a>  </li>
<li>解压文档：tar xvzf geniatagger.tar.gz  </li>
<li><p>Make:  </p>
<pre><code>cd geniatagger  
make
</code></pre></li>
<li><p>标记句子：准备一个每行包含一个句子的文本文件，然后  </p>
</li>
</ul>
<pre><code>./geniatagger &lt; RAWTEXT &gt; TAGGEDTEXT
</code></pre><table>
<thead>
<tr>
<th>word</th>
<th>base</th>
<th>POStag</th>
<th>chunktag</th>
<th>NEtag</th>
</tr>
</thead>
<tbody>
<tr>
<td>word1</td>
<td>base1</td>
<td>POStag1</td>
<td>chunktag1</td>
<td>NEtag1</td>
</tr>
<tr>
<td>word2</td>
<td>base2</td>
<td>POStag2</td>
<td>chunktag2</td>
<td>NEtag2</td>
</tr>
<tr>
<td>  :</td>
<td>:</td>
<td>:</td>
<td>:</td>
<td>:</td>
</tr>
</tbody>
</table>
<p>标记器以以上制表符分隔的格式输出基本形式，词性（POS）标记，块标记和命名实体（NE）标记。<br>块以IOB2格式表示（B表示BEGIN，I表示内部，O表示外部）。</p>
<p><strong>示例：</strong>  </p>
<pre><code>echo &quot;Inhibition of NF-kappaB activation reversed the anti-apoptotic effect of isochamaejasmin.&quot; | ./geniatagger
</code></pre><table>
<thead>
<tr>
<th>word</th>
<th>base</th>
<th>POStag</th>
<th>chunktag</th>
<th>NEtag</th>
</tr>
</thead>
<tbody>
<tr>
<td>Inhibition</td>
<td>Inhibition</td>
<td>NN</td>
<td>B-NP</td>
<td>O</td>
</tr>
<tr>
<td>of</td>
<td>of</td>
<td>IN</td>
<td>B-PP</td>
<td>O</td>
</tr>
<tr>
<td>NF-kappaB</td>
<td>NF-kappaB</td>
<td>NN</td>
<td>B-NP</td>
<td>B-protein</td>
</tr>
<tr>
<td>activation</td>
<td>activation</td>
<td>NN</td>
<td>I-NP</td>
<td>O</td>
</tr>
<tr>
<td>reversed</td>
<td>reverse</td>
<td>VBD</td>
<td>B-VP</td>
<td>O</td>
</tr>
<tr>
<td>the</td>
<td>the</td>
<td>DT</td>
<td>B-NP</td>
<td>O</td>
</tr>
<tr>
<td>anti-apoptotic</td>
<td>anti-apoptotic</td>
<td>JJ</td>
<td>I-NP</td>
<td>O</td>
</tr>
<tr>
<td>effect</td>
<td>effect</td>
<td>NN</td>
<td>I-NP</td>
<td>O</td>
</tr>
<tr>
<td>of</td>
<td>of</td>
<td>IN</td>
<td>B-PP</td>
<td>O</td>
</tr>
<tr>
<td>isochamaejasmin</td>
<td>isochamaejasmin</td>
<td>NN</td>
<td>B-NP</td>
<td>O</td>
</tr>
<tr>
<td>.</td>
<td>.</td>
<td>.</td>
<td>O</td>
<td>O</td>
</tr>
</tbody>
</table>
<p>通过查看块标签，您可以从该输出中轻松提取四个名词短语（“抑制”，“NF-kappaB激活”，“抗凋亡效应”和“isochamaejasmin”）。您还可以使用指定的实体标签查找蛋白质名称。</p>
<h2 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h2><p>[1] S. Kulick, A. Bies, M. Liberman, M. Mandel, R. McDonald, M. Palmer, A. Schein and L. Ungar. Integrated Annotation for Biomedical Information Extraction, HLT/NAACL 2004 Workshop: Biolink 2004, pp. 61-68.<br>[2] Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim, Tomoko Ohta, John McNaught, Sophia Ananiadou, and Jun’ichi Tsujii, Developing a Robust Part-of-Speech Tagger for Biomedical Text, Advances in Informatics - 10th Panhellenic Conference on Informatics, LNCS 3746, pp. 382-392, 2005 (pdf)<br>[3] Yoshimasa Tsuruoka and Jun’ichi Tsujii, Bidirectional Inference with the Easiest-First Strategy for Tagging Sequence Data, Proceedings of HLT/EMNLP 2005, pp. 467-474. (pdf)</p>
<p>上文来源：<a href="http://www.nactem.ac.uk/GENIA/tagger/" target="_blank" rel="noopener">http://www.nactem.ac.uk/GENIA/tagger/</a></p>
<p>GENIA Tagger Demo：<a href="http://text0.mib.man.ac.uk/software/geniatagger/" target="_blank" rel="noopener">http://text0.mib.man.ac.uk/software/geniatagger/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/李华勇_gensim/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/李华勇_gensim/" itemprop="url">Gensim</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="https://radimrehurek.com/gensim/" target="_blank" rel="noopener">https://radimrehurek.com/gensim/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Gensim是一个免费的Python库，它可以用来从文档中自动提取语义主题，并且尽可能地做到轻松（对人）高效（对电脑）。</p>
<p>Gensim致力于处理原始的、非结构化的数字文本（普通文本）。Gensim中用到的算法，如潜在语义分析（Latent Semantic Analysis，LSA）、隐含狄利克雷分配（Latent Dirichlet Allocation，LDA）或随机预测（Random Projections）等，是通过检查单词在训练语料库的同一文档中的统计共现模式来发现文档的语义结构。这些算法都是无监督算法，也就是无需人工输入——你仅需一个普通文本的语料库即可。</p>
<p><img src="https://i.loli.net/2018/04/21/5adb301720070.jpg" alt=""></p>
<h1 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h1><p>内存占用低——任何时候都不会将整个语料库全部读入内存中，可以处理大规模、网络规模的语料库。</p>
<p>有效实现了几种流行的向量空间算法，包括Tf-idf、分布式增量潜在语义分析、分布式增量隐含狄利克雷分配或随机预测；增加新的模型也十分方便（没骗你！）。</p>
<p>预置了几种流行的数据格式的I/O封装器和转换器。</p>
<p>利用文档的语义代表计算其相似性。</p>
<p>整个gensim包围绕语料库（Corpus）、向量（Vector）、模型（Model）三个概念展开。</p>
<h1 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade gensim</span><br></pre></td></tr></table></figure>
<h2 id="tfidf表示"><a href="#tfidf表示" class="headerlink" title="tfidf表示"></a>tfidf表示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">34</span>]: tfidf = models.TfidfModel(corpus) <span class="comment"># step 1 -- initialize a model</span></span><br><span class="line">In [<span class="number">37</span>]: doc_bow = [(<span class="number">0</span>, <span class="number">1</span>), (<span class="number">1</span>, <span class="number">1</span>)]</span><br><span class="line">In [<span class="number">38</span>]: print(tfidf[doc_bow])</span><br><span class="line">[(<span class="number">0</span>, <span class="number">0.7071067811865476</span>), (<span class="number">1</span>, <span class="number">0.7071067811865476</span>)]</span><br><span class="line">In [<span class="number">39</span>]: corpus_tfidf = tfidf[corpus]</span><br><span class="line">In [<span class="number">40</span>]: pprint(corpus_tfidf)</span><br><span class="line">&lt;gensim.interfaces.TransformedCorpus object at <span class="number">0x0129FFD0</span>&gt;</span><br><span class="line">In [<span class="number">41</span>]: <span class="keyword">for</span> doc <span class="keyword">in</span> corpus_tfidf:</span><br><span class="line">    ...:     pprint(doc)</span><br><span class="line">    ...:</span><br></pre></td></tr></table></figure>
<h2 id="lsi表示"><a href="#lsi表示" class="headerlink" title="lsi表示"></a>lsi表示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">42</span>]: lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=<span class="number">2</span>) <span class="comment"># initialize an LSI transformation</span></span><br><span class="line">In [<span class="number">43</span>]: corpus_lsi = lsi[corpus_tfidf] <span class="comment">#  create a double wrapper over the original corpus: bow-&gt;tfidf-&gt;fold-in-lsi</span></span><br><span class="line">In [<span class="number">47</span>]: lsi.print_topics(<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">47</span>]: [(<span class="number">0</span>, <span class="string">'-0.703*"trees" + -0.538*"graph" + -0.402*"minors" + -0.187*"survey" + -0.061*"system" + -0.060*"time" + -0.060*"response" + -0.058*"user" + -0.049*"computer" + -0.035*"interface"'</span>), (<span class="number">1</span>, <span class="string">'-0.460*"system" + -0.373*"user" + -0.332*"eps" + -0.328*"interface" + -0.320*"time" + -0.320*"response" + -0.293*"computer" + -0.280*"human" + -0.171*"survey" + 0.161*"trees"'</span>)]</span><br><span class="line">In [<span class="number">48</span>]: <span class="keyword">for</span> doc <span class="keyword">in</span> corpus_lsi:</span><br><span class="line">    ...:     print(doc)</span><br><span class="line">    ...:</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.066007833960906648</span>), (<span class="number">1</span>, <span class="number">-0.5200703306361848</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.19667592859142974</span>), (<span class="number">1</span>, <span class="number">-0.76095631677000308</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.089926399724468281</span>), (<span class="number">1</span>, <span class="number">-0.72418606267525087</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.075858476521785109</span>), (<span class="number">1</span>, <span class="number">-0.632055158600343</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.10150299184980502</span>), (<span class="number">1</span>, <span class="number">-0.57373084830029464</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.70321089393783032</span>), (<span class="number">1</span>, <span class="number">0.16115180214026176</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.87747876731198216</span>), (<span class="number">1</span>, <span class="number">0.16758906864659895</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.90986246868185694</span>), (<span class="number">1</span>, <span class="number">0.14086553628719531</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.61658253505692839</span>), (<span class="number">1</span>, <span class="number">-0.053929075663890019</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="相似度查询"><a href="#相似度查询" class="headerlink" title="相似度查询"></a>相似度查询</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">49</span>]: <span class="keyword">from</span> gensim <span class="keyword">import</span> similarities</span><br><span class="line">In [<span class="number">50</span>]: index = similarities.MatrixSimilarity(lsi[corpus]) <span class="comment"># transform corpus to LSI space and index it</span></span><br></pre></td></tr></table></figure>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ol>
<li>Khosrovian K, Pfahl D, Garousi V. GENSIM 2.0: a customizable process simulation model for software process evaluation[C]//International Conference on Software Process. Springer, Berlin, Heidelberg, 2008: 294-306.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CNLR</p>
              <p class="site-description motion-element" itemprop="description">语料库、数据集及工具资源和教程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">44</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CNLR</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
