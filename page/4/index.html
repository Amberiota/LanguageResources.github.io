<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="语料库、数据集及工具资源和教程">
<meta property="og:type" content="website">
<meta property="og:title" content="世界语言资源平台">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="世界语言资源平台">
<meta property="og:description" content="语料库、数据集及工具资源和教程">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="世界语言资源平台">
<meta name="twitter:description" content="语料库、数据集及工具资源和教程">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/4/"/>





  <title>世界语言资源平台</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">世界语言资源平台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/13/卢梦依_SemEval2010 Task8 关系抽取数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/13/卢梦依_SemEval2010 Task8 关系抽取数据集/" itemprop="url">SemEval2010 Task8 关系抽取数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-13T21:09:02+05:00">
                2018-05-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依<br>下载地址：<a href="http://semeval2.fbk.eu/semeval2.php?location=data" target="_blank" rel="noopener">http://semeval2.fbk.eu/semeval2.php?location=data</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>SemEval-2010的任务8关注的是两个名词之间的语义关系。例如，茶和人参是在“从德里人参的杯子里”的一种物质来源关系中。语义关系的自动识别有许多应用，如信息提取、文档摘要、机器翻译、词汇和语义网络的构建等。它还可以促进辅助任务，如wordsense消除歧义、语言建模、语法分析和识别文本蕴涵。<br>有9种关系如下所示:</p>
<p><strong>Cause-Effect (CE)</strong>.An event or object leads to an effect. Example: those cancers were caused by radiation exposures.因果关系</p>
<p><strong>Instrument-Agency (IA).</strong> An agent uses an instrument. Example: phone operator</p>
<p><strong>Product-Producer (PP)</strong>.A producer causes a product to exist. Example: a factory manufactures suits 生产与被生产的关系</p>
<p><strong>Content-Container (CC)</strong>.An object is physically stored in a delineated area of space. Example:a bottle full of honey was weighed 容器与内容物的关系</p>
<p><strong>Entity-Origin (EO)</strong>.An entity is coming or is derived from an origin (e.g., position or mate-rial) Example:letters from foreign countries 实体来自或源自原产地（例如，位置或材料）</p>
<p><strong>Entity-Destination (ED)</strong>.An entity is moving towards a destination. Example: the boy went to bed 一个实体正在向目的地移动。 例如：男孩去睡觉</p>
<p><strong>Component-Whole (CW)</strong>.An object is a component of a larger whole. Example: my apartment has a large kitchen 组件到整体</p>
<p><strong>Member-Collection (MC)</strong>.A member forms anonfunctional part of a collection. Example:there are many trees in the forest 成员集合关系（MC），成员构成集合的非功能部分。 例如：森林里有很多树</p>
<p><strong>Message-Topic (MT)</strong>.A message, written or spoken, is about a topic. Example: the lecture was about semantics 。信息与主题 例如：讲座是关于语义的。</p>
<p>各占比例如下图：</p>
<p><img src="https://i.loli.net/2018/05/06/5aef10ccf1817.jpg" alt=""></p>
<h1 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h1><p> 类型：txt文本<br>train data: 1370KB<br>test data: 342KB<br>文件格式：”The <e1>news</e1> brought about a <e2>commotion</e2> in the office.这段话标明两个实体（news，commotion）这两个实体之间的关系是Cause-Effect(e1,e2)。因果果关系。</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Zeng D, Liu K, Chen Y, et al. Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks[C]// Conference on Empirical Methods in Natural Language Processing. 2015:1753-1762.<br>2.Cai R, Zhang X, Wang H. Bidirectional Recurrent Convolutional Neural Network for Relation Classification[C]// Meeting of the Association for Computational Linguistics. 2016:756-765.<br>3.Miwa M, Bansal M. End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures[J]. 2016.<br>4.Zhou P, Shi W, Tian J, et al. Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification[C]// Meeting of the Association for Computational Linguistics. 2016:207-212.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/12/刘唯_STL-10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/12/刘唯_STL-10/" itemprop="url">STL-10</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-12T18:02:00+05:00">
                2018-05-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>STL-10 是一个图像数据集，包含 10 类物体的图片，每类 1300 张图片，500 张训练，800 张测试，每张图片分辨率为 96x96。除了具有类别标签的图片之外，还有 100000 张无类别信息的图片。</p>
<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a href="https://cs.stanford.edu/~acoates/stl10/" target="_blank" rel="noopener">https://cs.stanford.edu/~acoates/stl10/</a></p>
<h1 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h1><p>2.46 Gb</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Yoshihiro Shima. Image Augmentation for Object Image Classification Based On Combination of Pre-Trained CNN and SVM[J]. Journal of Physics: Conference Series,2018,1004(1).<br>[2]Yazhou Yao,Jian Zhang,Fumin Shen,Xiansheng Hua,Jingsong Xu,Zhenmin Tang. A new web-supervised method for image dataset constructions[J]. Neurocomputing,2016.<br>[3]Kristo,Chin Seng Chua. Cost effective window arrangement for spatial pyramid matching[J]. Journal of Visual Communication and Image Representation,2015,29.<br>[4]Yunong Wang,Nenghai Yu,Taifeng Wang. Ada-Sal Network: emulate the Human Visual System[J]. Signal Processing: Image Communication,2016,47.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/刘晓_COIL-20/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/刘晓_COIL-20/" itemprop="url">COIL-20 数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T17:37:46+05:00">
                2018-05-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>下载地址：<a href="http://www.cs.columbia.edu/CAVE/software/softlib/coil-20.php" target="_blank" rel="noopener">http://www.cs.columbia.edu/CAVE/software/softlib/coil-20.php</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>COIL-20 数据集是彩色图片集合，包含对 20 个物体从不同角度的拍摄，每隔 5 度拍摄一副图像，每个物体 72 张图像。每张图像大小进行了统一处理为 128x128。数据集包含两个子集。第一组 包含 10 个对象的总共 720 张未处理图像。第二组包含 20 个对象处理后的总共 1440 张图像。<br><img src="https://i.loli.net/2018/05/11/5af5910ed488d.jpg" alt=""></p>
<h1 id="数据集大小"><a href="#数据集大小" class="headerlink" title="数据集大小"></a>数据集大小</h1><p>12.40 Mb  </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] C Rate ， C Retrieval, Columbia Object Image Library (COIL-20) ,《Computer》 , 2011<br>[2]TV Hoang ， S Tabbone, Generic R-transform for invariant pattern representation, International Workshop on Content-based Multime… , 2011 :157-162</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/李华勇_Large Movie Review Dataset/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/李华勇_Large Movie Review Dataset/" itemprop="url">Large Movie Review Dataset</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T17:37:46+05:00">
                2018-05-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="http://ai.stanford.edu/~amaas/data/sentiment/" target="_blank" rel="noopener">http://ai.stanford.edu/~amaas/data/sentiment/</a></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h1><p>在自然语言处理中，情感分析一般是指判断一段文本所表达的情绪状态。其中，一段文本可以是一个句子，一个段落或一个文档。情绪状态可以是两类，如（正面，负面），（高兴，悲伤）；也可以是三类，如（积极，消极，中性）等等。情感分析的应用场景十分广泛，如把用户在购物网站（亚马逊、天猫、淘宝等）、旅游网站、电影评论网站上发表的评论分成正面评论和负面评论；或为了分析用户对于某一产品的整体使用感受，抓取产品的用户评论并进行情感分析等等。<br><img src="https://i.loli.net/2018/05/14/5af92d39c4595.jpg" alt=""></p>
<h1 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h1><p>这是一个二进制情绪分类数据集，其中包含比以前的基准数据集更多的数据。我们提供了一套25,000个的电影评论进行培训，25,000个进行测试。还有其他未标记的数据也可以使用。提供原始文本和已处理的文字格式包。</p>
<p>IMDB数据集的训练集和测试集分别包含25000个已标注过的电影评论。其中，负面评论的得分小于等于4，正面评论的得分大于等于7，满分10分。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">aclImdb</span><br><span class="line">|- test</span><br><span class="line">   |-- neg</span><br><span class="line">   |-- pos</span><br><span class="line">|- train</span><br><span class="line">   |-- neg</span><br><span class="line">   |-- pos</span><br></pre></td></tr></table></figure></p>
<h1 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h1><p><a href="http://ai.stanford.edu/~amaas/data/sentiment/" target="_blank" rel="noopener">http://ai.stanford.edu/~amaas/data/sentiment/</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><ol>
<li>Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/刘晓_NORB v1.0 图像数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/刘晓_NORB v1.0 图像数据/" itemprop="url">NORB v1.0 图像数据</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T17:37:46+05:00">
                2018-05-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>下载地址：<a href="http://cs.nyu.edu/~ylclab/data/norb-v1.0/" target="_blank" rel="noopener">http://cs.nyu.edu/~ylclab/data/norb-v1.0/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>NORB 是 3D 物体图像识别数据集。从不同的角度对 5 大类别（四条腿的动物、人像、飞机、卡车、小汽车）中的 50 个玩具模型进行图像拍摄。拍摄采用了 2 个照相机，6 种不同的光照条件，9 个特定的拍摄角度， 18 个仰角。 训练集合中包括每个类别的 5 个实例，余下 5 个实例为测试集。该数据库用于研究目的。它不能被出售。  </p>
<h1 id="数据集内容"><a href="#数据集内容" class="headerlink" title="数据集内容"></a>数据集内容</h1><p>文件便于下载已被处理成压缩。在未压缩之后，它们是一个简单的二进制矩阵格式，带有文件后缀“.mat”。文件格式将在后面的部分中解释。“-dat”文件存储图像序列。“-cat”文件存储图像的相应类别。每个“-dat”文件存储了29,160个图像对(6个类别，5个实例，6个lightings, 9个特定的拍摄角度，18个方位角)。第6类是没有对象的图像，可以用来训练系统拒绝图像，因为这5个对象类别都没有。每个对应的“-cat”文件包含29,160个类别标签(动物为0，人为1，飞机为2，卡车为3，汽车为4，空白为5)。<br>每个“-info”文件存储了29,160个10维向量，其中包含了关于相应图像的额外信息。向量的前四个元素是:  </p>
<ul>
<li>类别中的实例(0到9)  </li>
<li>高程(0到8，意味着摄像机分别为30、35、40、45、50、55、60、65、70度)  </li>
<li>3。方位角(0、2、4,……，34，乘以10，得到角度的方位角)  </li>
<li>4。照明条件(0至5)  </li>
</ul>
<p>接下来的6个元素描述了在一个杂乱的背景上叠加在物体上的微扰。  </p>
<h1 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a>文件格式</h1><p>这些文件存储在所谓的“二进制矩阵”文件格式中，这是一种简单的矢量格式和各种元素类型的多维矩阵。二进制矩阵文件首先是一个文件头，它描述了矩阵的类型和大小，然后是矩阵的二进制图像。<br>注意，当矩阵小于3维时，比如说，它是一维向量，然后是dim[1]和dim[2]都是1。当矩阵有超过3个维度时，标题将被进一步的尺寸信息。否则，在文件头出现后，将在最后一个维度中以索引存储的矩阵数据变化最快。  </p>
<p>这是一张 “norb-5x46789x9x18x6x2x108x108-training-10-dat.mat”文件中前30张图片的截图。，按顺序排列，从左到右(列主要)。下面的标题显示了相应的 “-cat.mat” 和 “-info.mat” 的内容。它们是”category / instance / elevation / azimuth / lighting”。对于背景图像，后面的4个数字都是-1。    </p>
<p><img src="https://i.loli.net/2018/05/11/5af598679d179.jpg" alt="">  </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Y. LeCun, F.J. Huang, L. Bottou, Learning Methods for Generic Object Recognition with Invariance to Pose and Lighting. CVPR 2004</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/刘晓_Visual7W 图像数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/刘晓_Visual7W 图像数据/" itemprop="url">Visual7W 图像数据</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T17:37:46+05:00">
                2018-05-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>下载地址：<a href="http://web.stanford.edu/~yukez/visual7w/" target="_blank" rel="noopener">http://web.stanford.edu/~yukez/visual7w/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Visual7W 图像数据是一个图像内容理解的数据集，通过对图像区域的文字描述和互相之间的关联，进行视觉问答（Visual Question Answering）任务，数据集中不仅包含图像本身，还包括图像内容的区域内容的问答。Visual7W是Visual Genome的一个子集，包含47,300张图像。Visual7W的问题主要由What, Where, How, When, Who,Why, and Which构成。Visual7W的问题是多选问题，每个问题都有四个候选答案。  </p>
<p><img src="https://i.loli.net/2018/05/11/5af59a6e24fb7.jpg" alt=""></p>
<h1 id="文件类型"><a href="#文件类型" class="headerlink" title="文件类型"></a>文件类型</h1><p>多文件压缩包  </p>
<p>#文件大小<br>1.77Gb  </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Yuke Zhu, Oliver Groth, Michael Bernstein and Li Fei-Fei, Visual7W: Grounded Question Answering in Images</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/李华勇_coNLL05SRL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/李华勇_coNLL05SRL/" itemprop="url">语义角色标注数据集CoNLL 2005SRL</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T17:37:46+05:00">
                2018-05-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="http://www.cs.upc.edu/~srlconll/" target="_blank" rel="noopener">http://www.cs.upc.edu/~srlconll/</a></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h1><p>自然语言分析技术大致分为三个层面：词法分析、句法分析和语义分析。语义角色标注是实现浅层语义分析的一种方式。在一个句子中，谓词是对主语的陈述或说明，指出“做什么”、“是什么”或“怎么样，代表了一个事件的核心，跟谓词搭配的名词称为论元。语义角色是指论元在动词所指事件中担任的角色。主要有：施事者（Agent）、受事者（Patient）、客体（Theme）、经验者（Experiencer）、受益者（Beneficiary）、工具（Instrument）、处所（Location）、目标（Goal）和来源（Source）等。</p>
<p>请看下面的例子，“遇到” 是谓词（Predicate，通常简写为“Pred”），“小明”是施事者（Agent），“小红”是受事者（Patient），“昨天” 是事件发生的时间（Time），“公园”是事情发生的地点（Location）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[小明]Agent[昨天]Time[晚上]Time在[公园]Location[遇到]Predicate了[小红]Patient。</span><br></pre></td></tr></table></figure>
<p>语义角色标注（Semantic Role Labeling，SRL）以句子的谓词为中心，不对句子所包含的语义信息进行深入分析，只分析句子中各成分与谓词之间的关系，即句子的谓词（Predicate）- 论元（Argument）结构，并用语义角色来描述这些结构关系，是许多自然语言理解任务（如信息抽取，篇章分析，深度问答等）的一个重要中间步骤。在研究中一般都假定谓词是给定的，所要做的就是找出给定谓词的各个论元和它们的语义角色。</p>
<h1 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h1><p>我们选用CoNLL 2005SRL任务开放出的数据集作为示例。需要特别说明的是，CoNLL 2005 SRL任务的训练数集和开发集在比赛之后并非免费进行公开，目前，能够获取到的只有测试集，包括Wall Street Journal的23节和Brown语料集中的3节。</p>
<p>原始数据中同时包括了词性标注、命名实体识别、语法解析树等多种信息。<br><img src="https://i.loli.net/2018/05/14/5af92c15cf06b.jpg" alt=""><br>原始数据需要进行数据预处理才能被使用，预处理包括下面几个步骤:</p>
<ol>
<li>将文本序列和标记序列其合并到一条记录中；</li>
<li>一个句子如果含有n个谓词，这个句子会被处理n次，变成n条独立的训练样本，每个样本一个不同的谓词；</li>
<li>抽取谓词上下文和构造谓词上下文区域标记；</li>
<li>构造以BIO法表示的标记；</li>
<li>依据词典获取词对应的整数索引。</li>
</ol>
<p>预处理完成之后一条训练样本包含9个特征，分别是：句子序列、谓词、谓词上下文（占 5 列）、谓词上下区域标志、标注序列。下表是一条训练样本的示例。<br><img src="https://i.loli.net/2018/05/14/5af92c2e73f5e.jpg" alt=""></p>
<h1 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h1><p><a href="http://www.cs.upc.edu/~srlconll/soft.html" target="_blank" rel="noopener">http://www.cs.upc.edu/~srlconll/soft.html</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><ol>
<li>Carreras X, Màrquez L. Introduction to the CoNLL-2005 shared task: Semantic role labeling[C]//Proceedings of the ninth conference on computational natural language learning. Association for Computational Linguistics, 2005: 152-164.</li>
<li>Palmer M, Gildea D, Xue N. Semantic role labeling[J]. Synthesis Lectures on Human Language Technologies, 2010, 3(1): 1-103.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/刘晓_Caltech-UCSD Birds 200 鸟类图像数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/刘晓_Caltech-UCSD Birds 200 鸟类图像数据/" itemprop="url">Caltech-UCSD Birds 200 鸟类图像数据</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T17:37:46+05:00">
                2018-05-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>下载地址:<a href="http://www.vision.caltech.edu/visipedia/CUB-200-2011.html" target="_blank" rel="noopener">http://www.vision.caltech.edu/visipedia/CUB-200-2011.html</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Caltech-UCSD Birds 200 是一个鸟类图片数据集，包含 200 不同种鸟类，共计 11788 张图片。<br>Caltech-UCSD Birds-200-2011 (CUB-200-2011)是CUB-200数据集的扩展版本，每个类的图像数量大约是两倍，新的部分位置标注。有关数据集的详细信息，请参见下面链接的技术报告。  </p>
<ul>
<li>种类数量： 200  </li>
<li>图像数量：11,788  </li>
<li>每个图像的注释:15部分位置，312个二进制属性，1个边界框。</li>
</ul>
<p><img src="https://i.loli.net/2018/05/11/5af59444719b4.jpg" alt="">   </p>
<h1 id="文件类型"><a href="#文件类型" class="headerlink" title="文件类型"></a>文件类型</h1><p>多文件压缩包  </p>
<h1 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h1><p>1.12Gb  </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Wah C., Branson S., Welinder P., Perona P., Belongie S. “The Caltech-UCSD Birds-200-2011 Dataset.” Computation &amp; Neural Systems Technical Report, CNS-TR-2011-001. <a href="http://www.vision.caltech.edu/visipedia/papers/CUB_200_2011.pdf" target="_blank" rel="noopener">download pdf</a><br>[2] Goering, C., Rodner, E., Freytag, A., Denzler, J., “Nonparametric Part Transfer for Fine-grained Recognition”, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2014.<br>[3] Wah, C., Van Horn, G., Branson, S., Maji, S., Perona, P., Belongie, S., “Similarity Comparisons for Interactive Fine-Grained Categorization”, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2014.<br>[4] Berg T., Belhumeur P., “POOF: Part-Based One-vs-One Features for Fine-Grained Categorization, Face Verification, and Attribute Estimation”, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2013.<br>[5] Chai, Y., Lempitsky, V., Zisserman, A., “Symbiotic Segmentation and Part Localization for Fine-Grained Categorization”, IEEE International Conference on Computer Vision (ICCV), Sydney, Australia, 2013.<br>[6] Gavves E., Fernando B., Snoek C., Smeulders A., Tuytelaars T., “Fine-Grained Categorization by Alignments”, IEEE International Conference on Computer Vision (ICCV), Sydney, Australia, 2013.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/杜成玉_KITTI数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/杜成玉_KITTI数据集/" itemprop="url">KITTI数据集及简介</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T15:37:46+05:00">
                2018-05-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：杜成玉<br>下载地址：<a href="http://www.cvlibs.net/datasets/kitti/" target="_blank" rel="noopener">http://www.cvlibs.net/datasets/kitti/</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>数据来源：<a href="https://blog.csdn.net/solomon1558/article/details/70173223" target="_blank" rel="noopener">https://blog.csdn.net/solomon1558/article/details/70173223</a><br>KITTI数据集由德国卡尔斯鲁厄理工学院和丰田美国技术研究院联合创办，是目前国际上最大的自动驾驶场景下的计算机视觉算法评测数据集。该数据集用于评测立体图像(stereo)，光流(optical flow)，视觉测距(visual odometry)，3D物体检测(object detection)和3D跟踪(tracking)等计算机视觉技术在车载环境下的性能。KITTI包含市区、乡村和高速公路等场景采集的真实图像数据，每张图像中最多达15辆车和30个行人，还有各种程度的遮挡与截断。整个数据集由389对立体图像和光流图，39.2 km视觉测距序列以及超过200k 3D标注物体的图像组成[1] ，以10Hz的频率采样及同步。总体上看，原始数据集被分类为’Road’, ’City’, ’Residential’, ’Campus’ 和 ’Person’。对于3D物体检测，label细分为car, van, truck, pedestrian, pedestrian(sitting), cyclist, tram以及misc组成。</p>
<h1 id="数据采集平台"><a href="#数据采集平台" class="headerlink" title="数据采集平台"></a>数据采集平台</h1><p>如图-1所示，KITTI数据集的数据采集平台装配有2个灰度摄像机，2个彩色摄像机，一个Velodyne 64线3D激光雷达，4个光学镜头，以及1个GPS导航系统。具体的传感器参数如下[2] ：<br>·2 × PointGray Flea2 grayscale cameras (FL2-14S3M-C), 1.4 Megapixels, 1/2” Sony ICX267 CCD, global shutter<br>·2 × PointGray Flea2 color cameras (FL2-14S3C-C), 1.4 Megapixels, 1/2” Sony ICX267 CCD, global shutter<br>·4 × Edmund Optics lenses, 4mm, opening angle ∼ 90◦, vertical opening angle of region of interest (ROI) ∼ 35◦<br>·1 × Velodyne HDL-64E rotating 3D laser scanner, 10 Hz, 64 beams, 0.09 degree angular resolution, 2 cm distance accuracy, collecting ∼ 1.3 million points/second, field of view: 360◦ horizontal, 26.8◦ vertical, range: 120 m<br>·1 × OXTS RT3003 inertial and GPS navigation system, 6 axis, 100 Hz, L1/L2 RTK, resolution: 0.02m / 0.1◦<br><img src="https://i.loli.net/2018/05/11/5af5a5bb7e0fc.jpg" alt=""><br>如图-2所示为传感器的配置平面图。为了生成双目立体图像，相同类型的摄像头相距54cm安装。由于彩色摄像机的分辨率和对比度不够好，所以还使用了两个立体灰度摄像机，它和彩色摄像机相距6cm安装。为了方便传感器数据标定，规定坐标系方向如下[2] ：<br>• Camera: x = right, y = down, z = forward<br>• Velodyne: x = forward, y = left, z = up<br>• GPS/IMU: x = forward, y = left, z = up<br><img src="https://i.loli.net/2018/05/11/5af5a5f1c7cf1.jpg" alt=""></p>
<h1 id="Dataset详述"><a href="#Dataset详述" class="headerlink" title="Dataset详述"></a>Dataset详述</h1><p>图-3展示了KITTI数据集的典型样本，分为 ’Road’, ’City’, ’Residential’, ’Campus’ 和’Person’五类。原始数据采集于2011年的5天，共有180GB数据。<br><img src="https://i.loli.net/2018/05/11/5af5a6305edf6.jpg" alt=""></p>
<h1 id="数据组织形式"><a href="#数据组织形式" class="headerlink" title="数据组织形式"></a>数据组织形式</h1><p>论文[2] 中提及的数据组织形式，可能是早期的版本，与目前KITTI数据集官网公布的形式不同，本文稍作介绍。 如图-4所示，一个视频序列的所有传感器数据都存储于data_drive文件夹下，其中date和drive是占位符，表示采集数据的日期和视频编号。时间戳记录在Timestamps.txt文件。<br><img src="https://i.loli.net/2018/05/11/5af5a66dd0ff0.jpg" alt=""></p>
<h1 id="Annotations"><a href="#Annotations" class="headerlink" title="Annotations"></a>Annotations</h1><p>KITTI数据集为摄像机视野内的运动物体提供一个3D边框标注（使用激光雷达的坐标系）。该数据集的标注一共分为8个类别：’Car’, ’Van’, ’Truck’, ’Pedestrian’, ’Person (sit- ting)’, ’Cyclist’, ’Tram’ 和’Misc’ (e.g., Trailers, Segways)。论文[2] 中说明了3D标注信息存储于date_drive_tracklets.xml，每一个物体的标注都由所属类别和3D尺寸（height，weight和length）组成。当前数据集的标注存于每种任务子数据集的label文件夹中，稍有不同。<br>为了说明KITTI数据集的标注格式，本文以Object detection任务的数据集为例。数据说明在Object development kit的readme.txt文档中。从标注数据的链接 training labels of object data set (5 MB)下载数据，解压文件后进入目录，每张图像对应一个.txt文件。一帧图像与其对应的.txt标注文件如图-5所示。<br><img src="https://i.loli.net/2018/05/11/5af5a6c0d6501.jpg" alt=""><br><img src="https://i.loli.net/2018/05/11/5af5a6ef28c4a.jpg" alt=""></p>
<h1 id="Development-Kit"><a href="#Development-Kit" class="headerlink" title="Development Kit"></a>Development Kit</h1><p>KITTI各个子数据集都提供开发工具 development kit，主要由cpp文件夹，matlab文件夹，mapping文件夹和readme.txt组成。下图以object detection任务的文件夹devkit_object为例，可以看到cpp文件夹主要包含评估模型的源代码evaluate_object.cpp。Mapping文件夹中的文件记录训练集到原始数据集的映射，从而开发者能够同时使用激光雷达点云，gps数据，右边彩色摄像机数据以及灰度摄像机图像等多模态数据。Matlab文件夹中的工具包含读写标签，绘制2D/3D标注框，运行demo等工具。Readme.txt文件非常重要，详述介绍了某个子数据集的数据格式，benchmark介绍，结果评估方法等详细内容。<br><img src="https://i.loli.net/2018/05/11/5af5a7436a585.jpg" alt=""></p>
<h1 id="评价准则Evaluation-Metrics"><a href="#评价准则Evaluation-Metrics" class="headerlink" title="评价准则Evaluation Metrics"></a>评价准则Evaluation Metrics</h1><p><img src="https://i.loli.net/2018/05/11/5af5a7936fa1d.jpg" alt=""><br><img src="https://i.loli.net/2018/05/11/5af5a7ae45874.jpg" alt=""><br><img src="https://i.loli.net/2018/05/12/5af69314cd9a7.jpg" alt=""><br><img src="https://i.loli.net/2018/05/12/5af692e01bb9d.jpg" alt=""></p>
<h1 id="数据使用实践"><a href="#数据使用实践" class="headerlink" title="数据使用实践"></a>数据使用实践</h1><p>KITTI数据集的标注信息更加丰富，在实际使用中可能只需要一部分字段，或者需要转换成其他数据集的格式。例如可以将KITTI数据集转换成PASCAL VOC格式，从而更方便地使用Faster RCNN或者SSD等先进的检测算法进行训练。转换KITTI数据集需要注意源数据集和目标数据集的格式，类别标签的重新处理等问题，实现细节建议参考Jesse_Mx[4] 和github上manutdzou的开源项目[5] ，这些资料介绍了转换KITTI数据集为PASCAL VOC格式，从而方便训练Faster RCNN或者SSD等模型。</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Andreas Geiger and Philip Lenz and Raquel Urtasun. Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite. CVPR, 2012<br>[2] Andreas Geiger and Philip Lenz and Christoph Stiller and Raquel Urtasun. Vision meets Robotics: The KITTI Dataset. IJRR, 2013<br>[3] M. Everingham, L.Van Gool, C. K. I.Williams, J.Winn, and A. Zisserman. The PASCAL Visual Object Classes Challenge 2011 (VOC2011) Results.<br>[4] Jesse_Mx.SD: Single Shot MultiBox Detector 训练KITTI数据集（1）.<br><a href="http://blog.csdn.net/jesse_mx/article/details/65634482" target="_blank" rel="noopener">http://blog.csdn.net/jesse_mx/article/details/65634482</a><br>[5]manutdzou.manutdzou/KITTI_SSD.<a href="https://github.com/manutdzou/KITTI_SSD" target="_blank" rel="noopener">https://github.com/manutdzou/KITTI_SSD</a> </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/10/朱述承_香港二十世纪中期粤语语料库/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/10/朱述承_香港二十世纪中期粤语语料库/" itemprop="url">香港二十世纪中期粤语语料库</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-10T09:37:00+05:00">
                2018-05-10
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：朱述承</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>过去的粤方言历时研究主要参考19世纪至20世纪中期的文字材料。部分出现在早期材料的语言特征，如完成体标记「哓」(Cheung, 1997, 郭必之和片冈新, 2006)、中性问句的VP-Neg句型(Yue, 2004, Cheung, 2001) 和间接宾语标记「过」和工具标记「畀」(Chin, 2009)等，大多在二十世纪二三十年代后逐渐消失或只散见于个别现代粤方言中。换句话说，二十世纪中期很可能是这些新旧语言特徵交替的时期。如果我们能够收集相关时期的语料，就可以增加我们对粤语发展的了解。除了从个别发音人收集方言语料之外，很多学者也使用自然语料，如香港大学语言学系上世纪九十年代构建的香港粤语语料库(The Hong Kong University Cantonese Corpus (Luke, 2011)，梁文德和罗心宝构建的The Hong Kong Cantonese Adult Language Corpus (Leung and Law, 2001)。也有学者透过多媒体（如电视剧、电台广播剧和电影）收集语料(如Chan, 1996, 欧阳伟豪, 2006, 梁仲森, 2005等)。 要收集二十世纪中期粤语的语料，我们可以从香港电影出发。香港电影业在五六十年代十分蓬勃，十多年间，生产了一千五百多部电影(锺宝贤, 2007)，一般称为「粤语长片」。有学者（如刘镇发和萧佩珊, 2010, 李雄溪和许子滨, 2005）曾经从粤语长片分析早期粤语的面貌。不过这些研究只根据研究者的兴趣而收集和分析个别语言特徵。背后缺乏一个有系统的语料库。 基于以上背景，香港教育学院（现为香港教育大学）语言学及现代语言系过去一年构建了一个以香港五六十年代的粤语长片为基础的语料库。语料库共有二十一套电影（其中十四套可供检索，见下表），每套电影长度约100分钟，电影中的对白用汉字转写，然后进行切词和校对，每个词语配有粤语读音(以香港语言学学会的「粤拼」为基础)。语料库共计约二十万字，并提供不同条件（如词汇、拼音、电影、影星等）的检索。</p>
<h1 id="访问地址"><a href="#访问地址" class="headerlink" title="访问地址"></a>访问地址</h1><p><a href="http://corpus.ied.edu.hk/hkcc/" target="_blank" rel="noopener">http://corpus.ied.edu.hk/hkcc/</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1、欧阳伟豪. (2006). 从周星驰对白的旧粤语到动词后置成份的句法构筑. 《香港语言学学会-粤语讨论会(WOC-5)：从社会语言学看粤语近代的转变》. 香港中文大学. 2006.4.29.<br>2、锺宝贤. (2007). 《香港影视业百年》. 香港 : 三联书店.<br>3、郭必之、片冈新. (2006). 早期广州话完成体标记「哓」的来源和演变。 《中国文化研究所学报》第46期, 91-116页。<br>4、刘镇发, 萧佩珊. (2010). 香港语言变化的探讨：透过六十年代粤语电影比较今昔粤语语音. 《第十五届国际粤方言研讨会》. 澳门. 2010.12.13-15.<br>5、李雄溪, 许子滨. (2005). 五、六十年代香港粤语电影语言研究——以语气词「遮」、「啫」为例. 《第十届国际粤方言研讨会》. 香港中文大学. 2005.12.12-14.<br>6、梁仲森. (2005). 《当代香港粤语语助词的研究》. 香港：香港城市大学语言资讯科学研究中心.<br>7、Chan, Marjorie. (2006). “Gender-marked speech in Cantonese: the case of sentence-final particles je and jek.” Studies in the Linguistic Sciences, 26.1/2: 1-38.<br>8、Cheung, Hung-nin Samuel. (1997). “Completing the completive: (Re)constructing early Cantonese grammar”. In Chaofen Sun ed., Studies on the History of Chinese Syntax, Journal of Chinese Linguistics Monograph, Series No.10, pp. 133-165.<br>9、Cheung, Hung-nin Samuel. (2001). “The interrogative construction: (Re)constructing early Cantonese grammar”. In H. Chappell, ed., Sinitic Grammar: Synchronic and Diachronic Perspectives. Oxford: Oxford University Press, pp. 191-231.<br>10、Chin, Andy Chi-on (钱志安). (2009). The Verb GIVE and the Double-object Construction in Cantonese in Synchronic, Diachronic and Typological Perspectives. PhD dissertation, University of Washington.<br>11、Luke, Kang Kwong. (2011). “The Hong Kong Cantonese corpus: Design and uses (香港粤语语料库的设计和用途)”. Paper presented at the Roundtable Conference on Linguistic Corpus and Corpus Linguistics in the Chinese Context 《汉语语料库及语料库语言学圆桌会议》, The Hong Kong Institute of Education, Hong Kong, May 6 – 8 2011.<br>12、Yue, Anne. (2004). “Materials for the diachronic study of the Yue dialects”. In Shi Feng and Shen Zhongwei, eds., The Joy of Research: A Festschrift in Honor of Professor William S-Y. Wang on His Seventieth Birthday《乐在其中 - 王士元教授七十华诞庆祝文集》. Nankai: Nankai University, pp. 246-271. </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CNLR</p>
              <p class="site-description motion-element" itemprop="description">语料库、数据集及工具资源和教程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">133</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CNLR</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
