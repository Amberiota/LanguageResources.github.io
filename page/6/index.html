<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="语料库、数据集及工具资源和教程">
<meta property="og:type" content="website">
<meta property="og:title" content="世界语言资源平台">
<meta property="og:url" content="http://yoursite.com/page/6/index.html">
<meta property="og:site_name" content="世界语言资源平台">
<meta property="og:description" content="语料库、数据集及工具资源和教程">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="世界语言资源平台">
<meta name="twitter:description" content="语料库、数据集及工具资源和教程">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/6/"/>





  <title>世界语言资源平台</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">世界语言资源平台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/03/朱述承_搜文解字/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/03/朱述承_搜文解字/" itemprop="url">搜文解字</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-03T15:37:46+05:00">
                2018-06-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：朱述承<br>访问地址：<a href="http://words.sinica.edu.tw/" target="_blank" rel="noopener">http://words.sinica.edu.tw/</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>“搜文解字”是台湾中央研究院语言学研究所筹备处文献语料库研究室、历史语言研究所金文资料库工作室、资讯科学研究所词库小组文字处理组、元智大学／华典籍网路系统研究室联合开发的语文参考室，不但可以检索新 词读音、词义、用法出处的线上工具书，也可提供相关 的语言、文字、与文学知识。共含四个部份：<br>　　『搜﹝搜词寻字﹞』　『文﹝文学之美﹞』<br>　　『解﹝游戏解惑﹞』　『字﹝古文字的世界﹞』</p>
<h1 id="系统说明"><a href="#系统说明" class="headerlink" title="系统说明"></a>系统说明</h1><p>◎搜词寻字：是个网路上的词典工具书，提供多样多功能的检索方式。<br>◎文学之美：是线上的文学知识中心，不但可以浏览古典文学作品也提供了多媒体、多面向的讯息。<br>◎游戏解惑：把各种语文知识融合到机智问答、文字接龙、文字智慧拼盘等游戏中。<br>◎古文字的世界：则由甲骨文、金文、到东周文字，细述汉字的来源、演变及意义。 </p>
<h1 id="系统介绍"><a href="#系统介绍" class="headerlink" title="系统介绍"></a>系统介绍</h1><p>本系统以平易近人的人机介面呈现语文知识，是一部中文的新世代网上数位语文字典。在「搜文解字」这个虚拟参考室的检词部份裡，包含了多种不同时代的词汇资料库与词典，现已扩充至历代典籍如《论语》、《孟子》、《老子》、《庄子》及《红楼梦》、《全唐诗》等古籍。未来仍可随时扩充，连接新的语文知识资料。经由多种搜寻途径，更使读者能轻易从线上取得所需的语文知识。<br>本系统在「搜文解字」大计画下连结「平衡语料库」，为一个以语境为贵的语词检索系统，并附加了生动的线上即时辅佐救援，随时预备为您排难解疑。而轻松地在查询工作进行的同时，亦增加一点儿语文小知识。此外，利用造词、注音、词语出处等方法加以搜寻，不但涵盖一般传统辞典所能提供您的结果，还有典籍原文出处的同步一贯查询，以及新创以语料有五百万词之多的语料库为基础，提供语境上下文来突显关键词语法和语义的相关信息，更是「字字珠玑」系统的特色。希望这个系统能帮网友在上网游环宇之余，也可轻松提升自己的中国语文素养。<br>本系统之应用，以「字」、「词」、「文」为三大检索途径，各途径下又分列不同的搜寻条件，兹简述并示例如下：<br>〈一〉字：依文字之形、音、义分为字形搜寻、音韵搜寻、字典<br>（1〉字形搜寻：<br>　　　〈a〉部件搜寻－依据「含有某部件」、「字首为某部件」及「字尾为某部件」搜寻所需文字。<br>　　 　　　例如：所有含「力」部件的文字：功、加、力…<br>                 字首为「力」部件的文字：加、力…<br>　　      　　     字尾为「力」部件的文字：功、劳、力…<br>　　　〈b〉部首笔画搜寻－根据部首、笔画或总笔画搜寻所需文字<br>　　　　　 例如：「力」部，三画者：功、加…<br>　　　　　        总笔画五画者：功、加、付…<br>〈2〉音韵搜寻：依据文字之韵母、声母、声调或汉语拼音检索所需文字<br>　　　　　 例如：韵母为ㄢ者：沾、山…<br>      　　　     声母为ㄆ者：喷、扑…<br>　　　           声调为二声者：人、平…<br>      　　　     汉语拼音为zi4者：字、渍…<br>〈3〉字典：在「字典」功能中，输入欲查文字，即可同时显示文字之形、音、义。<br>　　　     例如：「丁」：<br>　　　                  解形－《说文》：「丁，夏时万物皆丁实。象形。丁承丙，象人心。」<br>　　　　　　            《通训定声》：「丁，鐕也。象形。今俗以钉为之，其质用金或竹若木。<br>　　　                  注音－ding1。《广韵》：当经切，平青端。耕部。<br>　　　                  释义：（1）天干的第四位，与地支相配，用以纪年、月、日。<br>　　　　　　                  （2）序数第四的代称。<br>　　　　　　                  （3）钉子。<br>　　　　　　                  （4）……<br>〈二〉词：由形式、音韵及出处分列造词搜寻、音韵搜寻及出处搜寻。<br>（1） 造词搜寻：<br>　　　（a）一般搜寻－依个人需要查询「含有某字的词」、「词首为某字的词」或「词<br>　　　　　 尾为某字的词」。<br>　　　　　 例如：含有「夫」字的词：老夫子、丈夫、夫人<br>       　　　　　词首为「夫」字的词：夫妻、夫子<br>　　 　      　　词尾为「夫」字的词：可靠性、重要性<br>　　　（b）成语搜寻－文字在成语中的活用。<br>　　　　　 例如：一饮而尽、一炮而红<br>　　　（c）重叠词搜寻－字数或形式的组合变化<br>　　　　　 例如：AAB－走走路、洗洗澡<br>　　　　　       ABB－亮闪闪、红通通<br>                 AABB－高高兴兴、平平安安<br>　　　　         ABAB－高兴抱兴、研究研究<br>　　　（d）字数搜寻－依字数搜寻一、二、三、四、五字或以上的词<br>　　　　　 例如：大年夜、心有灵犀一点通<br>（2）音韵搜寻：依据韵母、声母、声调、汉语拼音，或同音、双声、叠韵、双声<br>　　　　　     叠韵等条件搜寻。<br>　　　　　 例如：<br>　　　  　　　　 同音词：ㄒㄧㄥˊ ㄕˋ或xing2 shi4同音者(形式、行事…)<br>　　　　  　　　 双声词：名目、思索<br>　　　　　  　　 叠韵词：混吨、讚歎<br>　　　　　　  　 双声叠韵：夫妇、想像<br>（3） 出处搜寻：提供搜寻的范围包括《论语》、《孟子》、《大学》、《中庸》、《老子》、《庄子》、《唐诗三百首》。<br>（三）文：「出处搜寻」的功能提供文句出处检索。在搜寻书目中（即《论语》、《孟子》、《大学》、《中庸》、《老子》、《庄子》、《唐诗三百首》），利用「一般搜寻」或「有趣的诗文查询」寻找欲知文句。<br>　　（1） 一般搜寻：自搜寻范围中寻找含有某段文句的句子。<br>　　（2） 有趣的诗文查询：欲查诗文，可利用作者、诗题或诗句搜寻。　</p>
<h1 id="参考网站"><a href="#参考网站" class="headerlink" title="参考网站"></a>参考网站</h1><h2 id="中央研究院现代汉语平衡语料库"><a href="#中央研究院现代汉语平衡语料库" class="headerlink" title="中央研究院现代汉语平衡语料库"></a>中央研究院现代汉语平衡语料库</h2><p><a href="http://www.sinica.edu.tw/SinicaCorpus" target="_blank" rel="noopener">http://www.sinica.edu.tw/SinicaCorpus</a></p>
<h2 id="古汉语语料库"><a href="#古汉语语料库" class="headerlink" title="古汉语语料库"></a>古汉语语料库</h2><p><a href="http://www.sinica.edu.tw/ftms-bin/ftmsw3" target="_blank" rel="noopener">http://www.sinica.edu.tw/ftms-bin/ftmsw3</a></p>
<h2 id="国语汇词典"><a href="#国语汇词典" class="headerlink" title="国语汇词典"></a>国语汇词典</h2><p><a href="http://www.edu.tw/mandr/clc/dict/" target="_blank" rel="noopener">http://www.edu.tw/mandr/clc/dict/</a></p>
<h2 id="网路展书读"><a href="#网路展书读" class="headerlink" title="网路展书读"></a>网路展书读</h2><p><a href="http://cls.hs.yzu.edu.tw/home.htm" target="_blank" rel="noopener">http://cls.hs.yzu.edu.tw/home.htm</a></p>
<h2 id="红楼梦"><a href="#红楼梦" class="headerlink" title="红楼梦"></a>红楼梦</h2><p><a href="http://cls.hs.yzu.edu.tw/hlm/" target="_blank" rel="noopener">http://cls.hs.yzu.edu.tw/hlm/</a></p>
<h2 id="词库小组"><a href="#词库小组" class="headerlink" title="词库小组"></a>词库小组</h2><p><a href="http://ckip.iis.sinica.edu.tw/CKIP/" target="_blank" rel="noopener">http://ckip.iis.sinica.edu.tw/CKIP/</a></p>
<h2 id="中央研究院历史语言研究所-文物陈列馆"><a href="#中央研究院历史语言研究所-文物陈列馆" class="headerlink" title="中央研究院历史语言研究所/文物陈列馆"></a>中央研究院历史语言研究所/文物陈列馆</h2><p><a href="http://www.ihp.sinica.edu.tw/chen" target="_blank" rel="noopener">http://www.ihp.sinica.edu.tw/chen</a></p>
<h2 id="中央研究院历史语言研究所-史学连线"><a href="#中央研究院历史语言研究所-史学连线" class="headerlink" title="中央研究院历史语言研究所/史学连线"></a>中央研究院历史语言研究所/史学连线</h2><p><a href="http://saturn.ihp.sinica.edu.tw/~liutk/shih" target="_blank" rel="noopener">http://saturn.ihp.sinica.edu.tw/~liutk/shih</a></p>
<h2 id="台南师院文字学多体媒教学"><a href="#台南师院文字学多体媒教学" class="headerlink" title="台南师院文字学多体媒教学"></a>台南师院文字学多体媒教学</h2><p><a href="http://www.cc.ntntc.edu.tw/wang" target="_blank" rel="noopener">http://www.cc.ntntc.edu.tw/wang</a></p>
<h2 id="清华大学「董作宾百年诞展」"><a href="#清华大学「董作宾百年诞展」" class="headerlink" title="清华大学「董作宾百年诞展」"></a>清华大学「董作宾百年诞展」</h2><p><a href="http://www.arts.nthu.edu.tw/Exhibition/dong/index.html" target="_blank" rel="noopener">http://www.arts.nthu.edu.tw/Exhibition/dong/index.html</a></p>
<h2 id="不朽的殿堂-汉代的墓葬与文化"><a href="#不朽的殿堂-汉代的墓葬与文化" class="headerlink" title="不朽的殿堂-汉代的墓葬与文化"></a>不朽的殿堂-汉代的墓葬与文化</h2><p><a href="http://www.sinica.edu.tw/~hantomb/" target="_blank" rel="noopener">http://www.sinica.edu.tw/~hantomb/</a></p>
<h2 id="香港中文大学-郭店楚简资料库"><a href="#香港中文大学-郭店楚简资料库" class="headerlink" title="香港中文大学/郭店楚简资料库"></a>香港中文大学/郭店楚简资料库</h2><p><a href="http://decapps.lib.cuhk.edu.hk/basisbwdocs/bamboo/bam_main.html" target="_blank" rel="noopener">http://decapps.lib.cuhk.edu.hk/basisbwdocs/bamboo/bam_main.html</a></p>
<h2 id="文林辞典"><a href="#文林辞典" class="headerlink" title="文林辞典"></a>文林辞典</h2><p><a href="http://decapps.lib.cuhk.edu.hk/basisbwdocs/bamboo/bam_main.html" target="_blank" rel="noopener">http://decapps.lib.cuhk.edu.hk/basisbwdocs/bamboo/bam_main.html</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/03/杜成玉_Antconc3.21语料库分析统计软件/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/03/杜成玉_Antconc3.21语料库分析统计软件/" itemprop="url">Antconc3.21语料库分析统计软件</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-03T15:37:46+05:00">
                2018-06-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：杜成玉<br>下载地址：<a href="http://www.laurenceanthony.net/software/antconc/" target="_blank" rel="noopener">http://www.laurenceanthony.net/software/antconc/</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>该语料库工具是语料库检索软件，具有以下特点：<br>（1）能识别txt，html，htm，xml这四种格式；<br>（2）可以统计出关键词在文本中出现的次数；<br>（3）能列出文本中的词项数和词形，还能将词项数按出现的频率高低排列；<br>（4）文本去重；<br>（5）能够将某个词的搭配按照统计数据从高到低或者反向排序。<br>（6）模糊检索</p>
<h1 id="使用教程："><a href="#使用教程：" class="headerlink" title="使用教程："></a>使用教程：</h1><p>（1）从file菜单的openfile（打开文件）或opendir（打开目录）选择一个或多个要处理的文件，选出来的文件按顺序在主窗户的左边框里显示出来。<br>（2）在左边的按钮条的输入框里输入一个检索词<br>（3）使用右边”SearchWindowSize”（检索窗口大小）的按钮条的增加和减少按钮来选择在检索词两边显示的字符数。<br>（4）按“Start”（开始）键开始产生索引行的检索结果。检索过程中可按“stop”(停止）键随时停止检索。<br>（5）使用KwicSort（上下文关键词分类）下的按钮条选择一个目标词来重排索引行,0是检索词，1L，2L是检索词左边的第一，第二个单词，1R，2R是检索词右边第一，第二个单词。<br>（6）按“Sort”（分类）键开始分类处理。<br>（7）将指针移到其中一行索引行的突出的检索词之上，系统默认为蓝色。指针会转变成一个手形的图标。点击突出的检索词，可以看到检索词在原文中出现的情况。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/卢梦依_SVHN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/卢梦依_SVHN/" itemprop="url">SVHN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T21:23:00+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>SVHN数据来源于 Google 街景视图中房屋信息，它是一个真实世界的图像数据集，用于开发机器学习和对象识别算法，对数据预处理和格式化的要求最低。它跟MNIST相似，但是包含更多数量级的标签数据（超过60万个数字图像），并且来源更加多样，用来识别自然场景图像中的数字。</p>
<h1 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h1><p><a href="http://ufldl.stanford.edu/housenumbers/" target="_blank" rel="noopener">http://ufldl.stanford.edu/housenumbers/</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Shuai Li,Wenfeng Song,Hong Qin,Aimin Hao. Deep variance network: An iterative, improved CNN framework for unbalanced training datasets[J]. Pattern Recognition,2018,81.<br>[2]Andrey V. Savchenko,Natalya S. Belova. Unconstrained face identification using maximum likelihood of distances between deep off-the-shelf features[J]. Expert Systems With Applications,2018,108.<br>[3]Alistair Peter McGeorge. An Urban Partnership for Inner Sydney Social Inclusion, Health and Well-being[J]. International Journal of Integrated Care,2017,17(3).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/卢梦依_Labeled Faces in the Wild数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/卢梦依_Labeled Faces in the Wild数据集/" itemprop="url">Labeled Faces in the Wild数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T21:19:00+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>该数据集是用于研究无约束面部识别问题的面部照片数据库。数据集包含从网络收集的13000多张图像。每张脸都贴上了所画的人的名字，图片中的1680人在数据集中有两个或更多不同的照片。</p>
<h1 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h1><p><a href="http://vis-www.cs.umass.edu/lfw/" target="_blank" rel="noopener">http://vis-www.cs.umass.edu/lfw/</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]David Rim,Md Kamrul Hasan,Fannie Puech,Christopher J. Pal. Learning from weakly labeled faces and video in the wild[J]. Pattern Recognition,2015,48(3).<br>[2]Davide Lombardo. An explicit open image theorem for products of elliptic curves[J]. Journal of Number Theory,2016,168.<br>[3]M. Nazir,A. Majid-Mirza,S. Ali-Khan. PSO-GA Based Optimized Feature Selection Using Facial and Clothing Information for Gender Classification[J]. Journal of Applied Research and Technology,2014,12(1).<br>[4]Jiang-Jing Lv,Cheng Cheng,Guo-Dong Tian,Xiang-Dong Zhou,Xi Zhou. Landmark perturbation-based data augmentation for unconstrained face recognition[J]. Signal Processing: Image Communication,2016,47.<br>[5]Blondin , John M.,Kallman , Timothy R.,Pereyra , Nicolas Antonio. Hydrodynamic Models of Line-Driven Accretion Disk Winds in Cataclysmic Variables[J]. Revista Mexicana de Astronomía y Astrofísica : Universidad Nacional Autónoma de México. Instituto de Astronomía,2001(11).<br>[6]Ian W. Roxburgh. Challenges to Theories of the Structure of Moderate-Mass Stars[M].Springer Berlin Heidelberg:2005-07-19.<br>[7]Andrey V. Savchenko,Natalya S. Belova. Unconstrained face identification using maximum likelihood of distances between deep off-the-shelf features[J]. Expert Systems With Applications,2018,108. </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/卢梦依_LSUN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/卢梦依_LSUN/" itemprop="url">LSUN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T21:14:00+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>国外的PASCAL VOC和ImageNet ILSVRC比赛使用的数据集，数据领域包括卧室、冰箱、教师、厨房、起居室、酒店等多个主题。</p>
<h1 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h1><p><a href="http://lsun.cs.princeton.edu/2017/" target="_blank" rel="noopener">http://lsun.cs.princeton.edu/2017/</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Blondin , John M.,Kallman , Timothy R.,Pereyra , Nicolas Antonio. Hydrodynamic Models of Line-Driven Accretion Disk Winds in Cataclysmic Variables[J]. Revista Mexicana de Astronomía y Astrofísica : Universidad Nacional Autónoma de México. Instituto de Astronomía,2001(11).<br>[2]Ian W. Roxburgh. Challenges to Theories of the Structure of Moderate-Mass Stars[M].Springer Berlin Heidelberg:2005-07-19.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/刘唯_Open Image/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/刘唯_Open Image/" itemprop="url">Open Image</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T20:10:00+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>过去几年机器学习的发展使得计算机视觉有了快速的进步，系统能够自动描述图片，对共享的图片创造自然语言回应。其中大部分的进展都可归因于 ImageNet 、COCO这样的数据集的公开使用。谷歌作为一家伟大的公司，自然也要做出些表示，于是乎就有了Open Image。</p>
<p>Open Image是一个包含~900万张图像URL的数据集，里面的图片通过标签注释被分为6000多类。该数据集中的标签要比ImageNet（1000类）包含更真实生活的实体存在，它足够让我们从头开始训练深度神经网络。</p>
<p>谷歌出品，必属精品！唯一不足的可能就是它只是提供图片URL，使用起来可能不如直接提供图片方便。</p>
<h1 id="数据集大小"><a href="#数据集大小" class="headerlink" title="数据集大小"></a>数据集大小</h1><p>~1.5GB（不包括图片）</p>
<h1 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h1><p><a href="https://github.com/openimages/dataset" target="_blank" rel="noopener">https://github.com/openimages/dataset</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]M. Hu&amp;scaron,ek. Open images of orderable spaces[J]. proc,1983,88(4).<br>[2]Davide Lombardo. An explicit open image theorem for products of elliptic curves[J]. Journal of Number Theory,2016,168.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/刘唯_Labelme/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/刘唯_Labelme/" itemprop="url">Labelme</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T20:10:00+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p> Labelme是斯坦福一个学生的母亲利用休息时间帮儿子做的标注，后来便发展为一个数据集。该数据集的主要特点包括<br>（1）专门为物体分类识别设计，而非仅仅是实例识别<br>（2）专门为学习嵌入在一个场景中的对象而设计<br>（3）高质量的像素级别标注，包括多边形框（polygons）和背景标注（segmentation masks）<br>（4）物体类别多样性大，每种物体的差异性，多样性也大。<br>（5）所有图像都是自己通过相机拍摄，而非copy<br>（6）公开的，免费的</p>
<h1 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h1><p>图像如下图所示，需要通过matlab来下载，一种奇特的下载方式。<br>下载链接为<a href="http://labelme2.csail.mit.edu/Release3.0/index.php" target="_blank" rel="noopener">http://labelme2.csail.mit.edu/Release3.0/index.php</a><br><img src="https://i.loli.net/2018/05/24/5b06ac87bd99e.jpg" alt=""></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]吉江燕,方挺.基于Labelme的参考图像的手工分割[J].微型机与应用,2015,34(17):49-51+56.<br>[2]Bryan C. Russell,  Antonio Torralba,  Kevin P. Murphy,  William T. Freeman.International Journal of Computer Vision[J].LabelMe: A Database and Web-Based Tool for Image Annotation.<br>[3]</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/刘晓_CoPhIR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/刘晓_CoPhIR/" itemprop="url">CoPhIR 数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T10:31:58+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="http://cophir.isti.cnr.it/whatis.html" target="_blank" rel="noopener">http://cophir.isti.cnr.it/whatis.html</a>  </p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>雅虎发布的超大Flickr数据集，包含1亿多张图片。<br>CoPhIR（Content-based Photo Image Retrieval，基于内容的照片图像检索）测试集合的开发旨在对SAPIR项目基础设施（SAPIR：使用对等IR中的音频视频内容进行搜索）的可扩展性进行重要测试以进行相似性搜索。 CoPhIR是NMIS实验室与意大利比萨ISTI-CNR的HPC实验室共同努力的成果。 我们通过DILIGENT项目使用EGEE European GRID从Flickr存档提取元数据。 对于每个图像，已经提取了标准的MPEG-7图像特征。试验台的每个入口都包含：  </p>
<ul>
<li>链接Flickr网站的相应条目   </li>
<li>照片图像缩略图  </li>
<li>一个XML结构，在相应的Flickr条目中包含Flickr用户信息：标题，位置，GPS，标签，注释等。   </li>
<li><p>具有5个提取的标准MPEG-7图像特征的XML结构：  </p>
<ul>
<li>可伸缩的色彩  </li>
<li>色彩结构 </li>
<li>色彩布局  </li>
<li>边缘直方图</li>
<li>均匀纹理  </li>
</ul>
</li>
</ul>
<p>迄今收集的数据代表世界上最大的多媒体元数据收集，可用于可扩展相似性搜索技术的研究。 CoPhIR包含1.06亿个处理过的图像。   </p>
<p>CoPhIR现在可供研究人员尝试比较不同的索引技术进行相似性搜索，其中可扩展性是关键问题。  </p>
<p>我们使用Flickr图片内容符合Creative Commons许可。 CoPhIR测试集合符合基于WIPO（世界知识产权组织）版权条约和表演和录音制品条约以及意大利现行法律68/2003的欧洲第29/2001号建议书。<br>为了访问CoPhIR发行版，有兴趣在其上进行实验的组织（大学，研究实验室等）将必须签署随附的CoPhIR访问协议和CoPhIR访问注册表，将原始签名文件通过邮件发送给我们。请按照“如何获得CoPhIR测试集合”一节中的说明进行操作。然后，您将收到登录和密码以下载所需的文件。  </p>
<h1 id="使用–获得CoPhIR测试集"><a href="#使用–获得CoPhIR测试集" class="headerlink" title="使用–获得CoPhIR测试集"></a>使用–获得CoPhIR测试集</h1><ul>
<li>发送电子邮件到 cophiristi.cnr.it (subject: new access to Cophir)，包含有必要信息的请求(见<a href="http://cophir.isti.cnr.it/RequestTemplate.txt" target="_blank" rel="noopener">请求模板</a>)。  </li>
<li>打印CoPhIR Access Agreement和CoPhIR Access Registration Form (doc, pdf)，填写所需信息，然后由授权人签署正本文件。  </li>
<li>将两份文件邮寄至</li>
</ul>
<blockquote>
<p>Dr. Fausto Rabitti<br>NMIS Lab.<br>ISTI-CNR, Pisa Research Area<br>Via Moruzzi, 1<br>56124 Pisa (Italy).  </p>
</blockquote>
<ul>
<li><p>我们将发送到您的电子邮件地址，在访问注册表中显示，一封包含登录名和密码的电子邮件将用于访问CoPhIR测试集合。  </p>
</li>
<li><p>要下载CoPhIR测试集合的文件，请在CoPhIR网站上输入<a href="http://cophir.isti.cnr.it/download.html" target="_blank" rel="noopener">下载</a>部分并使用您的登录名和密码。  </p>
</li>
</ul>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] F Rabitti, R Perego,F Falchi,C Lucchese, P Bolettieri, CoPhIR (Content-based Photo Image Retrieval) Test-Collection, 2008<br>[2] M Batko,P Kohoutkova,D Novak, CoPhIR Image Collection under the Microscope, 2009  </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/刘晓_百度BROAD-Video Highlights视频精彩片段数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/刘晓_百度BROAD-Video Highlights视频精彩片段数据集/" itemprop="url">百度BROAD-Video Highlights视频精彩片段数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T10:31:58+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓</p>
<p>地址：<a href="http://ai.baidu.com/broad" target="_blank" rel="noopener">http://ai.baidu.com/broad</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>该数据集（下文中简称为BROAD-VH数据集）在介绍中将其定义为视频精彩片段提取任务。具体而言，就是提取视频中可能包含精彩片段的时间区域，而不需要对精彩片段的类别进行分类。该任务实际上与我之前介绍过的temporal action proposal 任务（相关介绍和算法可以参考<a href="https://zhuanlan.zhihu.com/p/31501316" target="_blank" rel="noopener">Temporal Action Detection (时序动作检测)方向2017年会议论文整理）</a>是完全相同的。</p>
<h1 id="视频及数据信息"><a href="#视频及数据信息" class="headerlink" title="视频及数据信息"></a>视频及数据信息</h1><p>BROAD-VH数据集主要来源于爱奇艺视频。视频类型为综艺节目，目前包括1500个长视频，视频总时长约1200小时。该数据集的视频时长分布图如下图所示（长度单位为帧）。按照总帧数和总时长的比例，估计采样的fps大概为1.5吧，算是比较低的采样频率了。</p>
<p>训练/验证/测试集的视频数量划分为1262/120/117。</p>
<p>该数据集通过爱奇艺网页link的方式提供了原始视频（即需要爬虫下载或手动下载），此外还提供了提取好的image feature和audio feature。这两种特征均在视频的每一帧上提取，维度均为2048。比如对于一个长度为1000帧的视频，image和audio特征矩阵的大小均为1000*2048。</p>
<h1 id="标签信息及分布"><a href="#标签信息及分布" class="headerlink" title="标签信息及分布"></a>标签信息及分布</h1><p>该数据集中一共有18000个精彩片段的时序标注，平均一个视频有12个时序标注。这些精彩片段的总时长占1500个小时中的750个小时，即有一半左右的视频时长被标注为了精彩片段。</p>
<p>我对训练集的标签信息进行了分析，分析的主要内容为精彩片段时长的分布，分布直方图如下图所示。</p>
<p>可以看出，大部分精彩片段的长度都在30-300帧的范围。</p>
<h1 id="测评方式"><a href="#测评方式" class="headerlink" title="测评方式"></a>测评方式</h1><p>测评方式部分与通常temporal action proposal任务中不同，并没有使用average recall (平均召回率），而是同detection任务一样使用了mAP，此处将所有highlights片段都看作为了一个动作类别。比较有趣的是，BROAD-VH基本上直接使用了ActivityNet Challenge的detection任务测评代码（略有改动）。</p>
<h1 id="简要分析"><a href="#简要分析" class="headerlink" title="简要分析"></a>简要分析</h1><p>根据上面的介绍以及分析内容，可以对这个数据集进行一些简单的评价：</p>
<ul>
<li>单个视频的时长可能很长（小时级别），单个视频中包含的精彩片段也比较多，这点与THUMOS数据集很像，而与单个视频时长短且包含片段少的ActivityNet数据集差异大</li>
<li>数据集标注的格式，测评代码等方面应该是直接参考的ActivityNet 数据集做的</li>
<li>数据的规模还是比较大的，从时长方面看比ActivityNet要长（ActivityNet时长大约为700小时）</li>
<li>视频的来源均为综艺视频，这点表明这个数据集的来源多样性比较单一</li>
<li>提供特征，其目的应该是节省研究者的计算开销。估计1500小时的视频，提取一遍特需要很长的时间。。根本没法玩。所以有现成的特征挺不错的。</li>
</ul>
<h1 id="简单的尝试"><a href="#简单的尝试" class="headerlink" title="简单的尝试"></a>简单的尝试</h1><p>下完数据集我就先跑了一个最简单的baseline方法，即activitynet challenge 2017 proposal task中的baseline：uniform random 方法。代码主要参考了activitynet官方提供的代码：<a href="https://link.zhihu.com/?target=https%3A//github.com/activitynet/ActivityNet/blob/master/Notebooks/ActivityNet-Release1.3.Proposals.ipynb" target="_blank" rel="noopener">activitynet/proposals</a></p>
<p>简单而言，就是在视频随机的位置产生随机长度的proposals，并给予随机的confidence score。在验证集中，对于每个视频我生成了200个proposals，得到的mAP大概在0.027 左右。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/刘晓_UCF101 - Action Recognition Data Set/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/刘晓_UCF101 - Action Recognition Data Set/" itemprop="url">UCF101 - Action Recognition Data Set</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T10:31:58+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓</p>
<p>地址：<a href="http://crcv.ucf.edu/data/UCF101.php" target="_blank" rel="noopener">http://crcv.ucf.edu/data/UCF101.php</a>  </p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>UCF101是一个动作识别数据集，包含现实的动作视频，从YouTube上收集，有101个动作类别。该数据集是UCF50数据集的扩展，该数据集有50个动作类别。<br>从101个动作类的13320个视频中，UCF101给出了最大的多样性，并且在摄像机运动、物体外观和姿态、物体尺度、视点、杂乱背景、光照条件等方面存在较大的差异，这是迄今为止最具挑战性的数据。<br>由于大多数可用的动作识别数据集都不现实，而且是由参与者进行的，UCF101旨在通过学习和探索新的现实行动类别来鼓励进一步研究行动识别。<br>101个动作类的视频被分成25组，每个组可以包含4-7个动作视频。同一组的视频可能有一些共同的特点，比如背景相似、观点相似等。  </p>
<p><strong>动作类别可以分为五类： </strong> </p>
<ul>
<li>Human-Object Interaction  </li>
<li>Body-Motion Only   </li>
<li>Human-Human Interaction   </li>
<li>Playing Musical Instruments   </li>
<li>Sports.   </li>
</ul>
<p>UCF101数据集的操作类别为:应用眼妆、唇膏、射箭、婴儿爬行,平衡木,乐队游行,棒球,篮球,篮球扣篮,卧推,骑自行车,台球,吹干头发,吹蜡烛,体重下蹲,保龄球,拳击出气筒,拳击袋速度,蛙泳,刷牙,挺举,悬崖跳水,板球保龄球,板球,削减在厨房,潜水,打鼓,击剑、曲棍球点球,地板体操,飞盘,爬泳,高尔夫挥杆,发型、链球、锤击,倒立俯卧撑,倒立行走,头部按摩,跳高,赛马,骑马、呼啦圈、冰上舞蹈,掷标枪,杂耍球,跳绳,跳杰克,皮划艇,针织,跳远,弓步,阅兵,搅拌面糊、拖地板,修女轻叩,双杠,披萨扔,弹吉他,弹钢琴,打手鼓,演奏小提琴,演奏大提琴,玩来说,玩时代,演奏长笛,玩锡塔尔琴,撑杆跳,鞍马、拉Ups、穿孔、俯卧撑、漂流、攀岩室内,绳索攀爬、划船、萨尔萨舞旋转,剃胡子,推铅球,滑板,滑雪,Skijet,跳伞,足球杂耍,足球点球,还是戒指,相扑,冲浪,秋千,乒乓球拍、太极、网球挥拍,扔铁饼,蹦床跳,打字,高低杠,排球飙升,与狗一起散步,“推墙”,写作,溜溜球。  </p>
<p>下载UCF101数据集：<a href="http://crcv.ucf.edu/data/UCF101/UCF101.rar" target="_blank" rel="noopener">http://crcv.ucf.edu/data/UCF101/UCF101.rar</a>  </p>
<p>UCF101数据集的动作识别（ Action Recognition）的训练/测试集下载地址:<a href="http://crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip" target="_blank" rel="noopener">http://crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip</a>  </p>
<p>UCF101数据集的动作检测（ Action Detection）的训练/测试集下载地址:<a href="http://crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-DetectionTask.zip" target="_blank" rel="noopener">http://crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-DetectionTask.zip</a>  </p>
<p>UCF101数据集的STIP特性可以在这里下载:<a href="http://crcv.ucf.edu/data/UCF101/UCF101_STIP_Part1.rar" target="_blank" rel="noopener">Part1</a>,<a href="http://crcv.ucf.edu/data/UCF101/UCF101_STIP_Part2.rar" target="_blank" rel="noopener">Part2</a>  </p>
<p><img src="https://i.loli.net/2018/06/02/5b121da3d8ad6.jpg" alt="">  </p>
<h1 id="Statistics"><a href="#Statistics" class="headerlink" title="Statistics"></a>Statistics</h1><p><img src="http://crcv.ucf.edu/data/UCF101/Clip%20Duration%201.jpg" alt="">  </p>
<p><img src="http://crcv.ucf.edu/data/UCF101/Clip%20Duration%202.jpg" alt="">  </p>
<p><img src="http://crcv.ucf.edu/data/UCF101/Number%20of%20Videos%201.jpg" alt="">  </p>
<p><img src="http://crcv.ucf.edu/data/UCF101/Number%20of%20Videos%202.jpg" alt="">  </p>
<p>注意：将属于同一组的视频保持在训练和测试中非常重要。由于一组中的视频是从单个长视频中获得的，因此在训练和测试套件中共享来自同一组的视频会获得较高的性能。 </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Khurram Soomro, Amir Roshan Zamir and Mubarak Shah, UCF101: A Dataset of 101 Human Action Classes From Videos in The Wild, CRCV-TR-12-01, November, 2012.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/21/">21</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CNLR</p>
              <p class="site-description motion-element" itemprop="description">语料库、数据集及工具资源和教程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">203</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CNLR</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
