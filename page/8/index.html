<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="语料库、数据集及工具资源和教程">
<meta property="og:type" content="website">
<meta property="og:title" content="世界语言资源平台">
<meta property="og:url" content="http://yoursite.com/page/8/index.html">
<meta property="og:site_name" content="世界语言资源平台">
<meta property="og:description" content="语料库、数据集及工具资源和教程">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="世界语言资源平台">
<meta name="twitter:description" content="语料库、数据集及工具资源和教程">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/8/"/>





  <title>世界语言资源平台</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">世界语言资源平台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/刘晓_UCF101 - Action Recognition Data Set/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/刘晓_UCF101 - Action Recognition Data Set/" itemprop="url">UCF101 - Action Recognition Data Set</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T10:31:58+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓</p>
<p>地址：<a href="http://crcv.ucf.edu/data/UCF101.php" target="_blank" rel="noopener">http://crcv.ucf.edu/data/UCF101.php</a>  </p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>UCF101是一个动作识别数据集，包含现实的动作视频，从YouTube上收集，有101个动作类别。该数据集是UCF50数据集的扩展，该数据集有50个动作类别。<br>从101个动作类的13320个视频中，UCF101给出了最大的多样性，并且在摄像机运动、物体外观和姿态、物体尺度、视点、杂乱背景、光照条件等方面存在较大的差异，这是迄今为止最具挑战性的数据。<br>由于大多数可用的动作识别数据集都不现实，而且是由参与者进行的，UCF101旨在通过学习和探索新的现实行动类别来鼓励进一步研究行动识别。<br>101个动作类的视频被分成25组，每个组可以包含4-7个动作视频。同一组的视频可能有一些共同的特点，比如背景相似、观点相似等。  </p>
<p><strong>动作类别可以分为五类： </strong> </p>
<ul>
<li>Human-Object Interaction  </li>
<li>Body-Motion Only   </li>
<li>Human-Human Interaction   </li>
<li>Playing Musical Instruments   </li>
<li>Sports.   </li>
</ul>
<p>UCF101数据集的操作类别为:应用眼妆、唇膏、射箭、婴儿爬行,平衡木,乐队游行,棒球,篮球,篮球扣篮,卧推,骑自行车,台球,吹干头发,吹蜡烛,体重下蹲,保龄球,拳击出气筒,拳击袋速度,蛙泳,刷牙,挺举,悬崖跳水,板球保龄球,板球,削减在厨房,潜水,打鼓,击剑、曲棍球点球,地板体操,飞盘,爬泳,高尔夫挥杆,发型、链球、锤击,倒立俯卧撑,倒立行走,头部按摩,跳高,赛马,骑马、呼啦圈、冰上舞蹈,掷标枪,杂耍球,跳绳,跳杰克,皮划艇,针织,跳远,弓步,阅兵,搅拌面糊、拖地板,修女轻叩,双杠,披萨扔,弹吉他,弹钢琴,打手鼓,演奏小提琴,演奏大提琴,玩来说,玩时代,演奏长笛,玩锡塔尔琴,撑杆跳,鞍马、拉Ups、穿孔、俯卧撑、漂流、攀岩室内,绳索攀爬、划船、萨尔萨舞旋转,剃胡子,推铅球,滑板,滑雪,Skijet,跳伞,足球杂耍,足球点球,还是戒指,相扑,冲浪,秋千,乒乓球拍、太极、网球挥拍,扔铁饼,蹦床跳,打字,高低杠,排球飙升,与狗一起散步,“推墙”,写作,溜溜球。  </p>
<p>下载UCF101数据集：<a href="http://crcv.ucf.edu/data/UCF101/UCF101.rar" target="_blank" rel="noopener">http://crcv.ucf.edu/data/UCF101/UCF101.rar</a>  </p>
<p>UCF101数据集的动作识别（ Action Recognition）的训练/测试集下载地址:<a href="http://crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip" target="_blank" rel="noopener">http://crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip</a>  </p>
<p>UCF101数据集的动作检测（ Action Detection）的训练/测试集下载地址:<a href="http://crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-DetectionTask.zip" target="_blank" rel="noopener">http://crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-DetectionTask.zip</a>  </p>
<p>UCF101数据集的STIP特性可以在这里下载:<a href="http://crcv.ucf.edu/data/UCF101/UCF101_STIP_Part1.rar" target="_blank" rel="noopener">Part1</a>,<a href="http://crcv.ucf.edu/data/UCF101/UCF101_STIP_Part2.rar" target="_blank" rel="noopener">Part2</a>  </p>
<p><img src="https://i.loli.net/2018/06/02/5b121da3d8ad6.jpg" alt="">  </p>
<h1 id="Statistics"><a href="#Statistics" class="headerlink" title="Statistics"></a>Statistics</h1><p><img src="http://crcv.ucf.edu/data/UCF101/Clip%20Duration%201.jpg" alt="">  </p>
<p><img src="http://crcv.ucf.edu/data/UCF101/Clip%20Duration%202.jpg" alt="">  </p>
<p><img src="http://crcv.ucf.edu/data/UCF101/Number%20of%20Videos%201.jpg" alt="">  </p>
<p><img src="http://crcv.ucf.edu/data/UCF101/Number%20of%20Videos%202.jpg" alt="">  </p>
<p>注意：将属于同一组的视频保持在训练和测试中非常重要。由于一组中的视频是从单个长视频中获得的，因此在训练和测试套件中共享来自同一组的视频会获得较高的性能。 </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Khurram Soomro, Amir Roshan Zamir and Mubarak Shah, UCF101: A Dataset of 101 Human Action Classes From Videos in The Wild, CRCV-TR-12-01, November, 2012.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/刘晓_CoPhIR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/刘晓_CoPhIR/" itemprop="url">CoPhIR 数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T10:31:58+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="http://cophir.isti.cnr.it/whatis.html" target="_blank" rel="noopener">http://cophir.isti.cnr.it/whatis.html</a>  </p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>雅虎发布的超大Flickr数据集，包含1亿多张图片。<br>CoPhIR（Content-based Photo Image Retrieval，基于内容的照片图像检索）测试集合的开发旨在对SAPIR项目基础设施（SAPIR：使用对等IR中的音频视频内容进行搜索）的可扩展性进行重要测试以进行相似性搜索。 CoPhIR是NMIS实验室与意大利比萨ISTI-CNR的HPC实验室共同努力的成果。 我们通过DILIGENT项目使用EGEE European GRID从Flickr存档提取元数据。 对于每个图像，已经提取了标准的MPEG-7图像特征。试验台的每个入口都包含：  </p>
<ul>
<li>链接Flickr网站的相应条目   </li>
<li>照片图像缩略图  </li>
<li>一个XML结构，在相应的Flickr条目中包含Flickr用户信息：标题，位置，GPS，标签，注释等。   </li>
<li><p>具有5个提取的标准MPEG-7图像特征的XML结构：  </p>
<ul>
<li>可伸缩的色彩  </li>
<li>色彩结构 </li>
<li>色彩布局  </li>
<li>边缘直方图</li>
<li>均匀纹理  </li>
</ul>
</li>
</ul>
<p>迄今收集的数据代表世界上最大的多媒体元数据收集，可用于可扩展相似性搜索技术的研究。 CoPhIR包含1.06亿个处理过的图像。   </p>
<p>CoPhIR现在可供研究人员尝试比较不同的索引技术进行相似性搜索，其中可扩展性是关键问题。  </p>
<p>我们使用Flickr图片内容符合Creative Commons许可。 CoPhIR测试集合符合基于WIPO（世界知识产权组织）版权条约和表演和录音制品条约以及意大利现行法律68/2003的欧洲第29/2001号建议书。<br>为了访问CoPhIR发行版，有兴趣在其上进行实验的组织（大学，研究实验室等）将必须签署随附的CoPhIR访问协议和CoPhIR访问注册表，将原始签名文件通过邮件发送给我们。请按照“如何获得CoPhIR测试集合”一节中的说明进行操作。然后，您将收到登录和密码以下载所需的文件。  </p>
<h1 id="使用–获得CoPhIR测试集"><a href="#使用–获得CoPhIR测试集" class="headerlink" title="使用–获得CoPhIR测试集"></a>使用–获得CoPhIR测试集</h1><ul>
<li>发送电子邮件到 cophiristi.cnr.it (subject: new access to Cophir)，包含有必要信息的请求(见<a href="http://cophir.isti.cnr.it/RequestTemplate.txt" target="_blank" rel="noopener">请求模板</a>)。  </li>
<li>打印CoPhIR Access Agreement和CoPhIR Access Registration Form (doc, pdf)，填写所需信息，然后由授权人签署正本文件。  </li>
<li>将两份文件邮寄至</li>
</ul>
<blockquote>
<p>Dr. Fausto Rabitti<br>NMIS Lab.<br>ISTI-CNR, Pisa Research Area<br>Via Moruzzi, 1<br>56124 Pisa (Italy).  </p>
</blockquote>
<ul>
<li><p>我们将发送到您的电子邮件地址，在访问注册表中显示，一封包含登录名和密码的电子邮件将用于访问CoPhIR测试集合。  </p>
</li>
<li><p>要下载CoPhIR测试集合的文件，请在CoPhIR网站上输入<a href="http://cophir.isti.cnr.it/download.html" target="_blank" rel="noopener">下载</a>部分并使用您的登录名和密码。  </p>
</li>
</ul>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] F Rabitti, R Perego,F Falchi,C Lucchese, P Bolettieri, CoPhIR (Content-based Photo Image Retrieval) Test-Collection, 2008<br>[2] M Batko,P Kohoutkova,D Novak, CoPhIR Image Collection under the Microscope, 2009  </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/27/刘唯_AI2科学问答数据集(多选)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/27/刘唯_AI2科学问答数据集(多选)/" itemprop="url">AI2科学问答数据集(多选)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-27T21:47:46+05:00">
                2018-05-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯<br>下载地址：<a href="https://www.kaggle.com/allenai/ai2-science-questions" target="_blank" rel="noopener">https://www.kaggle.com/allenai/ai2-science-questions</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>Allen Institute for Artificial Intelligence (AI2)的Project Aristo专注于构建一个系统，该系统能够获取并存储大量的可计算形式的知识，然后将这些知识应用于不同年级水平的学生的标准化考试中的各种科学问题。我们邀请更广泛的人工智能研究社区，通过提供学生科学评估问题的数据集，来与我们共同应对这一重大挑战。<br>这些都是英语语言问题，它跨越了文件中所显示的几个年级水平。每个问题都是对应4个选择回答。其中一些问题包括一个图表，作为问题文本的一部分，作为回答选项，或者两者兼而有之。图在文本中表示，文件名对应于对应文件夹中的图文件本身。这些问题被预先划分为培训、开发和测试集。<br>数据集包括以下字段:<br>questionID: a unique identifier for the question<br>originalQuestionID: the question number on the test<br>totalPossiblePoints: how many points the question is worth<br>AnswerKey: the correct answer option<br>isMultipleChoiceQuestion: 1 = multiple choice, 0 = other<br>includesDiagram: 1 = includes diagram, 0 = other<br>examName: the source of the exam<br>schoolGrade: grade level<br>year: year the source exam was published<br>question: the question itself<br>subject: Science<br>category: Test, Train, or Dev (data comes pre-split into these categories)</p>
<h1 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h1><p>大小：56MB</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Clark, Peter. “Elementary School Science and Math Tests as a Driver for AI: Take the Aristo Challenge!” AAAI (2015).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/27/刘唯_完形填空(多选阅读理解)数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/27/刘唯_完形填空(多选阅读理解)数据集/" itemprop="url">完形填空(多选阅读理解)数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-27T21:47:46+05:00">
                2018-05-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘维<br>下载地址：<a href="https://tticnlp.github.io/who_did_what/index.html" target="_blank" rel="noopener">https://tticnlp.github.io/who_did_what/index.html</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>我们已经构建了一个新的“Who-did-What”数据集，该数据集包含了来自LDC英语Gigaword newswire语料库构建的超过20万填充物(cloze)的多重选择阅读理解问题。WDW数据集具有多种新特性。首先，与CNN和每日邮件数据(Hermann et al.， 2015)相比，我们避免使用文章摘要来回答问题。相反，每一个问题都是由两篇独立的文章组成的——一篇文章作为一篇文章，另一篇文章是关于同一事件的一篇文章。第二，我们避免匿名化——每个选择都是一个人的名字。第三，这些问题被过滤掉，去掉了一个简单的基线可以轻易解决的分数，而剩下的84%由人类来解决。我们报告了标准系统的性能基准，并提出WDW数据集作为社区的一项挑战任务。</p>
<h1 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h1><p> 大小：包含了37322个50个动物的图像。<br> 1.CUHK student data set 含188张faces<br> 2.AR data set (123 faces)<br> 3.XM2VTS data set (295 faces)</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Y. Xian, C. H. Lampert, B. Schiele, Z. Akata. “Zero-Shot Learning - A Comprehensive Evaluation of the Good, the Bad and the Ugly” arXiv:1707.00600</p>
<p>[2] C. H. Lampert, H. Nickisch, and S. Harmeling. “Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer”. In CVPR, 2009<br>[3] C. H. Lampert, H. Nickisch, and S. Harmeling. “Attribute-Based Classification for Zero-Shot Visual Object Categorization”. IEEE T-PAMI, 2013</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/27/刘唯_动物属性标记数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/27/刘唯_动物属性标记数据集/" itemprop="url">动物属性标记数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-27T21:47:46+05:00">
                2018-05-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘维<br>下载地址：<a href="http://cvml.ist.ac.at/AwA2/" target="_blank" rel="noopener">http://cvml.ist.ac.at/AwA2/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>该数据集提供了一个平台，用于基准的转移学习算法，特别是属性基分类和零射学习。它可以充当原始动物的替代，使用属性(AwA)数据集，因为它具有相同的类结构和几乎相同的特征。它包含了37322个50个动物的图像，每个图像都有预先提取的特征表示。这些类与Osherson的经典类/属性矩阵一致，从而为每个类提供85个数字属性值。使用共享属性，可以在不同的类之间传递信息。这些图像数据是在2016年从Flickr等公共资源中收集的。</p>
<h1 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h1><p> 大小：包含了37322个50个动物的图像。<br> 1.CUHK student data set 含188张faces<br> 2.AR data set (123 faces)<br> 3.XM2VTS data set (295 faces)</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Y. Xian, C. H. Lampert, B. Schiele, Z. Akata. “Zero-Shot Learning - A Comprehensive Evaluation of the Good, the Bad and the Ugly” arXiv:1707.00600</p>
<p>[2] C. H. Lampert, H. Nickisch, and S. Harmeling. “Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer”. In CVPR, 2009<br>[3] C. H. Lampert, H. Nickisch, and S. Harmeling. “Attribute-Based Classification for Zero-Shot Visual Object Categorization”. IEEE T-PAMI, 2013<br>[4]X. Tang, and X. Wang, “Face Photo Recognition Using Sketch,” in Proceedings of IEEE International Conference on Image Processing (ICIP), Vol. 1, pp. 257-260, Rochester, New York, Sept. 2002.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/27/刘唯_人脸素描数据集 /">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/27/刘唯_人脸素描数据集 /" itemprop="url">人脸素描数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-27T21:47:46+05:00">
                2018-05-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘维<br>下载地址：<a href="http://mmlab.ie.cuhk.edu.hk/archive/facesketch.html" target="_blank" rel="noopener">http://mmlab.ie.cuhk.edu.hk/archive/facesketch.html</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>中大脸部素描数据库(CUFS)是面向人脸素描合成和人脸素描识别的研究。它包括来自香港中文大学(中大)学生数据库的188张脸，来自AR数据库的123张脸，以及295张来自XM2VTS数据库的面孔。总共有606张脸。对于每张脸，都有一幅画是由一位艺术家绘制的。</p>
<h1 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h1><p> 大小：包含3个文件数据文件。<br> 1.CUHK student data set 含188张faces<br> 2.AR data set (123 faces)<br> 3.XM2VTS data set (295 faces)</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><ol>
<li><p>X. Wang and X. Tang, “Face Photo-Sketch Synthesis and Recognition,” IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), Vol. 31, 2009.</p>
</li>
<li><p>Qingshan Liu, Xiaoou Tang, Hongliang Jin, Hanqing Lu, and Songde Ma,  A Nonlinear Approach For Face Sketch Synthesis and Recognition,  Int’l Conf. on Computer Vision and Pattern Recognition (CVPR), 2005.</p>
</li>
<li><p>X. Tang, and X. Wang, “Face Sketch Recognition,” IEEE Transactions on Circuits and Systems for Video Technology (CSVT), Special Issue on Image- and Video- Based Biometrics, Vol. 14, No. 1, pp. 50-57, January, 2004.</p>
</li>
<li><p>X. Tang, and X. Wang, “Face Sketch Synthesis and Recognition,” in Proceedings of IEEE International Conference on Computer Vision (ICCV), 2003.</p>
</li>
<li><p>X. Tang, and X. Wang, “Face Photo Recognition Using Sketch,” in Proceedings of IEEE International Conference on Image Processing (ICIP), Vol. 1, pp. 257-260, Rochester, New York, Sept. 2002.</p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/27/卢梦依_语义关系分类数据集-semeval2007Task4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/27/卢梦依_语义关系分类数据集-semeval2007Task4/" itemprop="url">语义关系分类数据集-semeval2007Task4</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-27T21:47:46+05:00">
                2018-05-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依<br>下载地址：<a href="https://github.com/davidsbatista/Annotated-Semantic-Relationships-Datasets/blob/master/datasets/SemEval2007-Task4.tar.gz" target="_blank" rel="noopener">https://github.com/davidsbatista/Annotated-Semantic-Relationships-Datasets/blob/master/datasets/SemEval2007-Task4.tar.gz</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>Task 4的主要任务是简单名词(名词或基本名词短语)之间的语义关系的分类，例如，蜜蜂，显示了产品生产者关系的一个实例。这种分类发生在书面英语文本中的一个句子的语境中。语义关系分类算法可以应用于信息检索、信息提取、文本摘要、问答等方面。对文本蕴涵(Tatu和Moldovan, 2005)的认识是在高端NLP应用中成功使用这种类型的深入分析的一个例子。</p>
<h1 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h1><p> 大小：小数据集，包含7个关系类型和总共1529个注释示例。</p>
<p> 示例：<br><img src="https://i.loli.net/2018/05/27/5b09c465cdde2.jpg" alt=""></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.T. Chklovskiand P. Pantel. 2004. Verbocean: Mining the web for fine-grained semantic verb relations. In Proc.Conf.onEmpiricalMethodsin NaturalLanguageProcessing, EMNLP-04, pages 33–40, Barcelona, Spain.<br>2.R. Girju, D. Moldovan, M. Tatu, and D. Antohe. 2005. On the semantics of noun compounds. Computer Speech and Language, 19:479–496.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/25/朱述承_中研院中文句结构树资料库/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/25/朱述承_中研院中文句结构树资料库/" itemprop="url">中研院中文句结构树资料库</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-25T15:37:46+05:00">
                2018-05-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：朱述承<br>访问地址：<a href="http://treebank.sinica.edu.tw/" target="_blank" rel="noopener">http://treebank.sinica.edu.tw/</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>“中文句结构树资料库”(Sinica Treebank Version 3.0) 包含了6个档案，61,087个中文树图，361,834个词，是中央研究院词库小组从中央研究院平衡语料库 (Sinica Corpus) 中抽取句子，经由电脑剖析成结构树，并加以人工修正、检验后所得的成果。在中文句结构树中，我们标示了中文句语意和语法的讯息。此一“中文句结构树资料库”目前开放网上检索及资料移转，以供学者专家在中文句法、语意关系研究参考之用。另有1000个句结构树开放下载。</p>
<h1 id="100棵树图参考资料"><a href="#100棵树图参考资料" class="headerlink" title="100棵树图参考资料"></a>100棵树图参考资料</h1><p><a href="http://turing.iis.sinica.edu.tw/treesearch/" target="_blank" rel="noopener">http://turing.iis.sinica.edu.tw/treesearch/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/25/朱述承_中研院中古汉语标记语料库/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/25/朱述承_中研院中古汉语标记语料库/" itemprop="url">中研院中古汉语标记语料库</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-25T15:37:46+05:00">
                2018-05-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：朱述承<br>访问地址：<a href="http://lingcorpus.iis.sinica.edu.tw/middle/" target="_blank" rel="noopener">http://lingcorpus.iis.sinica.edu.tw/middle/</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>“中央研究院中古汉语标记语料库”是“中央研究院古汉语语料库”(Academia Sinica Ancient Chinese Corpus)的一个次语料库。“中央研究院古汉语语料库”是应汉语史研究需求而建构的语料库。这个语料库又可依是否经过断词及加标词类而分成两类，即未加标的素语料库以及有标注的标记语料库。目前素语料库所收集的语料已含盖上古汉语（先秦至西汉）、中古汉语（东汉魏晋南北朝）、近代汉语（唐五代以后）大部分的重要语料，并已陆续开放使用；在标记语料库方面，上古汉语及近代汉语都已有部分语料完成标注的工作，并视结果逐步提供线上检索。“中央研究院古汉语语料库”的建构始于一九九０年，创始者为黄居仁(语言所研究员)、谭朴森(英国伦敦大学亚非学院教授)、陈克健(资讯所研究员)、魏培泉(语言所研究员)等，最初的经费来源为蒋经国基金会及中央研究院历史语言研究所，目标是收集上古汉语的素语料。素语料库的构建自此未曾停歇，语料也由上古汉语扩充到中古汉语和近代汉语。</p>
<h1 id="使用限制"><a href="#使用限制" class="headerlink" title="使用限制"></a>使用限制</h1><p>院内检索限制两万行资料，院外检索限两千行资料。</p>
<h1 id="功能简介"><a href="#功能简介" class="headerlink" title="功能简介"></a>功能简介</h1><p>透过这个语料库的介面可以进行下列几项工作：<br>一、检索：首先进入“自订语料库”的画面，设定文献的搜寻范围，接著进入“内容检索”与“进阶处理”的画面，在自订语料库范围内针对词项、词头、词尾、词类、词类特征、重叠词型态……等进行检索以及进阶检索；<br>二、显示：有两种资料，“在关键词检索典”画面上，将检索到的资料依句显示在屏幕上，“文本”的画面出现该关键词所出现的该章回段落；<br>三、过滤：依照使用者设定的条件筛选语料；<br>四、词类累计：统计每个词类出现的数量；<br>五、统计共现率（collocation）；<br>六、排序：针对使用者设定的条件将语料依序排列。 </p>
<h1 id="文献内容"><a href="#文献内容" class="headerlink" title="文献内容"></a>文献内容</h1><p>抱朴子内篇  世说新语  新校搜神记  洛阳伽蓝记  颜氏家训<br>道行般若经  佛说兜沙经  阿门佛国经  佛说遗日摩尼宝经  佛说般舟三昧经<br>般舟三昧经  文殊师利问菩萨署经  法镜经  阿含口解十二因缘经  中本起经<br>修行本起经  梵摩渝经  佛说义足经  大明度经  佛说菩萨本业经<br>了本生死经  佛说四愿经  六度集经  生经  佛说普曜经<br>光讚经  大楼炭经  阿育王传  出曜经  大庄严论经<br>妙法莲华经  悲华经  百喻经  佛本行集经  佛说伅真陀罗所问如来三昧经<br>佛说阿闍世王经  齐民要术 </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/25/杜成玉_LibriSpeech文本和语音的有声读物数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/25/杜成玉_LibriSpeech文本和语音的有声读物数据集/" itemprop="url">LibriSpeech文本和语音的有声读物数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-25T15:37:46+05:00">
                2018-05-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：杜成玉<br>下载地址：<a href="http://www.openslr.org/12/" target="_blank" rel="noopener">http://www.openslr.org/12/</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>数据来源：<a href="https://www.zhihu.com/question/63383992/answer/222718972" target="_blank" rel="noopener">https://www.zhihu.com/question/63383992/answer/222718972</a><br>该数据集为包含文本和语音的有声读物数据集，由Vassil Panayotov编写的大约1000小时的16kHz读取英语演讲的语料库。数据来源于LibriVox项目的阅读有声读物，并经过细致的细分和一致。推荐应用方向：自然语音理解和分析挖掘</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Panayotov V, Chen G, Povey D, et al. Librispeech: an ASR corpus based on public domain audio books[C]//Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on. IEEE, 2015: 5206-5210.<br>[2]Amodei D, Ananthanarayanan S, Anubhai R, et al. Deep speech 2: End-to-end speech recognition in english and mandarin[C]//International Conference on Machine Learning. 2016: 173-182.<br>[3]Ko T, Peddinti V, Povey D, et al. Audio augmentation for speech recognition[C]//Sixteenth Annual Conference of the International Speech Communication Association. 2015.<br>[4]Soltau H, Liao H, Sak H. Neural speech recognizer: Acoustic-to-word LSTM model for large vocabulary speech recognition[J]. arXiv preprint arXiv:1610.09975, 2016.<br>[5]Chung Y A, Wu C C, Shen C H, et al. Audio word2vec: Unsupervised learning of audio segment representations using sequence-to-sequence autoencoder[J]. arXiv preprint arXiv:1603.00982, 2016.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/7/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><a class="extend next" rel="next" href="/page/9/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CNLR</p>
              <p class="site-description motion-element" itemprop="description">语料库、数据集及工具资源和教程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">212</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CNLR</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
