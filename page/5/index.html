<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="语料库、数据集及工具资源和教程">
<meta property="og:type" content="website">
<meta property="og:title" content="世界语言资源平台">
<meta property="og:url" content="http://yoursite.com/page/5/index.html">
<meta property="og:site_name" content="世界语言资源平台">
<meta property="og:description" content="语料库、数据集及工具资源和教程">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="世界语言资源平台">
<meta name="twitter:description" content="语料库、数据集及工具资源和教程">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/5/"/>





  <title>世界语言资源平台</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">世界语言资源平台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/21/杜成玉_iris数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/21/杜成玉_iris数据集/" itemprop="url">iris数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-21T15:37:46+05:00">
                2018-04-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：杜成玉<br>下载地址：<a href="https://www.yelp.com/dataset/download" target="_blank" rel="noopener">https://www.yelp.com/dataset/download</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>数据来源：<a href="https://blog.csdn.net/java1573/article/details/78865495。" target="_blank" rel="noopener">https://blog.csdn.net/java1573/article/details/78865495。</a><br>iris数据集的中文名是安德森鸢尾花卉数据集，英文全称是Anderson’s Iris data set。iris包含150个样本，对应数据集的每行数据。每行数据包含每个样本的四个特征和样本的类别信息，所以iris数据集是一个150行5列的二维表。通俗地说，iris数据集是用来给花做分类的数据集，每个样本包含了花萼长度、花萼宽度、花瓣长度、花瓣宽度四个特征（前4列），我们需要建立一个分类器，分类器可以通过样本的四个特征来判断样本属于山鸢尾、变色鸢尾还是维吉尼亚鸢尾（这三个名词都是花的品种）。iris的每个样本都包含了品种信息，即目标属性（第5列，也叫target或label）。</p>
<h1 id="数据集特征"><a href="#数据集特征" class="headerlink" title="数据集特征"></a>数据集特征</h1><p>数据来源：<a href="http://archive.ics.uci.edu/ml/datasets/Iris" target="_blank" rel="noopener">http://archive.ics.uci.edu/ml/datasets/Iris</a><br>特征：多变量<br>记录数：150<br>领域：生活<br>属性特征：实数<br>属性数目：4<br>相关应用：分类<br>缺失值？无</p>
<h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>iris的每个样本都包含了品种信息，即目标属性（第5列，也叫target或label）。将样本中的4个特征两两组合（任选2个特征分别作为横轴和纵轴，用不同的颜色标记不同品种的花），可以构建12种组合（其实只有6种，另外6种与之对称）。</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Fisher,R.A. “The use of multiple measurements in taxonomic problems” Annual Eugenics, 7, Part II, 179-188 (1936); also in “Contributions to Mathematical Statistics” (John Wiley, NY, 1950).<br>2.Duda,R.O., &amp; Hart,P.E. (1973) Pattern Classification and Scene Analysis. (Q327.D83) John Wiley &amp; Sons. ISBN 0-471-22361-1. See page 218.<br>3.Manuel Oliveira. Library Release Form Name of Author: Stanley Robson de Medeiros Oliveira Title of Thesis: Data Transformation For Privacy-Preserving Data Mining Degree: Doctor of Philosophy Year this Degree Granted. University of Alberta Library. 2005.<br>4.Ping Zhong and Masao Fukushima. A Regularized Nonsmooth Newton Method for Multi-class Support Vector Machines. 2005.<br>5.Anthony K H Tung and Xin Xu and Beng Chin Ooi. CURLER: Finding and Visualizing Nonlinear Correlated Clusters. SIGMOD Conference. 2005. </p>
<p><code>`</code></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/21/杜成玉_win数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/21/杜成玉_win数据集/" itemprop="url">win数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-21T15:37:46+05:00">
                2018-04-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：杜成玉<br>下载地址：<a href="http://archive.ics.uci.edu/ml/machine-learning-databases/wine/" target="_blank" rel="noopener">http://archive.ics.uci.edu/ml/machine-learning-databases/wine/</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="数据来源：https-www-jianshu-com-p-be23b3870d2e"><a href="#数据来源：https-www-jianshu-com-p-be23b3870d2e" class="headerlink" title="数据来源：https://www.jianshu.com/p/be23b3870d2e"></a>数据来源：<a href="https://www.jianshu.com/p/be23b3870d2e" target="_blank" rel="noopener">https://www.jianshu.com/p/be23b3870d2e</a></h2><p>这份数据集包含来自3种不同起源的葡萄酒的共178条记录。13个属性是葡萄酒的13种化学成分。通过化学分析可以来推断葡萄酒的起源。值得一提的是所有属性变量都是连续变量。</p>
<h1 id="数据集特征"><a href="#数据集特征" class="headerlink" title="数据集特征"></a>数据集特征</h1><h2 id="数据来源：http-archive-ics-uci-edu-ml-datasets-Wine"><a href="#数据来源：http-archive-ics-uci-edu-ml-datasets-Wine" class="headerlink" title="数据来源：http://archive.ics.uci.edu/ml/datasets/Wine"></a>数据来源：<a href="http://archive.ics.uci.edu/ml/datasets/Wine" target="_blank" rel="noopener">http://archive.ics.uci.edu/ml/datasets/Wine</a></h2><p>特征：多变量<br>记录数：178<br>领域：物理<br>属性特征：整型，实数<br>属性数目：13<br>相关应用：分类<br>缺失值？没有</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Ping Zhong and Masao Fukushima. A Regularized Nonsmooth Newton Method for Multi-class Support Vector Machines. 2005.<br>2.Igor Fischer and Jan Poland. Amplifying the Block Matrix Structure for Spectral Clustering. Telecommunications Lab. 2005.<br>3.Agapito Ledezma and Ricardo Aler and Araceli Sanchís and Daniel Borrajo. Empirical Evaluation of Optimized Stacking Configurations. ICTAI. 2004.<br>4.Jianbin Tan and David L. Dowe. MML Inference of Oblique Decision Trees. Australian Conference on Artificial Intelligence. 2004.<br>5.Sugato Basu. Semi-Supervised Clustering with Limited Background Knowledge. AAAI. 2004. </p>
<p><code>`</code></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/李华勇_gensim/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/李华勇_gensim/" itemprop="url">Gensim</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="https://radimrehurek.com/gensim/" target="_blank" rel="noopener">https://radimrehurek.com/gensim/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Gensim是一个免费的Python库，它可以用来从文档中自动提取语义主题，并且尽可能地做到轻松（对人）高效（对电脑）。</p>
<p>Gensim致力于处理原始的、非结构化的数字文本（普通文本）。Gensim中用到的算法，如潜在语义分析（Latent Semantic Analysis，LSA）、隐含狄利克雷分配（Latent Dirichlet Allocation，LDA）或随机预测（Random Projections）等，是通过检查单词在训练语料库的同一文档中的统计共现模式来发现文档的语义结构。这些算法都是无监督算法，也就是无需人工输入——你仅需一个普通文本的语料库即可。</p>
<p><img src="https://i.loli.net/2018/04/21/5adb301720070.jpg" alt=""></p>
<h1 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h1><p>内存占用低——任何时候都不会将整个语料库全部读入内存中，可以处理大规模、网络规模的语料库。</p>
<p>有效实现了几种流行的向量空间算法，包括Tf-idf、分布式增量潜在语义分析、分布式增量隐含狄利克雷分配或随机预测；增加新的模型也十分方便（没骗你！）。</p>
<p>预置了几种流行的数据格式的I/O封装器和转换器。</p>
<p>利用文档的语义代表计算其相似性。</p>
<p>整个gensim包围绕语料库（Corpus）、向量（Vector）、模型（Model）三个概念展开。</p>
<h1 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade gensim</span><br></pre></td></tr></table></figure>
<h2 id="tfidf表示"><a href="#tfidf表示" class="headerlink" title="tfidf表示"></a>tfidf表示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">34</span>]: tfidf = models.TfidfModel(corpus) <span class="comment"># step 1 -- initialize a model</span></span><br><span class="line">In [<span class="number">37</span>]: doc_bow = [(<span class="number">0</span>, <span class="number">1</span>), (<span class="number">1</span>, <span class="number">1</span>)]</span><br><span class="line">In [<span class="number">38</span>]: print(tfidf[doc_bow])</span><br><span class="line">[(<span class="number">0</span>, <span class="number">0.7071067811865476</span>), (<span class="number">1</span>, <span class="number">0.7071067811865476</span>)]</span><br><span class="line">In [<span class="number">39</span>]: corpus_tfidf = tfidf[corpus]</span><br><span class="line">In [<span class="number">40</span>]: pprint(corpus_tfidf)</span><br><span class="line">&lt;gensim.interfaces.TransformedCorpus object at <span class="number">0x0129FFD0</span>&gt;</span><br><span class="line">In [<span class="number">41</span>]: <span class="keyword">for</span> doc <span class="keyword">in</span> corpus_tfidf:</span><br><span class="line">    ...:     pprint(doc)</span><br><span class="line">    ...:</span><br></pre></td></tr></table></figure>
<h2 id="lsi表示"><a href="#lsi表示" class="headerlink" title="lsi表示"></a>lsi表示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">42</span>]: lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=<span class="number">2</span>) <span class="comment"># initialize an LSI transformation</span></span><br><span class="line">In [<span class="number">43</span>]: corpus_lsi = lsi[corpus_tfidf] <span class="comment">#  create a double wrapper over the original corpus: bow-&gt;tfidf-&gt;fold-in-lsi</span></span><br><span class="line">In [<span class="number">47</span>]: lsi.print_topics(<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">47</span>]: [(<span class="number">0</span>, <span class="string">'-0.703*"trees" + -0.538*"graph" + -0.402*"minors" + -0.187*"survey" + -0.061*"system" + -0.060*"time" + -0.060*"response" + -0.058*"user" + -0.049*"computer" + -0.035*"interface"'</span>), (<span class="number">1</span>, <span class="string">'-0.460*"system" + -0.373*"user" + -0.332*"eps" + -0.328*"interface" + -0.320*"time" + -0.320*"response" + -0.293*"computer" + -0.280*"human" + -0.171*"survey" + 0.161*"trees"'</span>)]</span><br><span class="line">In [<span class="number">48</span>]: <span class="keyword">for</span> doc <span class="keyword">in</span> corpus_lsi:</span><br><span class="line">    ...:     print(doc)</span><br><span class="line">    ...:</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.066007833960906648</span>), (<span class="number">1</span>, <span class="number">-0.5200703306361848</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.19667592859142974</span>), (<span class="number">1</span>, <span class="number">-0.76095631677000308</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.089926399724468281</span>), (<span class="number">1</span>, <span class="number">-0.72418606267525087</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.075858476521785109</span>), (<span class="number">1</span>, <span class="number">-0.632055158600343</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.10150299184980502</span>), (<span class="number">1</span>, <span class="number">-0.57373084830029464</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.70321089393783032</span>), (<span class="number">1</span>, <span class="number">0.16115180214026176</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.87747876731198216</span>), (<span class="number">1</span>, <span class="number">0.16758906864659895</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.90986246868185694</span>), (<span class="number">1</span>, <span class="number">0.14086553628719531</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.61658253505692839</span>), (<span class="number">1</span>, <span class="number">-0.053929075663890019</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="相似度查询"><a href="#相似度查询" class="headerlink" title="相似度查询"></a>相似度查询</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">49</span>]: <span class="keyword">from</span> gensim <span class="keyword">import</span> similarities</span><br><span class="line">In [<span class="number">50</span>]: index = similarities.MatrixSimilarity(lsi[corpus]) <span class="comment"># transform corpus to LSI space and index it</span></span><br></pre></td></tr></table></figure>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ol>
<li>Khosrovian K, Pfahl D, Garousi V. GENSIM 2.0: a customizable process simulation model for software process evaluation[C]//International Conference on Software Process. Springer, Berlin, Heidelberg, 2008: 294-306.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/李华勇_CN-DBpedia/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/李华勇_CN-DBpedia/" itemprop="url">CN-DBpedia</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="http://kw.fudan.edu.cn/cndbpedia/intro/" target="_blank" rel="noopener">http://kw.fudan.edu.cn/cndbpedia/intro/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>CN-DBpedia是由复旦大学知识工场实验室研发并维护的大规模通用领域结构化百科，其前身是复旦GDM中文知识图谱，是国内最早推出的也是目前最大规模的开放百科中文知识图谱，涵盖数千万实体和数亿级的关系，相关知识服务API累计调用量已达6亿次。</p>
<p>CN-DBpedia以通用百科知识沉淀为主线，以垂直纵深领域图谱积累为支线，致力于为机器语义理解提供了丰富的背景知识，为实现机器语言认知提供必要支撑。</p>
<p>CN-DBpedia已经从百科领域延伸至法律、工商、金融、文娱、科技、军事、教育、医疗等十多个垂直领域，为各类行业智能化应用提供支撑性知识服务，目前已有近百家单位在使用。</p>
<p>CN-DBpedia具有体量巨大、质量精良、实时更新、丰富的API服务等特色。CN-DBpedia已经成为业界开放中文知识图谱的首选。基于CN-DBpedia的知识图谱构建与应用能力已经输出并应用在华为、小I机器人、中国电信、中国移动、同花顺等业界领军企业的产品与解决方案中。</p>
<p>CN-DBpedia提供全套API，并且免费开放使用。</p>
<h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><h2 id="浏览器检索"><a href="#浏览器检索" class="headerlink" title="浏览器检索"></a>浏览器检索</h2><p>直接在网页上search即可。<br>比如输入 北京语言大学 的结果如下：<br><img src="https://i.loli.net/2018/04/19/5ad84af89927d.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84b3f2c647.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84b646724c.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84b792f19f.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84b8e94b19.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84c086f34d.jpg" alt=""></p>
<h2 id="API接口"><a href="#API接口" class="headerlink" title="API接口"></a>API接口</h2><h3 id="api-cndbpedia-ment2ent："><a href="#api-cndbpedia-ment2ent：" class="headerlink" title="api/cndbpedia/ment2ent："></a>api/cndbpedia/ment2ent：</h3><p>输入实体指称项名称(mention name)，返回对应实体(entity)的列表，json格式。</p>
<p>请求参数<br>q：实体指称项名称(mention name)；必填项</p>
<p>apikey：开发者的访问密钥；可选项（注：不加访问密钥会存在访问限制）</p>
<p>返回字段<br>status：本次API访问状态，如果成功返回“ok”，如果失败返回“fail”</p>
<p>ret： 返回entity name list</p>
<p>URL<br><a href="http://shuyantech.com/api/cndbpedia/ment2ent?q=*" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/ment2ent?q=*</a>*</p>
<p><a href="http://shuyantech.com/api/cndbpedia/ment2ent?q=**&amp;apikey=*" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/ment2ent?q=**&amp;apikey=*</a>*</p>
<p>Example<br><a href="http://shuyantech.com/api/cndbpedia/ment2ent?q=红楼梦" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/ment2ent?q=红楼梦</a></p>
<h3 id="api-cndbpedia-avpair："><a href="#api-cndbpedia-avpair：" class="headerlink" title="api/cndbpedia/avpair："></a>api/cndbpedia/avpair：</h3><p>输入实体名，返回实体全部的三元组知识</p>
<p>请求参数<br>q：实体名称(entity name)；必填项</p>
<p>apikey：开发者的访问密钥；可选项（注：不加访问密钥会存在访问限制）</p>
<p>返回字段<br>status：本次API访问状态，如果成功返回“ok”，如果失败返回“fail”</p>
<p>ret： 返回attribute-value pair list, 每个pair也是一个list （[attribute, value]）</p>
<p>URL<br><a href="http://shuyantech.com/api/cndbpedia/avpair?q=*" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/avpair?q=*</a>*</p>
<p><a href="http://shuyantech.com/api/cndbpedia/avpair?q=**&amp;apikey=*" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/avpair?q=**&amp;apikey=*</a>*</p>
<p>Example<br><a href="http://shuyantech.com/api/cndbpedia/avpair?q=复旦大学" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/avpair?q=复旦大学</a></p>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ol>
<li>Bo Xu, Yong Xu, Jiaqing Liang, Chenhao Xie, Bin Liang, Wanyun Cui, and Yanghua Xiao. CN-DBpedia: A Never-Ending Chinese Knowledge Extraction System. In International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, pp. 428-438. Springer, Cham, 2017.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/刘晓_genia tagger/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/刘晓_genia tagger/" itemprop="url">GENIA Tagger</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="http://www.nactem.ac.uk/tsujii/GENIA/tagger/" title="http://www.nactem.ac.uk/tsujii/GENIA/tagger/" target="_blank" rel="noopener">http://www.nactem.ac.uk/tsujii/GENIA/tagger/</a></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>GENIA Tagger对生物医学文本进行标记、浅解析和命名实体识别。<br>GENIA标记器分析英语句子并输出基本形式，词性标记，块标记和命名实体标记。标记器专门针对生物医学文本（如MEDLINE摘要）进行了调整。如果需要从生物医学文档中提取信息，该标记器可能是一个有用的预处理工具。可以尝试<a href="http://text0.mib.man.ac.uk/software/geniatagger/" target="_blank" rel="noopener">演示页面</a>上的标记器。  </p>
<h2 id="使用教程"><a href="#使用教程" class="headerlink" title="使用教程"></a>使用教程</h2><p><strong>安装：</strong>  </p>
<ul>
<li>下载地址：<a href="http://www.nactem.ac.uk/tsujii/GENIA/tagger/geniatagger-3.0.2.tar.gz" target="_blank" rel="noopener">http://www.nactem.ac.uk/tsujii/GENIA/tagger/geniatagger-3.0.2.tar.gz</a>  </li>
<li>解压文档：tar xvzf geniatagger.tar.gz  </li>
<li><p>Make:  </p>
<pre><code>cd geniatagger  
make
</code></pre></li>
<li><p>标记句子：准备一个每行包含一个句子的文本文件，然后  </p>
</li>
</ul>
<pre><code>./geniatagger &lt; RAWTEXT &gt; TAGGEDTEXT
</code></pre><table>
<thead>
<tr>
<th>word</th>
<th>base</th>
<th>POStag</th>
<th>chunktag</th>
<th>NEtag</th>
</tr>
</thead>
<tbody>
<tr>
<td>word1</td>
<td>base1</td>
<td>POStag1</td>
<td>chunktag1</td>
<td>NEtag1</td>
</tr>
<tr>
<td>word2</td>
<td>base2</td>
<td>POStag2</td>
<td>chunktag2</td>
<td>NEtag2</td>
</tr>
<tr>
<td>  :</td>
<td>:</td>
<td>:</td>
<td>:</td>
<td>:</td>
</tr>
</tbody>
</table>
<p>标记器以以上制表符分隔的格式输出基本形式，词性（POS）标记，块标记和命名实体（NE）标记。<br>块以IOB2格式表示（B表示BEGIN，I表示内部，O表示外部）。</p>
<p><strong>示例：</strong>  </p>
<pre><code>echo &quot;Inhibition of NF-kappaB activation reversed the anti-apoptotic effect of isochamaejasmin.&quot; | ./geniatagger
</code></pre><table>
<thead>
<tr>
<th>word</th>
<th>base</th>
<th>POStag</th>
<th>chunktag</th>
<th>NEtag</th>
</tr>
</thead>
<tbody>
<tr>
<td>Inhibition</td>
<td>Inhibition</td>
<td>NN</td>
<td>B-NP</td>
<td>O</td>
</tr>
<tr>
<td>of</td>
<td>of</td>
<td>IN</td>
<td>B-PP</td>
<td>O</td>
</tr>
<tr>
<td>NF-kappaB</td>
<td>NF-kappaB</td>
<td>NN</td>
<td>B-NP</td>
<td>B-protein</td>
</tr>
<tr>
<td>activation</td>
<td>activation</td>
<td>NN</td>
<td>I-NP</td>
<td>O</td>
</tr>
<tr>
<td>reversed</td>
<td>reverse</td>
<td>VBD</td>
<td>B-VP</td>
<td>O</td>
</tr>
<tr>
<td>the</td>
<td>the</td>
<td>DT</td>
<td>B-NP</td>
<td>O</td>
</tr>
<tr>
<td>anti-apoptotic</td>
<td>anti-apoptotic</td>
<td>JJ</td>
<td>I-NP</td>
<td>O</td>
</tr>
<tr>
<td>effect</td>
<td>effect</td>
<td>NN</td>
<td>I-NP</td>
<td>O</td>
</tr>
<tr>
<td>of</td>
<td>of</td>
<td>IN</td>
<td>B-PP</td>
<td>O</td>
</tr>
<tr>
<td>isochamaejasmin</td>
<td>isochamaejasmin</td>
<td>NN</td>
<td>B-NP</td>
<td>O</td>
</tr>
<tr>
<td>.</td>
<td>.</td>
<td>.</td>
<td>O</td>
<td>O</td>
</tr>
</tbody>
</table>
<p>通过查看块标签，您可以从该输出中轻松提取四个名词短语（“抑制”，“NF-kappaB激活”，“抗凋亡效应”和“isochamaejasmin”）。您还可以使用指定的实体标签查找蛋白质名称。</p>
<h2 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h2><p>[1] S. Kulick, A. Bies, M. Liberman, M. Mandel, R. McDonald, M. Palmer, A. Schein and L. Ungar. Integrated Annotation for Biomedical Information Extraction, HLT/NAACL 2004 Workshop: Biolink 2004, pp. 61-68.<br>[2] Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim, Tomoko Ohta, John McNaught, Sophia Ananiadou, and Jun’ichi Tsujii, Developing a Robust Part-of-Speech Tagger for Biomedical Text, Advances in Informatics - 10th Panhellenic Conference on Informatics, LNCS 3746, pp. 382-392, 2005 (pdf)<br>[3] Yoshimasa Tsuruoka and Jun’ichi Tsujii, Bidirectional Inference with the Easiest-First Strategy for Tagging Sequence Data, Proceedings of HLT/EMNLP 2005, pp. 467-474. (pdf)</p>
<p>上文来源：<a href="http://www.nactem.ac.uk/GENIA/tagger/" target="_blank" rel="noopener">http://www.nactem.ac.uk/GENIA/tagger/</a></p>
<p>GENIA Tagger Demo：<a href="http://text0.mib.man.ac.uk/software/geniatagger/" target="_blank" rel="noopener">http://text0.mib.man.ac.uk/software/geniatagger/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/刘晓_百度自然语言处理API服务/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/刘晓_百度自然语言处理API服务/" itemprop="url">百度自然语言处理API服务</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="http://ai.baidu.com/tech/nlp" target="_blank" rel="noopener">http://ai.baidu.com/tech/nlp</a> </p>
<h2 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h2><p>百度自然语言处理：<a href="http://ai.baidu.com/tech/nlp" target="_blank" rel="noopener">http://ai.baidu.com/tech/nlp</a><br>SDK下载地址：<a href="http://ai.baidu.com/sdk#nlp" target="_blank" rel="noopener">http://ai.baidu.com/sdk#nlp</a>  </p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Python SDK文档，主要针对Python开发者描述百度自然语言处理接口服务的相关技术内容。 </p>
<p><strong>接口能力：</strong>  </p>
<ul>
<li>接口名称：     接口能力简要描述  </li>
<li>词法分析：        分词、词性标注、专名识别  </li>
<li>依存句法分析：    自动分析文本中的依存句法结构信息  </li>
<li>词向量表示：    查询词汇的词向量，实现文本的可计算  </li>
<li>DNN语言模型：    判断一句话是否符合语言表达习惯，输出分词结果并给出每个词在句子中的概率值  </li>
<li>词义相似度：    计算两个给定词语的语义相似度  </li>
<li>短文本相似度：    判断两个文本的相似度得分  </li>
<li>评论观点抽取：    提取一个句子观点评论的情感属性  </li>
<li>情感倾向分析：    对包含主观观点信息的文本进行情感极性类别（积极、消极、中性）的判断，并给出相应的置信度  </li>
<li>中文分词：     切分出连续文本中的基本词汇序列（已合并到词法分析接口）  </li>
<li>词性标注：     为自然语言文本中的每个词汇赋予词性（已合并到词法分析接口）  </li>
</ul>
<p>版本更新：<br>2018.01.25    2.2.0    新增文本标签API<br>2017.12.22    2.0.0    SDK代码重构<br>2017.5.11    1.0.0    自然语言处理服务上线</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><strong>安装自然语言处理 Python SDK</strong>  </p>
<p>自然语言处理 Python SDK目录结构：</p>
<p>|── README.md  </p>
<p>├── aip                   //SDK目录  </p>
<p>│   ├── <strong>init</strong>.py          //导出类  </p>
<p>│   ├── base.py           //aip基类  </p>
<p>│   ├── http.py           //http请求  </p>
<p>│   └── nlp.py //自然语言处理  </p>
<p>└── setup.py              //setuptools安装  </p>
<p><strong>支持Python版本：2.7.+ ,3.+</strong></p>
<p><strong>安装使用Python SDK有如下方式：</strong></p>
<p>如果已安装pip：  </p>
<pre><code>pip install baidu-aip  
</code></pre><p>如果已安装setuptools:  </p>
<pre><code>python setup.py install  
</code></pre><h2 id="使用教程"><a href="#使用教程" class="headerlink" title="使用教程"></a>使用教程</h2><p><strong>新建AipNlp</strong>    </p>
<p>AipNlp是自然语言处理的Python SDK客户端，为使用自然语言处理的开发人员提供了一系列的交互方法。  </p>
<p>参考如下代码新建一个AipNlp：</p>
<pre><code>from aip import AipNlp

&quot;&quot;&quot; 你的 APPID AK SK &quot;&quot;&quot;
APP_ID = &apos;你的 App ID&apos;
API_KEY = &apos;你的 Api Key&apos;
SECRET_KEY = &apos;你的 Secret Key&apos;

client = AipNlp(APP_ID, API_KEY, SECRET_KEY)  
</code></pre><p>在上面代码中，常量APP_ID在百度云控制台中创建，常量API_KEY与SECRET_KEY是在创建完毕应用后，系统分配给用户的，均为字符串，用于标识用户，为访问做签名验证，可在AI服务控制台中的应用列表中查看。</p>
<p>注意：如您以前是百度云的老用户，其中API_KEY对应百度云的“Access Key ID”，SECRET_KEY对应百度云的“Access Key Secret”。</p>
<p><strong>配置AipNlp</strong>  </p>
<p>如果用户需要配置AipNlp的网络请求参数(一般不需要配置)，可以在构造AipNlp之后调用接口设置参数，目前只支持以下参数：  </p>
<table>
<thead>
<tr>
<th>接口</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>setConnectionTimeoutInMillis</td>
<td>建立连接的超时时间（单位：毫秒  </td>
</tr>
<tr>
<td>setSocketTimeoutInMillis</td>
<td>通过打开的连接传输数据的超时时间（单位：毫秒）</td>
</tr>
</tbody>
</table>
<h2 id="接口说明"><a href="#接口说明" class="headerlink" title="接口说明"></a>接口说明</h2><p><strong>词法分析</strong><br>词法分析接口向用户提供分词、词性标注、专名识别三大功能；能够识别出文本串中的基本词汇（分词），对这些词汇进行重组、标注组合后词汇的词性，并进一步识别出命名实体。    </p>
<pre><code>text = &quot;百度是一家高科技公司&quot;

&quot;&quot;&quot; 调用词法分析 &quot;&quot;&quot;
client.lexer(text);  
</code></pre><ul>
<li>参数 –&gt; text : 必选，string类型，是一个待分析文本（目前仅支持GBK编码），长度不超过65536字节。   </li>
</ul>
<ul>
<li>返回参数分析：  </li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>必需</th>
<th>详细说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>string</td>
<td>是</td>
<td>原始单条请求文本</td>
</tr>
<tr>
<td>items</td>
<td>array(object)</td>
<td>是</td>
<td>词汇数组，每个元素对应结果中的一个词</td>
</tr>
<tr>
<td>+item</td>
<td>string</td>
<td>是</td>
<td>词汇的字符串</td>
</tr>
<tr>
<td>+ne</td>
<td>string</td>
<td>是</td>
<td>命名实体类型，命名实体识别算法使用。词性标注算法中，此项为空串</td>
</tr>
<tr>
<td>+pos</td>
<td>string</td>
<td>是</td>
<td>词性，词性标注算法使用。命名实体识别算法中，此项为空串</td>
</tr>
<tr>
<td>+byte_offset</td>
<td>int</td>
<td>是</td>
<td>在text中的字节级offset（使用GBK编码）</td>
</tr>
<tr>
<td>+byte_length</td>
<td>int</td>
<td>是</td>
<td>字节级length（使用GBK编码）</td>
</tr>
<tr>
<td>+uri</td>
<td>string</td>
<td>否</td>
<td>链指到知识库的URI，只对命名实体有效。对于非命名实体和链接不到知识库的命名实体，此项为空串</td>
</tr>
<tr>
<td>+formal</td>
<td>string</td>
<td>否</td>
<td>词汇的标准化表达，主要针对时间、数字单位，没有归一化表达的，此项为空串</td>
</tr>
<tr>
<td>+basic_words</td>
<td>array(string)</td>
<td>是</td>
<td>基本词成分</td>
</tr>
<tr>
<td>+loc_details</td>
<td>array(object)</td>
<td>否</td>
<td>地址成分，非必需，仅对地址型命名实体有效，没有地址成分的，此项为空数组。</td>
</tr>
<tr>
<td>++type</td>
<td>string</td>
<td>是</td>
<td>成分类型，如省、市、区、县</td>
</tr>
<tr>
<td>++byte_offset</td>
<td>int</td>
<td>是</td>
<td>在item中的字节级offset（使用GBK编码）</td>
</tr>
<tr>
<td>++byte_length</td>
<td>nt</td>
<td>是</td>
<td>字节级length（使用GBK编码）  </td>
</tr>
</tbody>
</table>
<ul>
<li><p>词法分析返回示例：    </p>
<pre><code> {
     &quot;status&quot;:0,
     &quot;version&quot;:&quot;ver_1_0_1&quot;,
     &quot;results&quot;:[
     {
       &quot;retcode&quot;:0,
       &quot;text&quot;:&quot;百度是一家高科技公司&quot;,
      &quot;items&quot;:[
     {
        &quot;byte_length&quot;:4,
        &quot;byte_offset&quot;:0,
        &quot;formal&quot;:&quot;&quot;,
        &quot;item&quot;:&quot;百度&quot;,
        &quot;ne&quot;:&quot;ORG&quot;,
        &quot;pos&quot;:&quot;&quot;,
        &quot;uri&quot;:&quot;&quot;,
        &quot;loc_details&quot;:[ ],
        &quot;basic_words&quot;:[&quot;百度&quot;]
      },
      {
        &quot;byte_length&quot;:2,
        &quot;byte_offset&quot;:4,
        &quot;formal&quot;:&quot;&quot;,
        &quot;item&quot;:&quot;是&quot;,
        &quot;ne&quot;:&quot;&quot;,
        &quot;pos&quot;:&quot;v&quot;,
        &quot;uri&quot;:&quot;&quot;,
        &quot;loc_details&quot;:[ ],
        &quot;basic_words&quot;:[&quot;是&quot;]
      },
      {
        &quot;byte_length&quot;:4,
        &quot;byte_offset&quot;:6,
        &quot;formal&quot;:&quot;&quot;,
        &quot;item&quot;:&quot;一家&quot;,
        &quot;ne&quot;:&quot;&quot;,
        &quot;pos&quot;:&quot;m&quot;,
        &quot;uri&quot;:&quot;&quot;,
        &quot;loc_details&quot;:[ ],
        &quot;basic_words&quot;:[&quot;一&quot;,&quot;家&quot;]
       },
       {
        &quot;byte_length&quot;:6,
        &quot;byte_offset&quot;:10,
        &quot;formal&quot;:&quot;&quot;,
        &quot;item&quot;:&quot;高科技&quot;,
        &quot;ne&quot;:&quot;&quot;,
        &quot;pos&quot;:&quot;n&quot;,
        &quot;uri&quot;:&quot;&quot;,
        &quot;loc_details&quot;:[ ],
        &quot;basic_words&quot;:[&quot;高&quot;,&quot;科技&quot;]
       },
       {
       &quot;byte_length&quot;:4,
       &quot;byte_offset&quot;:16,
       &quot;formal&quot;:&quot;&quot;,
       &quot;item&quot;:&quot;公司&quot;,
       &quot;ne&quot;:&quot;&quot;,
       &quot;pos&quot;:&quot;n&quot;,
       &quot;uri&quot;:&quot;&quot;,
       &quot;loc_details&quot;:[ ],
       &quot;basic_words&quot;:[&quot;公司&quot;]
       }
      ]
   }
  ]
}
</code></pre></li>
</ul>
<ul>
<li>词性缩略说明：  </li>
</ul>
<table>
<thead>
<tr>
<th>词性</th>
<th>含义</th>
<th>词性</th>
<th>含义</th>
<th>词性</th>
<th>含义</th>
<th>词性</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>n</td>
<td>普通名词</td>
<td>f</td>
<td>方位名词</td>
<td>s</td>
<td>处所名词</td>
<td>t</td>
<td>时间名词</td>
</tr>
<tr>
<td>nr</td>
<td>人名</td>
<td>ns</td>
<td>地名</td>
<td>nt</td>
<td>机构团体名</td>
<td>nw</td>
<td>作品名</td>
</tr>
<tr>
<td>nz</td>
<td>其他专名</td>
<td>v</td>
<td>普通动词</td>
<td>vd</td>
<td>动副词</td>
<td>vn</td>
<td>名动词</td>
</tr>
<tr>
<td>a</td>
<td>形容词</td>
<td>ad</td>
<td>副形词</td>
<td>an</td>
<td>名形词</td>
<td>d</td>
<td>副词</td>
</tr>
<tr>
<td>m</td>
<td>数量词</td>
<td>q</td>
<td>量词</td>
<td>r</td>
<td>代词</td>
<td>p</td>
<td>介词</td>
</tr>
<tr>
<td>c</td>
<td>连词</td>
<td>u</td>
<td>助词</td>
<td>xc</td>
<td>其他虚词</td>
<td>w</td>
<td>标点符号  </td>
</tr>
</tbody>
</table>
<ul>
<li>专名识别缩略词含义:</li>
</ul>
<table>
<thead>
<tr>
<th>缩略词</th>
<th>含义</th>
<th>缩略词</th>
<th>含义</th>
<th>缩略词</th>
<th>含义</th>
<th>缩略词</th>
<th>含义  </th>
</tr>
</thead>
<tbody>
<tr>
<td>PER</td>
<td>人名</td>
<td>LOC</td>
<td>地名</td>
<td>ORG</td>
<td>机构名</td>
<td>TIME</td>
<td>时间  </td>
</tr>
</tbody>
</table>
<p><strong>词法分析（定制版）</strong><br>词法分析接口向用户提供分词、词性标注、专名识别三大功能；能够识别出文本串中的基本词汇（分词），对这些词汇进行重组、标注组合后词汇的词性，并进一步识别出命名实体。定制版接口的使用教程请看链接：<a href="http://ai.baidu.com/forum/topic/show/496975" target="_blank" rel="noopener">http://ai.baidu.com/forum/topic/show/496975</a></p>
<pre><code>text = &quot;百度是一家高科技公司&quot;

&quot;&quot;&quot; 调用词法分析（定制版） &quot;&quot;&quot;
client.lexerCustom(text);
</code></pre><ul>
<li>词法分析（定制版） 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>待分析文本（目前仅支持GBK编码），长度不超过65536字节</td>
</tr>
</tbody>
</table>
<ul>
<li>词法分析（定制版） 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>必需</th>
<th>详细说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>string</td>
<td>是</td>
<td>原始单条请求文本</td>
</tr>
<tr>
<td>items</td>
<td>array(object)</td>
<td>是</td>
<td>词汇数组，每个元素对应结果中的一个词</td>
</tr>
<tr>
<td>+item</td>
<td>string</td>
<td>是</td>
<td>词汇的字符串</td>
</tr>
<tr>
<td>+ne</td>
<td>string</td>
<td>是</td>
<td>命名实体类型，命名实体识别算法使用。词性标注算法中，此项为空串</td>
</tr>
<tr>
<td>+pos</td>
<td>string</td>
<td>是</td>
<td>词性，词性标注算法使用。命名实体识别算法中，此项为空串</td>
</tr>
<tr>
<td>+byte_offset</td>
<td>int</td>
<td>是</td>
<td>在text中的字节级offset（使用GBK编码）</td>
</tr>
<tr>
<td>+byte_length</td>
<td>int</td>
<td>是</td>
<td>字节级length（使用GBK编码）</td>
</tr>
<tr>
<td>+uri</td>
<td>string</td>
<td>否</td>
<td>链指到知识库的URI，只对命名实体有效。对于非命名实体和链接不到知识库的命名实体，此项为空串</td>
</tr>
<tr>
<td>+formal</td>
<td>string</td>
<td>否</td>
<td>词汇的标准化表达，主要针对时间、数字单位，没有归一化表达的，此项为空串</td>
</tr>
<tr>
<td>+basic_words</td>
<td>array(string)</td>
<td>是</td>
<td>基本词成分</td>
</tr>
<tr>
<td>+loc_details</td>
<td>array(object)</td>
<td>否</td>
<td>地址成分，非必需，仅对地址型命名实体有效，没有地址成分的，此项为空数组。</td>
</tr>
<tr>
<td>++type</td>
<td>string</td>
<td>是</td>
<td>成分类型，如省、市、区、县</td>
</tr>
<tr>
<td>++byte_offset</td>
<td>int</td>
<td>是</td>
<td>在item中的字节级offset（使用GBK编码）</td>
</tr>
<tr>
<td>++byte_length</td>
<td>int</td>
<td>是</td>
<td>字节级length（使用GBK编码）  </td>
</tr>
</tbody>
</table>
<p><strong>依存句法分析</strong>  </p>
<p>依存句法分析接口可自动分析文本中的依存句法结构信息，利用句子中词与词之间的依存关系来表示词语的句法结构信息（如“主谓”、“动宾”、“定中”等结构关系），并用树状结构来表示整句的结构（如“主谓宾”、“定状补”等）。  </p>
<pre><code>text = &quot;张飞&quot;

&quot;&quot;&quot; 调用依存句法分析 &quot;&quot;&quot;
client.depParser(text);

&quot;&quot;&quot; 如果有可选参数 &quot;&quot;&quot;
options = {}
options[&quot;mode&quot;] = 1

&quot;&quot;&quot; 带参数调用依存句法分析 &quot;&quot;&quot;
client.depParser(text, options)  
</code></pre><ul>
<li>依存句法分析 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>待分析文本（目前仅支持GBK编码），长度不超过256字节</td>
</tr>
<tr>
<td>mode</td>
<td>否</td>
<td>string</td>
<td>模型选择。默认值为0，可选值mode=0（对应web模型）；mode=1（对应query模型）</td>
</tr>
</tbody>
</table>
<ul>
<li>依存句法分析 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>详细说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>uint64</td>
<td>随机数，本次请求的唯一标识码</td>
</tr>
<tr>
<td>id</td>
<td>number</td>
<td>词的ID</td>
</tr>
<tr>
<td>word</td>
<td>string</td>
<td>词</td>
</tr>
<tr>
<td>postag</td>
<td>string</td>
<td>词性，请参照API文档中的词性（postag)取值范围</td>
</tr>
<tr>
<td>head</td>
<td>int</td>
<td>词的父节点ID</td>
</tr>
<tr>
<td>+deprel</td>
<td>string</td>
<td>词与父节点的依存关系，请参照API文档的依存关系标识</td>
</tr>
</tbody>
</table>
<ul>
<li><p>依存句法分析 返回示例    </p>
<pre><code>{
&quot;log_id&quot;: 12345,
&quot;text&quot;:&quot;今天天气怎么样&quot;,
&quot;items&quot;:[
{
&quot;id&quot;:&quot;1&quot;, //id
&quot;word&quot;:&quot;今天&quot;, //word
&quot;postag&quot;:&quot;t&quot;, //POS tag
&quot;head&quot;:&quot;2&quot;, //id of current word&apos;s parent
&quot;deprel&quot;:&quot;ATT&quot;  //depend relations between current word and parent
},
{
&quot;id&quot;:&quot;2&quot;,
&quot;word&quot;:&quot;天气&quot;,
&quot;postag&quot;:&quot;n&quot;,
&quot;head&quot;:&quot;3&quot;,
&quot;deprel&quot;:&quot;SBV&quot;,
},
{
&quot;id&quot;:&quot;3&quot;,
&quot;word&quot;:&quot;怎么样&quot;,
&quot;postag&quot;:&quot;r&quot;,
&quot;head&quot;:&quot;0&quot;,
&quot;deprel&quot;:&quot;HED&quot;,
}
]
}  
</code></pre></li>
</ul>
<p><strong>词向量表示</strong>  </p>
<p>词向量表示接口提供中文词向量的查询功能。</p>
<pre><code>word = &quot;张飞&quot;

&quot;&quot;&quot; 调用词向量表示 &quot;&quot;&quot;
client.wordEmbedding(word);
</code></pre><ul>
<li>词向量表示 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<p>word    是    string    文本内容（GBK编码），最大64字节</p>
<ul>
<li>词向量表示 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>描述  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>uint64</td>
<td>请求唯一标识码</td>
</tr>
<tr>
<td>word</td>
<td>string</td>
<td>查询词</td>
</tr>
<tr>
<td>vec</td>
<td>float</td>
<td>词向量结果表示</td>
</tr>
</tbody>
</table>
<ul>
<li><p>词向量表示 返回示例  </p>
<pre><code>{
  &quot;word&quot;: &quot;张飞&quot;,
  &quot;vec&quot;: [
0.233962,
0.336867,
0.187044,
0.565261,
0.191568,
0.450725,
...
0.43869,
-0.448038,
0.283711,
-0.233656,
0.555556
  ]
}  
</code></pre></li>
</ul>
<p><strong> DNN语言模型 </strong></p>
<p>中文DNN语言模型接口用于输出切词结果并给出每个词在句子中的概率值,判断一句话是否符合语言表达习惯。</p>
<pre><code>text = &quot;床前明月光&quot;

&quot;&quot;&quot; 调用DNN语言模型 &quot;&quot;&quot;
client.dnnlm(text);
</code></pre><ul>
<li>DNN语言模型 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>文本内容（GBK编码），最大512字节，不需要切词  </td>
</tr>
</tbody>
</table>
<ul>
<li>DNN语言模型 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>uint64</td>
<td>请求唯一标识码</td>
</tr>
<tr>
<td>word</td>
<td>string</td>
<td>句子的切词结果</td>
</tr>
<tr>
<td>prob</td>
<td>float</td>
<td>该词在句子中的概率值,取值范围[0,1]</td>
</tr>
<tr>
<td>ppl</td>
<td>float</td>
<td>描述句子通顺的值：数值越低，句子越通顺</td>
</tr>
</tbody>
</table>
<pre><code>{
  &quot;text&quot;: &quot;床前明月光&quot;,
  &quot;items&quot;: [
    {
      &quot;word&quot;: &quot;床&quot;,
      &quot;prob&quot;: 0.0000385273
    },
    {
      &quot;word&quot;: &quot;前&quot;,
      &quot;prob&quot;: 0.0289018
    },
    {
      &quot;word&quot;: &quot;明月&quot;,
      &quot;prob&quot;: 0.0284406
    },
    {
      &quot;word&quot;: &quot;光&quot;,
      &quot;prob&quot;: 0.808029
    }
  ],
  &quot;ppl&quot;: 79.0651
}  
</code></pre><p><strong>词义相似度</strong></p>
<p>输入两个词，得到两个词的相似度结果。</p>
<pre><code>word1 = &quot;北京&quot;

word2 = &quot;上海&quot;

&quot;&quot;&quot; 调用词义相似度 &quot;&quot;&quot;
client.wordSimEmbedding(word1, word2);

&quot;&quot;&quot; 如果有可选参数 &quot;&quot;&quot;
options = {}

&quot;&quot;&quot; 带参数调用词义相似度 &quot;&quot;&quot;
client.wordSimEmbedding(word1, word2, options)
</code></pre><ul>
<li>词义相似度 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>word_1</td>
<td>是</td>
<td>string</td>
<td>词1（GBK编码），最大64字节</td>
</tr>
<tr>
<td>word_2</td>
<td>是</td>
<td>string</td>
<td>词1（GBK编码），最大64字节  </td>
</tr>
</tbody>
</table>
<ul>
<li>词义相似度 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>描述  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>number</td>
<td>请求唯一标识码,随机数</td>
</tr>
<tr>
<td>score</td>
<td>number</td>
<td>相似度分数</td>
</tr>
<tr>
<td>words</td>
<td>array</td>
<td>输入的词列表</td>
</tr>
<tr>
<td>+word_1</td>
<td>string</td>
<td>输入的word1参数</td>
</tr>
<tr>
<td>+word_2</td>
<td>string</td>
<td>输入的word2参数  </td>
</tr>
</tbody>
</table>
<ul>
<li><p>词义相似度 返回示例    </p>
<pre><code>{
    &quot;score&quot;: 0.456862,
    &quot;words&quot;: {
    &quot;word_1&quot;: &quot;北京&quot;,
    &quot;word_2&quot;: &quot;上海&quot;
    }
}
</code></pre></li>
</ul>
<p><strong>短文本相似度</strong></p>
<p>短文本相似度接口用来判断两个文本的相似度得分。</p>
<pre><code>text1 = &quot;浙富股份&quot;

text2 = &quot;万事通自考网&quot;

&quot;&quot;&quot; 调用短文本相似度 &quot;&quot;&quot;
client.simnet(text1, text2);

&quot;&quot;&quot; 如果有可选参数 &quot;&quot;&quot;
options = {}
options[&quot;model&quot;] = &quot;CNN&quot;

&quot;&quot;&quot; 带参数调用短文本相似度 &quot;&quot;&quot;
client.simnet(text1, text2, options)
</code></pre><ul>
<li>短文本相似度 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>可选值范围</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text_1</td>
<td>是</td>
<td>string</td>
<td></td>
<td>待比较文本1（GBK编码），最大512字节</td>
</tr>
<tr>
<td>text_2</td>
<td>是</td>
<td>string</td>
<td></td>
<td>待比较文本2（GBK编码），最大512字节</td>
</tr>
<tr>
<td>model</td>
<td>否</td>
<td>string</td>
<td>BOW /CNN /GRNN</td>
<td>默认为”BOW”，可选”BOW”、”CNN”与”GRNN”  </td>
</tr>
</tbody>
</table>
<ul>
<li>短文本相似度 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>描述  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>number</td>
<td>请求唯一标识</td>
</tr>
<tr>
<td>score</td>
<td>number</td>
<td>两个文本相似度得分</td>
</tr>
<tr>
<td>texts</td>
<td>array</td>
<td>输入文本</td>
</tr>
<tr>
<td>+text_1</td>
<td>string</td>
<td>第一个短文本</td>
</tr>
<tr>
<td>+text_2</td>
<td>string</td>
<td>第二个短文本  </td>
</tr>
</tbody>
</table>
<ul>
<li><p>短文本相似度 返回示例</p>
<pre><code>{
    &quot;log_id&quot;: 12345,
    &quot;texts&quot;:{
    &quot;text_1&quot;:&quot;浙富股份&quot;,
    &quot;text_2&quot;:&quot;万事通自考网&quot;
    },
   &quot;score&quot;:0.3300237655639648 //相似度结果
},  
</code></pre></li>
</ul>
<p><strong>评论观点抽取</strong></p>
<p>评论观点抽取接口用来提取一条评论句子的关注点和评论观点，并输出评论观点标签及评论观点极性。</p>
<pre><code>text = &quot;三星电脑电池不给力&quot;

&quot;&quot;&quot; 调用评论观点抽取 &quot;&quot;&quot;
client.commentTag(text);

&quot;&quot;&quot; 如果有可选参数 &quot;&quot;&quot;
options = {}
options[&quot;type&quot;] = 13

&quot;&quot;&quot; 带参数调用评论观点抽取 &quot;&quot;&quot;
client.commentTag(text, options)
</code></pre><ul>
<li>评论观点抽取 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>可选值范围</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td></td>
<td>评论内容（GBK编码），最大10240字节</td>
</tr>
<tr>
<td>type</td>
<td>否</td>
<td>string</td>
<td>1 - 酒店 2 - KTV 3 - 丽人 4 - 美食餐饮 5 - 旅游 6 - 健康 7 - 教育 8 - 商业 9 - 房产 10 - 汽车 11 - 生活 12 - 购物 13 - 3C</td>
<td>评论行业类型，默认为4（餐饮美食）</td>
</tr>
</tbody>
</table>
<ul>
<li>评论观点抽取 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>uint64</td>
<td>请求唯一标识码</td>
</tr>
<tr>
<td>prop</td>
<td>string</td>
<td>匹配上的属性词</td>
</tr>
<tr>
<td>adj</td>
<td>string</td>
<td>匹配上的描述词</td>
</tr>
<tr>
<td>sentiment</td>
<td>int</td>
<td>该情感搭配的极性（0表示消极，1表示中性，2表示积极）</td>
</tr>
<tr>
<td>begin_pos</td>
<td>int</td>
<td>该情感搭配在句子中的开始位置</td>
</tr>
<tr>
<td>end_pos</td>
<td>int</td>
<td>该情感搭配在句子中的结束位置</td>
</tr>
<tr>
<td>abstract</td>
<td>string</td>
<td>对应于该情感搭配的短句摘要</td>
</tr>
</tbody>
</table>
<ul>
<li><p>评论观点抽取 返回示例</p>
<pre><code>{
    &quot;items&quot;: [
    {
    &quot;prop&quot;:&quot;电池&quot;,
    &quot;adj&quot;: &quot;不给力&quot;,
    &quot;sentiment&quot;: 0,
    &quot;begin_pos&quot;: 8,
    &quot;end_pos&quot;: 18,
    &quot;abstract&quot;:&quot;三星电脑&lt;span&gt;电池不给力&lt;/span&gt;&quot;
    }
    ]
}  
</code></pre></li>
</ul>
<p><strong>情感倾向分析</strong></p>
<p>对包含主观观点信息的文本进行情感极性类别（积极、消极、中性）的判断，并给出相应的置信度。</p>
<pre><code>text = &quot;苹果是一家伟大的公司&quot;

&quot;&quot;&quot; 调用情感倾向分析 &quot;&quot;&quot;
client.sentimentClassify(text);
</code></pre><ul>
<li>情感倾向分析 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>文本内容（GBK编码），最大2048字节  </td>
</tr>
</tbody>
</table>
<ul>
<li>情感倾向分析 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>是否必须</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>输入的文本内容</td>
</tr>
<tr>
<td>items</td>
<td>是</td>
<td>array</td>
<td>输入的词列表</td>
</tr>
<tr>
<td>+sentiment</td>
<td>是</td>
<td>number</td>
<td>表示情感极性分类结果, 0:负向，1:中性，2:正向</td>
</tr>
<tr>
<td>+confidence</td>
<td>是</td>
<td>number</td>
<td>表示分类的置信度</td>
</tr>
<tr>
<td>+positive_prob</td>
<td>是</td>
<td>number</td>
<td>表示属于积极类别的概率</td>
</tr>
<tr>
<td>+negative_prob</td>
<td>是</td>
<td>number</td>
<td>表示属于消极类别的概率</td>
</tr>
</tbody>
</table>
<ul>
<li><p>情感倾向分析 返回示例</p>
<pre><code>{
    &quot;text&quot;:&quot;苹果是一家伟大的公司&quot;,
    &quot;items&quot;:[
    {
    &quot;sentiment&quot;:2,//表示情感极性分类结果
    &quot;confidence&quot;:0.40, //表示分类的置信度
    &quot;positive_prob&quot;:0.73, //表示属于积极类别的概率
    &quot;negative_prob&quot;:0.27  //表示属于消极类别的概率
    }
    ]
}
</code></pre></li>
</ul>
<p><strong>文章标签</strong> </p>
<p>文章标签服务能够针对网络各类媒体文章进行快速的内容理解，根据输入含有标题的文章，输出多个内容标签以及对应的置信度，用于个性化推荐、相似文章聚合、文本内容分析等场景。</p>
<pre><code>title = &quot;iphone手机出现“白苹果”原因及解决办法，用苹果手机的可以看下&quot;

content = &quot;如果下面的方法还是没有解决你的问题建议来我们门店看下成都市锦江区红星路三段99号银石广场24层01室。&quot;

&quot;&quot;&quot; 调用文章标签 &quot;&quot;&quot;
client.keyword(title, content);
</code></pre><ul>
<li>文章标签 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>title</td>
<td>是</td>
<td>string</td>
<td>篇章的标题，最大80字节</td>
</tr>
<tr>
<td>content</td>
<td>是</td>
<td>string</td>
<td>篇章的正文，最大65535字节  </td>
</tr>
</tbody>
</table>
<ul>
<li>文章标签 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>是否必选</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>items</td>
<td>是</td>
<td>array(object)</td>
<td>关键词结果数组，每个元素对应抽取到的一个关键词</td>
</tr>
<tr>
<td>+tag</td>
<td>是</td>
<td>string</td>
<td>关注点字符串</td>
</tr>
<tr>
<td>+score</td>
<td>是</td>
<td>number</td>
<td>权重(取值范围0~1)  </td>
</tr>
</tbody>
</table>
<ul>
<li>文章标签 返回示例</li>
</ul>
<pre><code>{
    &quot;log_id&quot;: 4457308639853058292,
    &quot;items&quot;: [
    {
        &quot;score&quot;: 0.997762,
        &quot;tag&quot;: &quot;iphone&quot;
    },
    {
        &quot;score&quot;: 0.861775,
        &quot;tag&quot;: &quot;手机&quot;
    },
    {
        &quot;score&quot;: 0.845657,
        &quot;tag&quot;: &quot;苹果&quot;
    },
    {
        &quot;score&quot;: 0.83649,
        &quot;tag&quot;: &quot;苹果公司&quot;
    },
    {
        &quot;score&quot;: 0.797243,
        &quot;tag&quot;: &quot;数码&quot;
    }
    ]
}  
</code></pre><p><strong>文章分类</strong>  </p>
<p>对文章按照内容类型进行自动分类，首批支持娱乐、体育、科技等26个主流内容类型，为文章聚类、文本内容分析等应用提供基础技术支持。</p>
<pre><code>title = &quot;欧洲冠军杯足球赛&quot;

content = &quot;欧洲冠军联赛是欧洲足球协会联盟主办的年度足球比赛，代表欧洲俱乐部足球最高荣誉和水平，被认为是全世界最高素质、最具影响力以及最高水平的俱乐部赛事，亦是世界上奖金最高的足球赛事和体育赛事之一。&quot;

&quot;&quot;&quot; 调用文章分类 &quot;&quot;&quot;
client.topic(title, content);
</code></pre><ul>
<li>文章分类 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>title</td>
<td>是</td>
<td>string</td>
<td>篇章的标题，最大80字节</td>
</tr>
<tr>
<td>content</td>
<td>是</td>
<td>string</td>
<td>篇章的正文，最大65535字节</td>
</tr>
</tbody>
</table>
<ul>
<li>文章分类 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>详细说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>item</td>
<td>object</td>
<td>分类结果，包含一级与二级分类</td>
</tr>
<tr>
<td>+lv1_tag_list</td>
<td>array of objects</td>
<td>一级分类结果</td>
</tr>
<tr>
<td>+lv2_tag_list</td>
<td>array of objects</td>
<td>二级分类结果</td>
</tr>
<tr>
<td>++score</td>
<td>float</td>
<td>类别标签对应得分，范围0-1</td>
</tr>
<tr>
<td>++tag</td>
<td>string</td>
<td>类别标签</td>
</tr>
</tbody>
</table>
<ul>
<li><p>文章分类 返回示例</p>
<pre><code>{
    &quot;log_id&quot;: 5710764909216517248,
    &quot;item&quot;: {
    &quot;lv2_tag_list&quot;: [
    {
    &quot;score&quot;: 0.895467,
    &quot;tag&quot;: &quot;足球&quot;
    },
    {
    &quot;score&quot;: 0.794878,
    &quot;tag&quot;: &quot;国际足球&quot;
    }
    ],
    &quot;lv1_tag_list&quot;: [
    {
    &quot;score&quot;: 0.88808,
    &quot;tag&quot;: &quot;体育&quot;
    }
    ]
    }
}
</code></pre></li>
</ul>
<p>错误信息</p>
<p><strong>错误返回格式</strong>  </p>
<p>若请求错误，服务器将返回的JSON文本包含以下参数：</p>
<ul>
<li>error_code：错误码。</li>
<li>error_msg：错误描述信息，帮助理解和解决发生的错误。  </li>
</ul>
<p><strong>错误码</strong>  </p>
<table>
<thead>
<tr>
<th>错误码</th>
<th>错误信息</th>
<th>描述  </th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>Open api request limit reached</td>
<td>集群超限额</td>
</tr>
<tr>
<td>14</td>
<td>IAM Certification failed</td>
<td>IAM鉴权失败，建议用户参照文档自查生成sign的方式是否正确，或换用控制台中ak sk的方式调用</td>
</tr>
<tr>
<td>17</td>
<td>Open api daily request limit reached</td>
<td>每天流量超限额</td>
</tr>
<tr>
<td>18</td>
<td>Open api qps request limit reached</td>
<td>QPS超限额</td>
</tr>
<tr>
<td>19</td>
<td>Open api total request limit reached</td>
<td>请求总量超限额</td>
</tr>
<tr>
<td>100</td>
<td>Invalid parameter</td>
<td>无效参数</td>
</tr>
<tr>
<td>110</td>
<td>Access token invalid or no longer valid</td>
<td>Access Token失效</td>
</tr>
<tr>
<td>111</td>
<td>Access token expired</td>
<td>Access token过期</td>
</tr>
<tr>
<td>282000</td>
<td>internal error</td>
<td>服务器内部错误，请再次请求， 如果持续出现此类错误，请通过QQ群（632426386）或工单联系技术支持团队。</td>
</tr>
<tr>
<td>282002</td>
<td>input encoding error</td>
<td>编码错误，请使用GBK编码</td>
</tr>
<tr>
<td>282004</td>
<td>invalid parameter(s)</td>
<td>请求中包含非法参数，请检查后重新尝试</td>
</tr>
<tr>
<td>282130</td>
<td>no result</td>
<td>当前查询无结果返回，出现此问题的原因一般为：参数配置存在问题，请检查后重新尝试</td>
</tr>
<tr>
<td>282131</td>
<td>input text too long</td>
<td>输入长度超限，请查看文档说明</td>
</tr>
<tr>
<td>282133</td>
<td>param {参数名} not exist</td>
<td>接口参数缺失</td>
</tr>
<tr>
<td>282300</td>
<td>word error</td>
<td>word不在算法词典中</td>
</tr>
<tr>
<td>282301</td>
<td>word_1 error</td>
<td>word_1提交的词汇暂未收录，无法比对相似度</td>
</tr>
<tr>
<td>282302</td>
<td>word_2 error</td>
<td>word_2提交的词汇暂未收录，无法比对相似度</td>
</tr>
<tr>
<td>282303</td>
<td>word_1&amp;word_2 error</td>
<td>word_1和word_2暂未收录，无法比对相似度</td>
</tr>
</tbody>
</table>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/李华勇_中国哲学电子书计划/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/李华勇_中国哲学电子书计划/" itemprop="url">中国哲学书电子化计划</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="https://ctext.org" target="_blank" rel="noopener">https://ctext.org</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>本网站的目的是提供尽可能精确且便利使用的中国古代原典文献（尤其先秦两汉文献），把这些资料以 恰当结构、可搜索模式来展现，并且广泛使用现代技术作为工具使这些文献更容易学习和研究，因而使更多人有机会接触这些原典文献。</p>
<p>本站提供不同的版本：中文版和英文版，简体字和繁体字。您可以使用任何一页左上边的连接随时转换。</p>
<h1 id="主要功能与内容"><a href="#主要功能与内容" class="headerlink" title="主要功能与内容"></a>主要功能与内容</h1><h2 id="原典资料库"><a href="#原典资料库" class="headerlink" title="原典资料库"></a>原典资料库</h2><p>本网站最主要的部分为古籍资料库，此资料库包含各种从哲学、历史、语言学等角度被视为重要的文献，写作年代以先秦两汉爲主。 本网站的所有资料都存在一个专门设计的数据库，以便读浏览和搜索的方便。 此外，部分原典有附英文或现代汉语翻译，这些翻译是一段一段对照原典而附上的，因此很容易从译文找出对应的原典，或从原典找出对应的译文。</p>
<p>在原典段落的左手边，系统将会显示下列的部份图标；点击这些图标，可以便利享用本站的许多独特功能：</p>
<p><img src="https://i.loli.net/2018/04/19/5ad8454700586.jpg" alt=""></p>
<h2 id="内部字典"><a href="#内部字典" class="headerlink" title="内部字典"></a>内部字典</h2><p>内部汉字字典合并三个来源的信息：统一码联盟（Unicode Consortium）的“Unihan”数据库、上述的原典资料库、以及本网站新开发的CTP字典。 其中Unihan数据库提供有关汉字的基本信息，包括部首、笔画数、异体字、标准字典中的出处、以及英文翻译（但此英文翻译以现代汉语用法爲主）。 原典资料库则给每一个字提供原典中的具体出处。最后，CTP字典试图对汉字的语义和实际运用提供一个尽可能完整的分析。 虽然从汉字的数量上看大多数汉字是单义词，但少数很常用的字却有许多不同的用法，这些不同用法通常有不同语义或读法。 CTP字典把这些不同意义或不同读法的用法分开处理，并且通过原典数据库给每一个不同用法分别提供原典出处。 这一功能是透过一种“语义链接”的手段而实现的，即建立从某篇某段某句中的某字到CTP字典中的相关用法的链接。 建立这些链接需要对文本的理解，因而是一个手动的且耗时的程序；因此CTP字典的范围目前很有限（但日益增加）。 您可以参考CTP字典中对 与、说、故的解释。</p>
<h2 id="词语分析表"><a href="#词语分析表" class="headerlink" title="词语分析表"></a>词语分析表</h2><p>通过内部字典和上述的语义链接，本站还可以对原典数据库中的任何段落提供词语分析表。 词语分析表为段落中的每一个字显示字典中的英文翻译及其它信息，并且对于有语意链接的词语显示词语在此脉络中的意义。 例如，在《论语》的第一段中，系统会显示“乐”的正确读法是“le”而不是“yue”，且该句中“说”的用法跟“悦”的读法、意义相同（请参考《学而》第一段词语分析表）。</p>
<p>建立语意链接的计划正在进行，因此目前也有缺少链接的字。当一个字尚未有语意链接时，系统将会显示此字的基本资料，并提供至完整字典项目的连接。</p>
<h2 id="相似段落资料"><a href="#相似段落资料" class="headerlink" title="相似段落资料"></a>相似段落资料</h2><p>由于种种原因，许多早期文献含有与其它文献相似的片段或较长的段落，足以证明两个著作并非完全独立而形成的。此现象有时表明原作者有意识的抄写了当时已形成的其它著作；有时表明谋一个俗语当时已流行；也有时是由其它的原因造成的。在许多情况下，虽然这些相似的片段具有明显的相似性，并足以保证此相似性并非巧合，与此同时这些片段有时候具有重要且有趣的不同之处。</p>
<p>本站的相似段落功能把这些相似或相同的段落连接起来，且显示相似部份以便对照。任何具有相似段落讯息的段落将会显示图标；点击此图标将会显示此段落、所有相似段落及其连接。</p>
<p>相似段落讯息可以使用下述的“高级搜索”功能来搜索。</p>
<h2 id="原典影印本"><a href="#原典影印本" class="headerlink" title="原典影印本"></a>原典影印本</h2><p>许多早期文献具有不同的现存版本。这些版本的不同有些是因不同的文献历史背景而产生的，也有一些产生于纠正抄写错误，也有部份来自假借字现象而造成的，而另外还有更多造成原因。这些造成原因加起来使得我们很难看出今天的电子版或印刷版的原典是否“正确”；甚至使得我们很难以下定义说什么叫做“正确”的版本，毕竟未必真的曾经存在过所谓“最原始的”由一个作者所写作的版本。</p>
<p>因此，本站为越来越多的原典提供原典扫瞄版，且为原典每一段落提供至扫瞄版的连接。原典数据库中的每一个字应对应于扫瞄版的一个字，而系统能够给使用者显示原典及原典扫瞄版的对照本，以便使用者确定原典与扫瞄本无误。另，因为扫瞄本有可能经过后世的研究而被视为本身有误，因此系统将会注明所有被修改的字词，同时保留原本错误的字以便与扫瞄版对照。</p>
<p>每个具有影印本的原典段落会显示图标；点击此图标将会打开电子版与扫瞄本的对照显示，并突显对应于此段落的部份。</p>
<h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><h2 id="全文搜索"><a href="#全文搜索" class="headerlink" title="全文搜索"></a>全文搜索</h2><p>要进行全文搜索时，先确认浏览器中打开的网页属于网站“原典全文”的部分，然后在左下角的“搜索”框内选择搜索范围并输入所要搜索的字词。（如：学而时习之）且点击“搜索”。全文资料库支持使用多数的搜索条件；在不同搜索条件之间输入半角空格分割（如：学而时 不亦君子），系统将会列出所有同时符合所有搜索条件的段落。若要搜索含有空格的英文词组，在词组外加上英文引号（如：”Mozi said”）。点击“高级搜索”可以使用更有弹性的搜索方式。</p>
<h2 id="辞典搜索"><a href="#辞典搜索" class="headerlink" title="辞典搜索"></a>辞典搜索</h2><p>要进行辞典搜索时，先确认浏览器中打开的网页属于网站“辞典”的部分，然后在左下角的“搜索”框内输入所要查询的字词。（如：学）且点击“搜索”。当输入的文字不作为辞典中的项目时，系统将会以表格的方式为被输入的每一个汉字列出辞典中的资料。</p>
<h2 id="研究资料搜索"><a href="#研究资料搜索" class="headerlink" title="研究资料搜索"></a>研究资料搜索</h2><p>要进行研究资料搜索时，先确认浏览器中打开的网页属于网站“研究资料”的部分，然后在左下角的“搜索”框内输入所要查询的字词。（如：Ethics）且点击“搜索”。点击“高级搜索”可以使用更有弹性的搜索方式。</p>
<h2 id="一般性图标"><a href="#一般性图标" class="headerlink" title="一般性图标"></a>一般性图标</h2><p><img src="https://i.loli.net/2018/04/19/5ad8464eac912.jpg" alt=""></p>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ol>
<li>吴智雄. 由 “数位人文研究法” 探《 皇明经世文编》 所载明初的海洋朝贡议论[J]. 南海学刊, 2016, 2(1): 18-27.</li>
<li>Sturgeon D. 中國哲學書電子化計劃[J]. 網址: <a href="http://ctext" target="_blank" rel="noopener">http://ctext</a>. org, 2011.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/刘晓_pynlpir/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/刘晓_pynlpir/" itemprop="url">pynlpir</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="http://ictclas.nlpir.org/" target="_blank" rel="noopener">http://ictclas.nlpir.org/</a></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>PyNLPIR是NLPIR / ICTCLAS中文分词软件的Python包装器<br>NLPIR汉语分词系统(又名ICTCLAS2013),主要功能包括中文分词；词性标注；命名实体识别；用户词典功能；支持GBK编码、UTF8编码、BIG5编码。新增微博分词、新词发现与关键词提取。<br>本文主要介绍Python版本—<a href="http://pynlpir.readthedocs.io/en/latest/" target="_blank" rel="noopener">PyNLPIR</a>  。</p>
<p>PyNLPIR允许使用NLPIR轻松地对中文文本进行分类，NLPIR是最受人们关注的中文文本分析器之一。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>PyNLPIR被设计为在Python 2.7或3上运行。由于包含了NLPIR库文件，它只能在Windows，GNU / Linux或macOS上运行。  </p>
<p><strong>Pip 安装：</strong>  </p>
<pre><code>$ pip install pynlpir
$ pynlpir update
</code></pre><p><strong>从源代码安装：</strong>  </p>
<p>如果你想手动安装PyNLPIR：  </p>
<ul>
<li>从<a href="https://pypi.org/project/PyNLPIR/" target="_blank" rel="noopener">https://pypi.org/project/PyNLPIR/</a>页面下载最新版本。</li>
<li>解压文件。</li>
<li>从目录PyNLPIR-XX中，运行python setup.py install</li>
<li>运行pynlpir 更新以下载最新的许可证文件。  </li>
</ul>
<p>这会在Python 站点包目录中安装PyNLPIR 。  </p>
<p><strong>安装开发版本：</strong>  </p>
<p><a href="https://github.com/tsroten/pynlpir" target="_blank" rel="noopener">PyNLPIR的代码</a>托管在GitHub上。首先安装开发版，确保安装了Git 。然后运行：  </p>
<pre><code>$ git clone git：//github.com/tsroten/pynlpir.git
$ pip install -e pynlpir
$ pynlpir update
</code></pre><p>这会将PyNLPIR目录链接到你的站点包 目录。pynlpir 更新将从NLPIR项目下载最新的许可证。  </p>
<p><strong>运行测试：</strong>  </p>
<p>运行测试很容易。下载并解压缩PyNLPIR的源代码后，从PyNLPIR的源代码目录中运行以下代码：</p>
<pre><code>$ python setup.py 测试  
</code></pre><p>如果要使用不同版本的Python运行测试，请安装并运行tox：</p>
<pre><code>$ pip安装tox
 $ tox
</code></pre><h2 id="使用教程"><a href="#使用教程" class="headerlink" title="使用教程"></a>使用教程</h2><p>有两种使用PyNLPIR的方法：直接使用PyNLPIR提供的ctypes接口或使用PyNLPIR的辅助函数。该ctypes的界面更广泛，更严格。辅助函数很容易使用，但不提供对每个NLPIR函数的访问。也可以使用这两种方法的混合。首先，让我们看看辅助函数。  </p>
<p><strong>PyNLPIR助手函数</strong><br>辅助函数位于PyNLPIR的<strong>init</strong>.py文件中，因此可以通过直接导入pynlpir来访问它们。</p>
<p><strong>初始化NLPIR</strong><br>导入PyNLPIR会自动加载NLPIR API库：  </p>
<pre><code>import pynlpir  
</code></pre><p>一旦它被导入，调用open（）来告诉NLPIR打开数据文件并初始化API。有关指定其他数据目录的信息，请参阅open（）的文档。  </p>
<pre><code>pynlpir.open()  
</code></pre><p>默认情况下，输入被假定为unicode或UTF-8编码。如果您想使用不同的编码（例如GBK或BIG5），请在调用open（）时使用encoding关键字参数：  </p>
<pre><code>pynlpir.open(encoding=&apos;big5&apos;)  
#Tip:无论指定什么编码，都可以将unicode字符串传递给 pynlpir函数。  
</code></pre><p>PyNLPIR的辅助函数总是返回unicode字符串。<br>一旦初始化了NLPIR，就可以开始分割和分析文本。   </p>
<p><strong>细分文本：</strong><br>让我们分段一个冗长的句子：   </p>
<pre><code>s = &apos;NLPIR分词系统前身为2000年发布的ICTCLAS词法分析系统，从2009年开始，为了和以前工作进行大的区隔，并推广NLPIR自然语言处理与信息检索共享平台，调整命名为NLPIR分词系统。&apos;
pynlpir.segment(s)

# Sample output: [(&apos;NLPIR&apos;, &apos;noun&apos;), (&apos;分词&apos;, &apos;verb&apos;), (&apos;系统&apos;, &apos;noun&apos;), (&apos;前身&apos;, &apos;noun&apos;), (&apos;为&apos;, &apos;preposition&apos;), (&apos;2000年&apos;, &apos;time word&apos;), (&apos;发布&apos;, &apos;verb&apos;), . . . ]
</code></pre><p>如果不想词性标注，segment（）中的参数pos_tagging设置为False：</p>
<pre><code>pynlpir.segment(s, pos_tagging=False)

# Sample output: [&apos;NLPIR&apos;, &apos;分词&apos;, &apos;系统&apos;, &apos;前身&apos;, &apos;为&apos;, &apos;2000年&apos;, &apos;发布&apos;, . . . ]  
</code></pre><p>还可以自定义如何显示词性标签。默认情况下，只使用最通用的词性名称部分，即父母（例如 ‘名词’，而不是’转录地名’）。如果希望使用最具体的演讲名称部分，即儿童，请将pos_names设置 为’child’：  </p>
<pre><code>pynlpir.segment(s, pos_names=&apos;child&apos;)
</code></pre><p>如果你想要了解关于词性标签的更多信息，你可以设置 pos_names为’all’，并且返回一个词性层次结构（例如， ‘noun：toponym：transcribed toponym’）：  </p>
<pre><code>pynlpir.segment(s, pos_names=&apos;all&apos;)
</code></pre><p>默认情况下，词性标记以英语返回。如果您希望看到中文（例如’名词’而不是’名词’），请将pos_english设置为False：  </p>
<pre><code>pynlpir.segment(s, pos_english=False)  
</code></pre><p><strong>获取关键词:</strong><br>另一个有用的函数是get_key_words（）：</p>
<pre><code>pynlpir.get_key_words(s, weighted=True)
[(&apos;NLPIR&apos;, 2.08), (&apos;系统&apos;, 1.74)]  
</code></pre><p>get_key_words（）分析给定的中文文本字符串并返回NLPIR认为关键字的单词。如果权重为 True，则关键字的权重也作为浮点数返回。  </p>
<p><strong>关闭API:</strong><br>现在我们已经看了PyNLPIR辅助函数的简要介绍，让我们看看如何关闭API。</p>
<p>当使用PyNLPIR时，你可以通过调用close（）来释放分配的内存 ：  </p>
<pre><code>pynlpir.close()    
</code></pre><p><strong>ctypes NLPIR接口:</strong>  </p>
<p>pynlpir.nlpir通过 ctypes提供对NLPIR’C函数的访问。你可以直接调用它们，而不用担心上面的辅助函数。这些函数的工作方式与C语言的对应函数几乎完全相同。</p>
<p>pynlpir.nlpir包含由NLPIR导出的调用其许多函数（例如编码和词性常量）所需的模块级常量。有关更多信息，请参阅 pynlpir.nlpir上的API页面。</p>
<p>以下各节不提供关于如何使用NLPIR的全面说明。NLPIR有它自己的文档。以下部分提供了有关如何开始使用PyNLPIR的基本信息，前提是您熟悉NLPIR。如果你不是，请务必查看下面链接的文档。  </p>
<p><strong>分词与词性标注示例：</strong><br>需要注意的是，使用pynlpir的时候，首先要初始化，也就是需要先open（pynlpir.open()），当执行完成后需要对应的关闭（pynlpir.close()）<br>代码示例：</p>
<pre><code># coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( &quot;utf-8&quot; )

import pynlpir

pynlpir.open()
s = &apos;因为我比较懒,所以我就只是修改了这句话,代码还是原博客的&apos;
segments = pynlpir.segment(s)
for segment in segments:
     print segment[0], &apos;\t&apos;, segment[1]

pynlpir.close()  
</code></pre><p>运行结果:  </p>
<pre><code>因为  preposition
我   pronoun
比较  adverb
懒   adjective
,   punctuation mark
所以  conjunction
我   pronoun
就   adverb
只   adverb
是   verb
修改  verb
了   particle
这   pronoun
句   classifier
话   noun
,   punctuation mark
代码  noun
还   adverb
是   verb
原   distinguishing word
博客  noun
的   particle

Process finished with exit code 0  
</code></pre><p>NLPIR还可以更加详细的输出词性信息，做如下修改：</p>
<pre><code>segments = pynlpir.segment(s)
改为：
segments = pynlpir.segment(s,pos_names=&apos;all&apos;)
你可以在segment时同时配置如下参数，调整结果，请自行选择：
pos_names=&apos;all&apos; / &apos;child&apos; / &apos;parent&apos; #默认是parent， 表示获取该词性的最顶级词性，child表示获取该词性的最具体的信息，all表示获取该词性相关的所有词性信息，相当于从其顶级词性到该词性的一条路径
pos_english=False # 词性标注结果以中文的形式显示
pos_tagging=False # 只做分词，而不显示词性
</code></pre><p>运行后可以得到更加详细的结果：</p>
<pre><code>因为  preposition
我   pronoun:personal pronoun
比较  adverb
懒   adjective
,   punctuation mark:comma
所以  conjunction
我   pronoun:personal pronoun
就   adverb
只   adverb
是   verb:verb 是
修改  verb
了   particle:particle 了/喽
这   pronoun:demonstrative pronoun:predicate demonstrative pronoun
句   classifier
话   noun
,   punctuation mark:comma
代码  noun
还   adverb
是   verb:verb 是
原   distinguishing word
博客  noun:other proper noun
的   particle:particle 的/底  
</code></pre><p><strong>关键词提取代码：</strong></p>
<pre><code># coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( &quot;utf-8&quot; )

import pynlpir

pynlpir.open()
s = &apos;因为我比较懒,所以我就只是修改了这句话,代码还是原博客的&apos;
print &apos;关键词测试:\n&apos;
key_words = pynlpir.get_key_words(s, weighted=True)
for key_word in key_words:
    print key_word[0], &apos;\t&apos;, key_word[1]

pynlpir.close()
</code></pre><p>运行后提取出来的关键词应该是：</p>
<pre><code>关键词测试:

修改  2.0
代码  2.0
博客  2.0

Process finished with exit code 0
</code></pre><p>本篇工具介绍参考：<br><a href="https://blog.csdn.net/MebiuW/article/details/52232562?locationNum=12" target="_blank" rel="noopener">https://blog.csdn.net/MebiuW/article/details/52232562?locationNum=12
</a><br><a href="http://www.shareditor.com/blogshow/?blogId=74" title="http://www.shareditor.com/blogshow/?blogId=74" target="_blank" rel="noopener">http://www.shareditor.com/blogshow/?blogId=74</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/李华勇_OpenNMT/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/李华勇_OpenNMT/" itemprop="url">OpenNMT</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="http://zh.opennmt.net/" target="_blank" rel="noopener">http://zh.opennmt.net/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>海量的数据背景下，人工翻译已经无法承载所有的翻译任务，机器翻译效果并不十分理想，但在有些情况下可以减少理解外语文本所需要的时间和精力。我本人出身英语专业，但是仍然感觉阅读英文文本所花费的时间和精力是中文文本的2-3倍，比如中文一分钟能够阅读600-1000字甚至更多，但英语文章书籍，一般也就200-300单词而已，而且时间长了，大脑更疲劳，难以有效获取信息。所以借助机器翻译，先大致浏览所需理解的外语文本，不失为一种节约时间精力的方式。随着机器翻译的效果越来越好，它的应用场景也越来越广泛，甚至可能彻底改变人类相互沟通的方式。</p>
<p>目前机器翻译已经基本都从传统的统计翻译，变成了神经网络机器翻译，效果有较大的提升，特别是西方语种之间，比如英德互译。而中英互译仍然有差距，不过我想达到令人满意的效果只是时间问题，Google 和 百度 的机器翻译，在某些类型的文档翻译上，已经几乎超过人类，比如科技类的论文，Google 的机器翻译效果尤其好。如果让一个译者去翻译一篇科技类的论文，成本非常高，有很多专业词汇，还有数学符号，懂的人并不多，翻译起来也费时费力，但机器翻译却对这类文本有着很高的效率，十分令人欣喜。</p>
<p>OpenNMT 是一个由 Harvard NLP (哈佛大学自然语言处理研究组) 开源的 Torch 神经网络机器翻译系统。</p>
<p><img src="https://i.loli.net/2018/04/21/5adb2d5ed8bcc.jpg" alt=""></p>
<h1 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h1><ol>
<li><p>简单的通用接口，只需要源/目标文件。</p>
</li>
<li><p>快速高性能GPU训练和内存优化。</p>
</li>
<li><p>提高翻译性能的最新的研究成果。</p>
</li>
<li><p>可配对多种语言的预训练模型（即将推出）。</p>
</li>
<li><p>允许其他序列生成任务的拓展，如汇总和图文生成</p>
</li>
</ol>
<h1 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h1><p>OpenNMT 包含三个命令</p>
<p>1) 数据预处理</p>
<p>th preprocess.lua -train_src data/src-train.txt -train_tgt data/tgt-train.txt -valid_src data/src-val.txt -valid_tgt data/tgt-val.txt -save_data data/demo</p>
<p>2) 模型训练</p>
<p>th train.lua -data data/demo-train.t7 -save_model model</p>
<p>3) 语句翻译</p>
<p>th translate.lua -model model_final.t7 -src data/src-test.txt -output pred.txt</p>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ol>
<li>Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to align and translate[J]. arXiv preprint arXiv:1409.0473, 2014.</li>
<li>Wu Y, Schuster M, Chen Z, et al. Google’s neural machine translation system: Bridging the gap between human and machine translation[J]. arXiv preprint arXiv:1609.08144, 2016.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/刘晓_Keras/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/刘晓_Keras/" itemprop="url">Keras</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="https://keras.io/#installation" target="_blank" rel="noopener">https://keras.io/#installation</a>  </p>
<h2 id="Keras-简介"><a href="#Keras-简介" class="headerlink" title="Keras 简介"></a>Keras 简介</h2><p>Keras 最初是作为 ONEIROS 项目（开放式神经电子智能机器人操作系统）研究工作的一部分而开发的。Keras是一个高层神经网络API，纯Python编写而成并基Tensorflow、Theano以及CNTK后端。Keras 为支持快速实验而生，能够把你的idea迅速转换为结果，如果你有如下需求，请选择Keras：  </p>
<ul>
<li>简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性）  </li>
<li>支持CNN和RNN，或二者的结合  </li>
<li>无缝CPU和GPU切换  </li>
</ul>
<p>Keras适用的Python版本是：Python 2.7-3.6      </p>
<p><a href="https://keras.io/" target="_blank" rel="noopener">Keras官方英文文档</a>  </p>
<p><a href="https://keras.io/zh/" target="_blank" rel="noopener">Keras官方中文文档</a>  </p>
<p><a href="https://github.com/keras-team" target="_blank" rel="noopener">Keras GitHub</a></p>
<h2 id="Keras-安装"><a href="#Keras-安装" class="headerlink" title="Keras 安装"></a>Keras 安装</h2><p>在安装 Keras 之前，请安装以下后端引擎之一：TensorFlow，Theano，或者 CNTK。官方推荐 <strong>TensorFlow 后端</strong> 。  </p>
<ul>
<li><a href="https://www.tensorflow.org/install/" target="_blank" rel="noopener">TensorFlow 安装指引 </a> </li>
<li><a href="http://deeplearning.net/software/theano/install.html#install" target="_blank" rel="noopener">Theano 安装指引 </a> </li>
<li><a href="https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine" target="_blank" rel="noopener">CNTK 安装指引</a></li>
</ul>
<p>还可以考虑安装一下可选依赖：</p>
<ul>
<li>cuDNN (如果你计划在 GPU 上运行 Keras，建议安装)。  </li>
<li>HDF5 和 h5py (如果你需要将 Keras 模型保存到磁盘，则需要这些)。  </li>
<li>graphviz 和 pydot (被可视化工具用来绘制模型图)。  </li>
</ul>
<p><strong>安装 Keras</strong>  ，有两种方法：  </p>
<ol>
<li><p>使用 PyPI 安装 Keras (推荐)  </p>
<pre><code>sudo pip install keras  
pip install keras   # virtualenv 虚拟环境下
</code></pre></li>
</ol>
<ol>
<li><p>使用 Github 源码安装 Keras：<br>使用 git 来克隆 Keras：</p>
<pre><code>git clone https://github.com/keras-team/keras.git    
</code></pre></li>
</ol>
<p>然后，cd 到 Keras 目录并且运行安装命令：  </p>
<pre><code>cd keras  
sudo python setup.py install  
</code></pre><h2 id="Keras-快速使用"><a href="#Keras-快速使用" class="headerlink" title="Keras 快速使用"></a>Keras 快速使用</h2><p>Keras 的核心数据结构是 model，一种组织网络层的方式。最简单的模型是 <strong>Sequential</strong> 顺序模型，它是由多个网络层线性堆叠的栈。对于更复杂的结构，应该使用 Keras 函数式 API，它允许构建任意的神经网络图。<br><strong>Sequential </strong>顺序模型如下所示：  </p>
<pre><code>from keras.models import Sequential  
model = Sequential()  
</code></pre><p>可以简单地使用 .add() 来堆叠模型：  </p>
<pre><code>from keras.layers import Dense
model.add(Dense(units=64, activation=&apos;relu&apos;, input_dim=100))
model.add(Dense(units=10, activation=&apos;softmax&apos;))  
</code></pre><p>在完成了模型的构建后, 可以使用 .compile() 来配置学习过程：  </p>
<pre><code>model.compile(loss=&apos;categorical_crossentropy&apos;, optimizer=&apos;sgd&apos;, metrics=[&apos;accuracy&apos;])  
</code></pre><p>如果需要，你还可以进一步地配置优化器。Keras 的一个核心原则是使事情变得相当简单，同时又允许用户在需要的时候能够进行完全的控制（终极的控制是源代码的易扩展性）。</p>
<pre><code>model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))    
</code></pre><p>现在，你可以批量地在训练数据上进行迭代了：  </p>
<pre><code># x_train 和 y_train 是 Numpy 数组 -- 就像在 Scikit-Learn API 中一样。
model.fit(x_train, y_train, epochs=5, batch_size=32)
</code></pre><p>或者，你可以手动地将批次的数据提供给模型：</p>
<pre><code>model.train_on_batch(x_batch, y_batch)    
</code></pre><p>只需一行代码就能评估模型性能：</p>
<pre><code>loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)    
</code></pre><p>或者对新的数据生成预测：</p>
<pre><code>classes = model.predict(x_test, batch_size=128)    
</code></pre><p>构建一个问答系统，一个图像分类模型，一个神经图灵机，或者其他的任何模型，就是这么的快。</p>
<h2 id="相关例子"><a href="#相关例子" class="headerlink" title="相关例子"></a>相关例子</h2><p>在Keras代码包的examples文件夹中，你将找到使用真实数据的示例模型：</p>
<ul>
<li>CIFAR10 小图片分类：使用CNN和实时数据提升  </li>
<li>IMDB 电影评论观点分类：使用LSTM处理成序列的词语  </li>
<li>Reuters（路透社）新闻主题分类：使用多层感知器（MLP）  </li>
<li>MNIST手写数字识别：使用多层感知器和CNN  </li>
<li>字符级文本生成：使用LSTM </li>
<li>基于多层感知器的softmax多分类：</li>
</ul>
<h2 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h2><p>涉及使用Keras实现的算法及论文后续补上</p>
<p><strong>小知识：</strong> Keras (κέρας) 在希腊语中意为 号角 。它来自古希腊和拉丁文学中的一个文学形象，首先出现于 《奥德赛》 中， 梦神 (Oneiroi, singular Oneiros) 从这两类人中分离出来：那些用虚幻的景象欺骗人类，通过象牙之门抵达地球之人，以及那些宣告未来即将到来，通过号角之门抵达之人。 它类似于文字寓意，κέρας (号角) / κραίνω (履行)，以及 ἐλέφας (象牙) / ἐλεφαίρομαι (欺骗)。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CNLR</p>
              <p class="site-description motion-element" itemprop="description">语料库、数据集及工具资源和教程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">82</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CNLR</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
