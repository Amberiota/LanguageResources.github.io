<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="语料库、数据集及工具资源和教程">
<meta property="og:type" content="website">
<meta property="og:title" content="世界语言资源平台">
<meta property="og:url" content="http://yoursite.com/page/7/index.html">
<meta property="og:site_name" content="世界语言资源平台">
<meta property="og:description" content="语料库、数据集及工具资源和教程">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="世界语言资源平台">
<meta name="twitter:description" content="语料库、数据集及工具资源和教程">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/7/"/>





  <title>世界语言资源平台</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">世界语言资源平台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/李华勇_gensim/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/李华勇_gensim/" itemprop="url">Gensim</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="https://radimrehurek.com/gensim/" target="_blank" rel="noopener">https://radimrehurek.com/gensim/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Gensim是一个免费的Python库，它可以用来从文档中自动提取语义主题，并且尽可能地做到轻松（对人）高效（对电脑）。</p>
<p>Gensim致力于处理原始的、非结构化的数字文本（普通文本）。Gensim中用到的算法，如潜在语义分析（Latent Semantic Analysis，LSA）、隐含狄利克雷分配（Latent Dirichlet Allocation，LDA）或随机预测（Random Projections）等，是通过检查单词在训练语料库的同一文档中的统计共现模式来发现文档的语义结构。这些算法都是无监督算法，也就是无需人工输入——你仅需一个普通文本的语料库即可。</p>
<p><img src="https://i.loli.net/2018/04/21/5adb301720070.jpg" alt=""></p>
<h1 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h1><p>内存占用低——任何时候都不会将整个语料库全部读入内存中，可以处理大规模、网络规模的语料库。</p>
<p>有效实现了几种流行的向量空间算法，包括Tf-idf、分布式增量潜在语义分析、分布式增量隐含狄利克雷分配或随机预测；增加新的模型也十分方便（没骗你！）。</p>
<p>预置了几种流行的数据格式的I/O封装器和转换器。</p>
<p>利用文档的语义代表计算其相似性。</p>
<p>整个gensim包围绕语料库（Corpus）、向量（Vector）、模型（Model）三个概念展开。</p>
<h1 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade gensim</span><br></pre></td></tr></table></figure>
<h2 id="tfidf表示"><a href="#tfidf表示" class="headerlink" title="tfidf表示"></a>tfidf表示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">34</span>]: tfidf = models.TfidfModel(corpus) <span class="comment"># step 1 -- initialize a model</span></span><br><span class="line">In [<span class="number">37</span>]: doc_bow = [(<span class="number">0</span>, <span class="number">1</span>), (<span class="number">1</span>, <span class="number">1</span>)]</span><br><span class="line">In [<span class="number">38</span>]: print(tfidf[doc_bow])</span><br><span class="line">[(<span class="number">0</span>, <span class="number">0.7071067811865476</span>), (<span class="number">1</span>, <span class="number">0.7071067811865476</span>)]</span><br><span class="line">In [<span class="number">39</span>]: corpus_tfidf = tfidf[corpus]</span><br><span class="line">In [<span class="number">40</span>]: pprint(corpus_tfidf)</span><br><span class="line">&lt;gensim.interfaces.TransformedCorpus object at <span class="number">0x0129FFD0</span>&gt;</span><br><span class="line">In [<span class="number">41</span>]: <span class="keyword">for</span> doc <span class="keyword">in</span> corpus_tfidf:</span><br><span class="line">    ...:     pprint(doc)</span><br><span class="line">    ...:</span><br></pre></td></tr></table></figure>
<h2 id="lsi表示"><a href="#lsi表示" class="headerlink" title="lsi表示"></a>lsi表示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">42</span>]: lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=<span class="number">2</span>) <span class="comment"># initialize an LSI transformation</span></span><br><span class="line">In [<span class="number">43</span>]: corpus_lsi = lsi[corpus_tfidf] <span class="comment">#  create a double wrapper over the original corpus: bow-&gt;tfidf-&gt;fold-in-lsi</span></span><br><span class="line">In [<span class="number">47</span>]: lsi.print_topics(<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">47</span>]: [(<span class="number">0</span>, <span class="string">'-0.703*"trees" + -0.538*"graph" + -0.402*"minors" + -0.187*"survey" + -0.061*"system" + -0.060*"time" + -0.060*"response" + -0.058*"user" + -0.049*"computer" + -0.035*"interface"'</span>), (<span class="number">1</span>, <span class="string">'-0.460*"system" + -0.373*"user" + -0.332*"eps" + -0.328*"interface" + -0.320*"time" + -0.320*"response" + -0.293*"computer" + -0.280*"human" + -0.171*"survey" + 0.161*"trees"'</span>)]</span><br><span class="line">In [<span class="number">48</span>]: <span class="keyword">for</span> doc <span class="keyword">in</span> corpus_lsi:</span><br><span class="line">    ...:     print(doc)</span><br><span class="line">    ...:</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.066007833960906648</span>), (<span class="number">1</span>, <span class="number">-0.5200703306361848</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.19667592859142974</span>), (<span class="number">1</span>, <span class="number">-0.76095631677000308</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.089926399724468281</span>), (<span class="number">1</span>, <span class="number">-0.72418606267525087</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.075858476521785109</span>), (<span class="number">1</span>, <span class="number">-0.632055158600343</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.10150299184980502</span>), (<span class="number">1</span>, <span class="number">-0.57373084830029464</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.70321089393783032</span>), (<span class="number">1</span>, <span class="number">0.16115180214026176</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.87747876731198216</span>), (<span class="number">1</span>, <span class="number">0.16758906864659895</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.90986246868185694</span>), (<span class="number">1</span>, <span class="number">0.14086553628719531</span>)]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">-0.61658253505692839</span>), (<span class="number">1</span>, <span class="number">-0.053929075663890019</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="相似度查询"><a href="#相似度查询" class="headerlink" title="相似度查询"></a>相似度查询</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">49</span>]: <span class="keyword">from</span> gensim <span class="keyword">import</span> similarities</span><br><span class="line">In [<span class="number">50</span>]: index = similarities.MatrixSimilarity(lsi[corpus]) <span class="comment"># transform corpus to LSI space and index it</span></span><br></pre></td></tr></table></figure>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ol>
<li>Khosrovian K, Pfahl D, Garousi V. GENSIM 2.0: a customizable process simulation model for software process evaluation[C]//International Conference on Software Process. Springer, Berlin, Heidelberg, 2008: 294-306.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/李华勇_中国哲学电子书计划/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/李华勇_中国哲学电子书计划/" itemprop="url">中国哲学书电子化计划</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="https://ctext.org" target="_blank" rel="noopener">https://ctext.org</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>本网站的目的是提供尽可能精确且便利使用的中国古代原典文献（尤其先秦两汉文献），把这些资料以 恰当结构、可搜索模式来展现，并且广泛使用现代技术作为工具使这些文献更容易学习和研究，因而使更多人有机会接触这些原典文献。</p>
<p>本站提供不同的版本：中文版和英文版，简体字和繁体字。您可以使用任何一页左上边的连接随时转换。</p>
<h1 id="主要功能与内容"><a href="#主要功能与内容" class="headerlink" title="主要功能与内容"></a>主要功能与内容</h1><h2 id="原典资料库"><a href="#原典资料库" class="headerlink" title="原典资料库"></a>原典资料库</h2><p>本网站最主要的部分为古籍资料库，此资料库包含各种从哲学、历史、语言学等角度被视为重要的文献，写作年代以先秦两汉爲主。 本网站的所有资料都存在一个专门设计的数据库，以便读浏览和搜索的方便。 此外，部分原典有附英文或现代汉语翻译，这些翻译是一段一段对照原典而附上的，因此很容易从译文找出对应的原典，或从原典找出对应的译文。</p>
<p>在原典段落的左手边，系统将会显示下列的部份图标；点击这些图标，可以便利享用本站的许多独特功能：</p>
<p><img src="https://i.loli.net/2018/04/19/5ad8454700586.jpg" alt=""></p>
<h2 id="内部字典"><a href="#内部字典" class="headerlink" title="内部字典"></a>内部字典</h2><p>内部汉字字典合并三个来源的信息：统一码联盟（Unicode Consortium）的“Unihan”数据库、上述的原典资料库、以及本网站新开发的CTP字典。 其中Unihan数据库提供有关汉字的基本信息，包括部首、笔画数、异体字、标准字典中的出处、以及英文翻译（但此英文翻译以现代汉语用法爲主）。 原典资料库则给每一个字提供原典中的具体出处。最后，CTP字典试图对汉字的语义和实际运用提供一个尽可能完整的分析。 虽然从汉字的数量上看大多数汉字是单义词，但少数很常用的字却有许多不同的用法，这些不同用法通常有不同语义或读法。 CTP字典把这些不同意义或不同读法的用法分开处理，并且通过原典数据库给每一个不同用法分别提供原典出处。 这一功能是透过一种“语义链接”的手段而实现的，即建立从某篇某段某句中的某字到CTP字典中的相关用法的链接。 建立这些链接需要对文本的理解，因而是一个手动的且耗时的程序；因此CTP字典的范围目前很有限（但日益增加）。 您可以参考CTP字典中对 与、说、故的解释。</p>
<h2 id="词语分析表"><a href="#词语分析表" class="headerlink" title="词语分析表"></a>词语分析表</h2><p>通过内部字典和上述的语义链接，本站还可以对原典数据库中的任何段落提供词语分析表。 词语分析表为段落中的每一个字显示字典中的英文翻译及其它信息，并且对于有语意链接的词语显示词语在此脉络中的意义。 例如，在《论语》的第一段中，系统会显示“乐”的正确读法是“le”而不是“yue”，且该句中“说”的用法跟“悦”的读法、意义相同（请参考《学而》第一段词语分析表）。</p>
<p>建立语意链接的计划正在进行，因此目前也有缺少链接的字。当一个字尚未有语意链接时，系统将会显示此字的基本资料，并提供至完整字典项目的连接。</p>
<h2 id="相似段落资料"><a href="#相似段落资料" class="headerlink" title="相似段落资料"></a>相似段落资料</h2><p>由于种种原因，许多早期文献含有与其它文献相似的片段或较长的段落，足以证明两个著作并非完全独立而形成的。此现象有时表明原作者有意识的抄写了当时已形成的其它著作；有时表明谋一个俗语当时已流行；也有时是由其它的原因造成的。在许多情况下，虽然这些相似的片段具有明显的相似性，并足以保证此相似性并非巧合，与此同时这些片段有时候具有重要且有趣的不同之处。</p>
<p>本站的相似段落功能把这些相似或相同的段落连接起来，且显示相似部份以便对照。任何具有相似段落讯息的段落将会显示图标；点击此图标将会显示此段落、所有相似段落及其连接。</p>
<p>相似段落讯息可以使用下述的“高级搜索”功能来搜索。</p>
<h2 id="原典影印本"><a href="#原典影印本" class="headerlink" title="原典影印本"></a>原典影印本</h2><p>许多早期文献具有不同的现存版本。这些版本的不同有些是因不同的文献历史背景而产生的，也有一些产生于纠正抄写错误，也有部份来自假借字现象而造成的，而另外还有更多造成原因。这些造成原因加起来使得我们很难看出今天的电子版或印刷版的原典是否“正确”；甚至使得我们很难以下定义说什么叫做“正确”的版本，毕竟未必真的曾经存在过所谓“最原始的”由一个作者所写作的版本。</p>
<p>因此，本站为越来越多的原典提供原典扫瞄版，且为原典每一段落提供至扫瞄版的连接。原典数据库中的每一个字应对应于扫瞄版的一个字，而系统能够给使用者显示原典及原典扫瞄版的对照本，以便使用者确定原典与扫瞄本无误。另，因为扫瞄本有可能经过后世的研究而被视为本身有误，因此系统将会注明所有被修改的字词，同时保留原本错误的字以便与扫瞄版对照。</p>
<p>每个具有影印本的原典段落会显示图标；点击此图标将会打开电子版与扫瞄本的对照显示，并突显对应于此段落的部份。</p>
<h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><h2 id="全文搜索"><a href="#全文搜索" class="headerlink" title="全文搜索"></a>全文搜索</h2><p>要进行全文搜索时，先确认浏览器中打开的网页属于网站“原典全文”的部分，然后在左下角的“搜索”框内选择搜索范围并输入所要搜索的字词。（如：学而时习之）且点击“搜索”。全文资料库支持使用多数的搜索条件；在不同搜索条件之间输入半角空格分割（如：学而时 不亦君子），系统将会列出所有同时符合所有搜索条件的段落。若要搜索含有空格的英文词组，在词组外加上英文引号（如：”Mozi said”）。点击“高级搜索”可以使用更有弹性的搜索方式。</p>
<h2 id="辞典搜索"><a href="#辞典搜索" class="headerlink" title="辞典搜索"></a>辞典搜索</h2><p>要进行辞典搜索时，先确认浏览器中打开的网页属于网站“辞典”的部分，然后在左下角的“搜索”框内输入所要查询的字词。（如：学）且点击“搜索”。当输入的文字不作为辞典中的项目时，系统将会以表格的方式为被输入的每一个汉字列出辞典中的资料。</p>
<h2 id="研究资料搜索"><a href="#研究资料搜索" class="headerlink" title="研究资料搜索"></a>研究资料搜索</h2><p>要进行研究资料搜索时，先确认浏览器中打开的网页属于网站“研究资料”的部分，然后在左下角的“搜索”框内输入所要查询的字词。（如：Ethics）且点击“搜索”。点击“高级搜索”可以使用更有弹性的搜索方式。</p>
<h2 id="一般性图标"><a href="#一般性图标" class="headerlink" title="一般性图标"></a>一般性图标</h2><p><img src="https://i.loli.net/2018/04/19/5ad8464eac912.jpg" alt=""></p>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ol>
<li>吴智雄. 由 “数位人文研究法” 探《 皇明经世文编》 所载明初的海洋朝贡议论[J]. 南海学刊, 2016, 2(1): 18-27.</li>
<li>Sturgeon D. 中國哲學書電子化計劃[J]. 網址: <a href="http://ctext" target="_blank" rel="noopener">http://ctext</a>. org, 2011.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/李华勇_CN-DBpedia/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/李华勇_CN-DBpedia/" itemprop="url">CN-DBpedia</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="http://kw.fudan.edu.cn/cndbpedia/intro/" target="_blank" rel="noopener">http://kw.fudan.edu.cn/cndbpedia/intro/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>CN-DBpedia是由复旦大学知识工场实验室研发并维护的大规模通用领域结构化百科，其前身是复旦GDM中文知识图谱，是国内最早推出的也是目前最大规模的开放百科中文知识图谱，涵盖数千万实体和数亿级的关系，相关知识服务API累计调用量已达6亿次。</p>
<p>CN-DBpedia以通用百科知识沉淀为主线，以垂直纵深领域图谱积累为支线，致力于为机器语义理解提供了丰富的背景知识，为实现机器语言认知提供必要支撑。</p>
<p>CN-DBpedia已经从百科领域延伸至法律、工商、金融、文娱、科技、军事、教育、医疗等十多个垂直领域，为各类行业智能化应用提供支撑性知识服务，目前已有近百家单位在使用。</p>
<p>CN-DBpedia具有体量巨大、质量精良、实时更新、丰富的API服务等特色。CN-DBpedia已经成为业界开放中文知识图谱的首选。基于CN-DBpedia的知识图谱构建与应用能力已经输出并应用在华为、小I机器人、中国电信、中国移动、同花顺等业界领军企业的产品与解决方案中。</p>
<p>CN-DBpedia提供全套API，并且免费开放使用。</p>
<h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><h2 id="浏览器检索"><a href="#浏览器检索" class="headerlink" title="浏览器检索"></a>浏览器检索</h2><p>直接在网页上search即可。<br>比如输入 北京语言大学 的结果如下：<br><img src="https://i.loli.net/2018/04/19/5ad84af89927d.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84b3f2c647.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84b646724c.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84b792f19f.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84b8e94b19.jpg" alt=""></p>
<p><img src="https://i.loli.net/2018/04/19/5ad84c086f34d.jpg" alt=""></p>
<h2 id="API接口"><a href="#API接口" class="headerlink" title="API接口"></a>API接口</h2><h3 id="api-cndbpedia-ment2ent："><a href="#api-cndbpedia-ment2ent：" class="headerlink" title="api/cndbpedia/ment2ent："></a>api/cndbpedia/ment2ent：</h3><p>输入实体指称项名称(mention name)，返回对应实体(entity)的列表，json格式。</p>
<p>请求参数<br>q：实体指称项名称(mention name)；必填项</p>
<p>apikey：开发者的访问密钥；可选项（注：不加访问密钥会存在访问限制）</p>
<p>返回字段<br>status：本次API访问状态，如果成功返回“ok”，如果失败返回“fail”</p>
<p>ret： 返回entity name list</p>
<p>URL<br><a href="http://shuyantech.com/api/cndbpedia/ment2ent?q=*" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/ment2ent?q=*</a>*</p>
<p><a href="http://shuyantech.com/api/cndbpedia/ment2ent?q=**&amp;apikey=*" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/ment2ent?q=**&amp;apikey=*</a>*</p>
<p>Example<br><a href="http://shuyantech.com/api/cndbpedia/ment2ent?q=红楼梦" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/ment2ent?q=红楼梦</a></p>
<h3 id="api-cndbpedia-avpair："><a href="#api-cndbpedia-avpair：" class="headerlink" title="api/cndbpedia/avpair："></a>api/cndbpedia/avpair：</h3><p>输入实体名，返回实体全部的三元组知识</p>
<p>请求参数<br>q：实体名称(entity name)；必填项</p>
<p>apikey：开发者的访问密钥；可选项（注：不加访问密钥会存在访问限制）</p>
<p>返回字段<br>status：本次API访问状态，如果成功返回“ok”，如果失败返回“fail”</p>
<p>ret： 返回attribute-value pair list, 每个pair也是一个list （[attribute, value]）</p>
<p>URL<br><a href="http://shuyantech.com/api/cndbpedia/avpair?q=*" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/avpair?q=*</a>*</p>
<p><a href="http://shuyantech.com/api/cndbpedia/avpair?q=**&amp;apikey=*" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/avpair?q=**&amp;apikey=*</a>*</p>
<p>Example<br><a href="http://shuyantech.com/api/cndbpedia/avpair?q=复旦大学" target="_blank" rel="noopener">http://shuyantech.com/api/cndbpedia/avpair?q=复旦大学</a></p>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ol>
<li>Bo Xu, Yong Xu, Jiaqing Liang, Chenhao Xie, Bin Liang, Wanyun Cui, and Yanghua Xiao. CN-DBpedia: A Never-Ending Chinese Knowledge Extraction System. In International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, pp. 428-438. Springer, Cham, 2017.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/19/刘晓_百度自然语言处理API服务/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/刘晓_百度自然语言处理API服务/" itemprop="url">百度自然语言处理API服务</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T17:37:46+05:00">
                2018-04-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓<br>地址：<a href="http://ai.baidu.com/tech/nlp" target="_blank" rel="noopener">http://ai.baidu.com/tech/nlp</a> </p>
<h2 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h2><p>百度自然语言处理：<a href="http://ai.baidu.com/tech/nlp" target="_blank" rel="noopener">http://ai.baidu.com/tech/nlp</a><br>SDK下载地址：<a href="http://ai.baidu.com/sdk#nlp" target="_blank" rel="noopener">http://ai.baidu.com/sdk#nlp</a>  </p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Python SDK文档，主要针对Python开发者描述百度自然语言处理接口服务的相关技术内容。 </p>
<p><strong>接口能力：</strong>  </p>
<ul>
<li>接口名称：     接口能力简要描述  </li>
<li>词法分析：        分词、词性标注、专名识别  </li>
<li>依存句法分析：    自动分析文本中的依存句法结构信息  </li>
<li>词向量表示：    查询词汇的词向量，实现文本的可计算  </li>
<li>DNN语言模型：    判断一句话是否符合语言表达习惯，输出分词结果并给出每个词在句子中的概率值  </li>
<li>词义相似度：    计算两个给定词语的语义相似度  </li>
<li>短文本相似度：    判断两个文本的相似度得分  </li>
<li>评论观点抽取：    提取一个句子观点评论的情感属性  </li>
<li>情感倾向分析：    对包含主观观点信息的文本进行情感极性类别（积极、消极、中性）的判断，并给出相应的置信度  </li>
<li>中文分词：     切分出连续文本中的基本词汇序列（已合并到词法分析接口）  </li>
<li>词性标注：     为自然语言文本中的每个词汇赋予词性（已合并到词法分析接口）  </li>
</ul>
<p>版本更新：<br>2018.01.25    2.2.0    新增文本标签API<br>2017.12.22    2.0.0    SDK代码重构<br>2017.5.11    1.0.0    自然语言处理服务上线</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><strong>安装自然语言处理 Python SDK</strong>  </p>
<p>自然语言处理 Python SDK目录结构：</p>
<p>|── README.md  </p>
<p>├── aip                   //SDK目录  </p>
<p>│   ├── <strong>init</strong>.py          //导出类  </p>
<p>│   ├── base.py           //aip基类  </p>
<p>│   ├── http.py           //http请求  </p>
<p>│   └── nlp.py //自然语言处理  </p>
<p>└── setup.py              //setuptools安装  </p>
<p><strong>支持Python版本：2.7.+ ,3.+</strong></p>
<p><strong>安装使用Python SDK有如下方式：</strong></p>
<p>如果已安装pip：  </p>
<pre><code>pip install baidu-aip  
</code></pre><p>如果已安装setuptools:  </p>
<pre><code>python setup.py install  
</code></pre><h2 id="使用教程"><a href="#使用教程" class="headerlink" title="使用教程"></a>使用教程</h2><p><strong>新建AipNlp</strong>    </p>
<p>AipNlp是自然语言处理的Python SDK客户端，为使用自然语言处理的开发人员提供了一系列的交互方法。  </p>
<p>参考如下代码新建一个AipNlp：</p>
<pre><code>from aip import AipNlp

&quot;&quot;&quot; 你的 APPID AK SK &quot;&quot;&quot;
APP_ID = &apos;你的 App ID&apos;
API_KEY = &apos;你的 Api Key&apos;
SECRET_KEY = &apos;你的 Secret Key&apos;

client = AipNlp(APP_ID, API_KEY, SECRET_KEY)  
</code></pre><p>在上面代码中，常量APP_ID在百度云控制台中创建，常量API_KEY与SECRET_KEY是在创建完毕应用后，系统分配给用户的，均为字符串，用于标识用户，为访问做签名验证，可在AI服务控制台中的应用列表中查看。</p>
<p>注意：如您以前是百度云的老用户，其中API_KEY对应百度云的“Access Key ID”，SECRET_KEY对应百度云的“Access Key Secret”。</p>
<p><strong>配置AipNlp</strong>  </p>
<p>如果用户需要配置AipNlp的网络请求参数(一般不需要配置)，可以在构造AipNlp之后调用接口设置参数，目前只支持以下参数：  </p>
<table>
<thead>
<tr>
<th>接口</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>setConnectionTimeoutInMillis</td>
<td>建立连接的超时时间（单位：毫秒  </td>
</tr>
<tr>
<td>setSocketTimeoutInMillis</td>
<td>通过打开的连接传输数据的超时时间（单位：毫秒）</td>
</tr>
</tbody>
</table>
<h2 id="接口说明"><a href="#接口说明" class="headerlink" title="接口说明"></a>接口说明</h2><p><strong>词法分析</strong><br>词法分析接口向用户提供分词、词性标注、专名识别三大功能；能够识别出文本串中的基本词汇（分词），对这些词汇进行重组、标注组合后词汇的词性，并进一步识别出命名实体。    </p>
<pre><code>text = &quot;百度是一家高科技公司&quot;

&quot;&quot;&quot; 调用词法分析 &quot;&quot;&quot;
client.lexer(text);  
</code></pre><ul>
<li>参数 –&gt; text : 必选，string类型，是一个待分析文本（目前仅支持GBK编码），长度不超过65536字节。   </li>
</ul>
<ul>
<li>返回参数分析：  </li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>必需</th>
<th>详细说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>string</td>
<td>是</td>
<td>原始单条请求文本</td>
</tr>
<tr>
<td>items</td>
<td>array(object)</td>
<td>是</td>
<td>词汇数组，每个元素对应结果中的一个词</td>
</tr>
<tr>
<td>+item</td>
<td>string</td>
<td>是</td>
<td>词汇的字符串</td>
</tr>
<tr>
<td>+ne</td>
<td>string</td>
<td>是</td>
<td>命名实体类型，命名实体识别算法使用。词性标注算法中，此项为空串</td>
</tr>
<tr>
<td>+pos</td>
<td>string</td>
<td>是</td>
<td>词性，词性标注算法使用。命名实体识别算法中，此项为空串</td>
</tr>
<tr>
<td>+byte_offset</td>
<td>int</td>
<td>是</td>
<td>在text中的字节级offset（使用GBK编码）</td>
</tr>
<tr>
<td>+byte_length</td>
<td>int</td>
<td>是</td>
<td>字节级length（使用GBK编码）</td>
</tr>
<tr>
<td>+uri</td>
<td>string</td>
<td>否</td>
<td>链指到知识库的URI，只对命名实体有效。对于非命名实体和链接不到知识库的命名实体，此项为空串</td>
</tr>
<tr>
<td>+formal</td>
<td>string</td>
<td>否</td>
<td>词汇的标准化表达，主要针对时间、数字单位，没有归一化表达的，此项为空串</td>
</tr>
<tr>
<td>+basic_words</td>
<td>array(string)</td>
<td>是</td>
<td>基本词成分</td>
</tr>
<tr>
<td>+loc_details</td>
<td>array(object)</td>
<td>否</td>
<td>地址成分，非必需，仅对地址型命名实体有效，没有地址成分的，此项为空数组。</td>
</tr>
<tr>
<td>++type</td>
<td>string</td>
<td>是</td>
<td>成分类型，如省、市、区、县</td>
</tr>
<tr>
<td>++byte_offset</td>
<td>int</td>
<td>是</td>
<td>在item中的字节级offset（使用GBK编码）</td>
</tr>
<tr>
<td>++byte_length</td>
<td>nt</td>
<td>是</td>
<td>字节级length（使用GBK编码）  </td>
</tr>
</tbody>
</table>
<ul>
<li><p>词法分析返回示例：    </p>
<pre><code> {
     &quot;status&quot;:0,
     &quot;version&quot;:&quot;ver_1_0_1&quot;,
     &quot;results&quot;:[
     {
       &quot;retcode&quot;:0,
       &quot;text&quot;:&quot;百度是一家高科技公司&quot;,
      &quot;items&quot;:[
     {
        &quot;byte_length&quot;:4,
        &quot;byte_offset&quot;:0,
        &quot;formal&quot;:&quot;&quot;,
        &quot;item&quot;:&quot;百度&quot;,
        &quot;ne&quot;:&quot;ORG&quot;,
        &quot;pos&quot;:&quot;&quot;,
        &quot;uri&quot;:&quot;&quot;,
        &quot;loc_details&quot;:[ ],
        &quot;basic_words&quot;:[&quot;百度&quot;]
      },
      {
        &quot;byte_length&quot;:2,
        &quot;byte_offset&quot;:4,
        &quot;formal&quot;:&quot;&quot;,
        &quot;item&quot;:&quot;是&quot;,
        &quot;ne&quot;:&quot;&quot;,
        &quot;pos&quot;:&quot;v&quot;,
        &quot;uri&quot;:&quot;&quot;,
        &quot;loc_details&quot;:[ ],
        &quot;basic_words&quot;:[&quot;是&quot;]
      },
      {
        &quot;byte_length&quot;:4,
        &quot;byte_offset&quot;:6,
        &quot;formal&quot;:&quot;&quot;,
        &quot;item&quot;:&quot;一家&quot;,
        &quot;ne&quot;:&quot;&quot;,
        &quot;pos&quot;:&quot;m&quot;,
        &quot;uri&quot;:&quot;&quot;,
        &quot;loc_details&quot;:[ ],
        &quot;basic_words&quot;:[&quot;一&quot;,&quot;家&quot;]
       },
       {
        &quot;byte_length&quot;:6,
        &quot;byte_offset&quot;:10,
        &quot;formal&quot;:&quot;&quot;,
        &quot;item&quot;:&quot;高科技&quot;,
        &quot;ne&quot;:&quot;&quot;,
        &quot;pos&quot;:&quot;n&quot;,
        &quot;uri&quot;:&quot;&quot;,
        &quot;loc_details&quot;:[ ],
        &quot;basic_words&quot;:[&quot;高&quot;,&quot;科技&quot;]
       },
       {
       &quot;byte_length&quot;:4,
       &quot;byte_offset&quot;:16,
       &quot;formal&quot;:&quot;&quot;,
       &quot;item&quot;:&quot;公司&quot;,
       &quot;ne&quot;:&quot;&quot;,
       &quot;pos&quot;:&quot;n&quot;,
       &quot;uri&quot;:&quot;&quot;,
       &quot;loc_details&quot;:[ ],
       &quot;basic_words&quot;:[&quot;公司&quot;]
       }
      ]
   }
  ]
}
</code></pre></li>
</ul>
<ul>
<li>词性缩略说明：  </li>
</ul>
<table>
<thead>
<tr>
<th>词性</th>
<th>含义</th>
<th>词性</th>
<th>含义</th>
<th>词性</th>
<th>含义</th>
<th>词性</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>n</td>
<td>普通名词</td>
<td>f</td>
<td>方位名词</td>
<td>s</td>
<td>处所名词</td>
<td>t</td>
<td>时间名词</td>
</tr>
<tr>
<td>nr</td>
<td>人名</td>
<td>ns</td>
<td>地名</td>
<td>nt</td>
<td>机构团体名</td>
<td>nw</td>
<td>作品名</td>
</tr>
<tr>
<td>nz</td>
<td>其他专名</td>
<td>v</td>
<td>普通动词</td>
<td>vd</td>
<td>动副词</td>
<td>vn</td>
<td>名动词</td>
</tr>
<tr>
<td>a</td>
<td>形容词</td>
<td>ad</td>
<td>副形词</td>
<td>an</td>
<td>名形词</td>
<td>d</td>
<td>副词</td>
</tr>
<tr>
<td>m</td>
<td>数量词</td>
<td>q</td>
<td>量词</td>
<td>r</td>
<td>代词</td>
<td>p</td>
<td>介词</td>
</tr>
<tr>
<td>c</td>
<td>连词</td>
<td>u</td>
<td>助词</td>
<td>xc</td>
<td>其他虚词</td>
<td>w</td>
<td>标点符号  </td>
</tr>
</tbody>
</table>
<ul>
<li>专名识别缩略词含义:</li>
</ul>
<table>
<thead>
<tr>
<th>缩略词</th>
<th>含义</th>
<th>缩略词</th>
<th>含义</th>
<th>缩略词</th>
<th>含义</th>
<th>缩略词</th>
<th>含义  </th>
</tr>
</thead>
<tbody>
<tr>
<td>PER</td>
<td>人名</td>
<td>LOC</td>
<td>地名</td>
<td>ORG</td>
<td>机构名</td>
<td>TIME</td>
<td>时间  </td>
</tr>
</tbody>
</table>
<p><strong>词法分析（定制版）</strong><br>词法分析接口向用户提供分词、词性标注、专名识别三大功能；能够识别出文本串中的基本词汇（分词），对这些词汇进行重组、标注组合后词汇的词性，并进一步识别出命名实体。定制版接口的使用教程请看链接：<a href="http://ai.baidu.com/forum/topic/show/496975" target="_blank" rel="noopener">http://ai.baidu.com/forum/topic/show/496975</a></p>
<pre><code>text = &quot;百度是一家高科技公司&quot;

&quot;&quot;&quot; 调用词法分析（定制版） &quot;&quot;&quot;
client.lexerCustom(text);
</code></pre><ul>
<li>词法分析（定制版） 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>待分析文本（目前仅支持GBK编码），长度不超过65536字节</td>
</tr>
</tbody>
</table>
<ul>
<li>词法分析（定制版） 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>必需</th>
<th>详细说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>string</td>
<td>是</td>
<td>原始单条请求文本</td>
</tr>
<tr>
<td>items</td>
<td>array(object)</td>
<td>是</td>
<td>词汇数组，每个元素对应结果中的一个词</td>
</tr>
<tr>
<td>+item</td>
<td>string</td>
<td>是</td>
<td>词汇的字符串</td>
</tr>
<tr>
<td>+ne</td>
<td>string</td>
<td>是</td>
<td>命名实体类型，命名实体识别算法使用。词性标注算法中，此项为空串</td>
</tr>
<tr>
<td>+pos</td>
<td>string</td>
<td>是</td>
<td>词性，词性标注算法使用。命名实体识别算法中，此项为空串</td>
</tr>
<tr>
<td>+byte_offset</td>
<td>int</td>
<td>是</td>
<td>在text中的字节级offset（使用GBK编码）</td>
</tr>
<tr>
<td>+byte_length</td>
<td>int</td>
<td>是</td>
<td>字节级length（使用GBK编码）</td>
</tr>
<tr>
<td>+uri</td>
<td>string</td>
<td>否</td>
<td>链指到知识库的URI，只对命名实体有效。对于非命名实体和链接不到知识库的命名实体，此项为空串</td>
</tr>
<tr>
<td>+formal</td>
<td>string</td>
<td>否</td>
<td>词汇的标准化表达，主要针对时间、数字单位，没有归一化表达的，此项为空串</td>
</tr>
<tr>
<td>+basic_words</td>
<td>array(string)</td>
<td>是</td>
<td>基本词成分</td>
</tr>
<tr>
<td>+loc_details</td>
<td>array(object)</td>
<td>否</td>
<td>地址成分，非必需，仅对地址型命名实体有效，没有地址成分的，此项为空数组。</td>
</tr>
<tr>
<td>++type</td>
<td>string</td>
<td>是</td>
<td>成分类型，如省、市、区、县</td>
</tr>
<tr>
<td>++byte_offset</td>
<td>int</td>
<td>是</td>
<td>在item中的字节级offset（使用GBK编码）</td>
</tr>
<tr>
<td>++byte_length</td>
<td>int</td>
<td>是</td>
<td>字节级length（使用GBK编码）  </td>
</tr>
</tbody>
</table>
<p><strong>依存句法分析</strong>  </p>
<p>依存句法分析接口可自动分析文本中的依存句法结构信息，利用句子中词与词之间的依存关系来表示词语的句法结构信息（如“主谓”、“动宾”、“定中”等结构关系），并用树状结构来表示整句的结构（如“主谓宾”、“定状补”等）。  </p>
<pre><code>text = &quot;张飞&quot;

&quot;&quot;&quot; 调用依存句法分析 &quot;&quot;&quot;
client.depParser(text);

&quot;&quot;&quot; 如果有可选参数 &quot;&quot;&quot;
options = {}
options[&quot;mode&quot;] = 1

&quot;&quot;&quot; 带参数调用依存句法分析 &quot;&quot;&quot;
client.depParser(text, options)  
</code></pre><ul>
<li>依存句法分析 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>待分析文本（目前仅支持GBK编码），长度不超过256字节</td>
</tr>
<tr>
<td>mode</td>
<td>否</td>
<td>string</td>
<td>模型选择。默认值为0，可选值mode=0（对应web模型）；mode=1（对应query模型）</td>
</tr>
</tbody>
</table>
<ul>
<li>依存句法分析 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>详细说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>uint64</td>
<td>随机数，本次请求的唯一标识码</td>
</tr>
<tr>
<td>id</td>
<td>number</td>
<td>词的ID</td>
</tr>
<tr>
<td>word</td>
<td>string</td>
<td>词</td>
</tr>
<tr>
<td>postag</td>
<td>string</td>
<td>词性，请参照API文档中的词性（postag)取值范围</td>
</tr>
<tr>
<td>head</td>
<td>int</td>
<td>词的父节点ID</td>
</tr>
<tr>
<td>+deprel</td>
<td>string</td>
<td>词与父节点的依存关系，请参照API文档的依存关系标识</td>
</tr>
</tbody>
</table>
<ul>
<li><p>依存句法分析 返回示例    </p>
<pre><code>{
&quot;log_id&quot;: 12345,
&quot;text&quot;:&quot;今天天气怎么样&quot;,
&quot;items&quot;:[
{
&quot;id&quot;:&quot;1&quot;, //id
&quot;word&quot;:&quot;今天&quot;, //word
&quot;postag&quot;:&quot;t&quot;, //POS tag
&quot;head&quot;:&quot;2&quot;, //id of current word&apos;s parent
&quot;deprel&quot;:&quot;ATT&quot;  //depend relations between current word and parent
},
{
&quot;id&quot;:&quot;2&quot;,
&quot;word&quot;:&quot;天气&quot;,
&quot;postag&quot;:&quot;n&quot;,
&quot;head&quot;:&quot;3&quot;,
&quot;deprel&quot;:&quot;SBV&quot;,
},
{
&quot;id&quot;:&quot;3&quot;,
&quot;word&quot;:&quot;怎么样&quot;,
&quot;postag&quot;:&quot;r&quot;,
&quot;head&quot;:&quot;0&quot;,
&quot;deprel&quot;:&quot;HED&quot;,
}
]
}  
</code></pre></li>
</ul>
<p><strong>词向量表示</strong>  </p>
<p>词向量表示接口提供中文词向量的查询功能。</p>
<pre><code>word = &quot;张飞&quot;

&quot;&quot;&quot; 调用词向量表示 &quot;&quot;&quot;
client.wordEmbedding(word);
</code></pre><ul>
<li>词向量表示 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<p>word    是    string    文本内容（GBK编码），最大64字节</p>
<ul>
<li>词向量表示 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>描述  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>uint64</td>
<td>请求唯一标识码</td>
</tr>
<tr>
<td>word</td>
<td>string</td>
<td>查询词</td>
</tr>
<tr>
<td>vec</td>
<td>float</td>
<td>词向量结果表示</td>
</tr>
</tbody>
</table>
<ul>
<li><p>词向量表示 返回示例  </p>
<pre><code>{
  &quot;word&quot;: &quot;张飞&quot;,
  &quot;vec&quot;: [
0.233962,
0.336867,
0.187044,
0.565261,
0.191568,
0.450725,
...
0.43869,
-0.448038,
0.283711,
-0.233656,
0.555556
  ]
}  
</code></pre></li>
</ul>
<p><strong> DNN语言模型 </strong></p>
<p>中文DNN语言模型接口用于输出切词结果并给出每个词在句子中的概率值,判断一句话是否符合语言表达习惯。</p>
<pre><code>text = &quot;床前明月光&quot;

&quot;&quot;&quot; 调用DNN语言模型 &quot;&quot;&quot;
client.dnnlm(text);
</code></pre><ul>
<li>DNN语言模型 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>文本内容（GBK编码），最大512字节，不需要切词  </td>
</tr>
</tbody>
</table>
<ul>
<li>DNN语言模型 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>uint64</td>
<td>请求唯一标识码</td>
</tr>
<tr>
<td>word</td>
<td>string</td>
<td>句子的切词结果</td>
</tr>
<tr>
<td>prob</td>
<td>float</td>
<td>该词在句子中的概率值,取值范围[0,1]</td>
</tr>
<tr>
<td>ppl</td>
<td>float</td>
<td>描述句子通顺的值：数值越低，句子越通顺</td>
</tr>
</tbody>
</table>
<pre><code>{
  &quot;text&quot;: &quot;床前明月光&quot;,
  &quot;items&quot;: [
    {
      &quot;word&quot;: &quot;床&quot;,
      &quot;prob&quot;: 0.0000385273
    },
    {
      &quot;word&quot;: &quot;前&quot;,
      &quot;prob&quot;: 0.0289018
    },
    {
      &quot;word&quot;: &quot;明月&quot;,
      &quot;prob&quot;: 0.0284406
    },
    {
      &quot;word&quot;: &quot;光&quot;,
      &quot;prob&quot;: 0.808029
    }
  ],
  &quot;ppl&quot;: 79.0651
}  
</code></pre><p><strong>词义相似度</strong></p>
<p>输入两个词，得到两个词的相似度结果。</p>
<pre><code>word1 = &quot;北京&quot;

word2 = &quot;上海&quot;

&quot;&quot;&quot; 调用词义相似度 &quot;&quot;&quot;
client.wordSimEmbedding(word1, word2);

&quot;&quot;&quot; 如果有可选参数 &quot;&quot;&quot;
options = {}

&quot;&quot;&quot; 带参数调用词义相似度 &quot;&quot;&quot;
client.wordSimEmbedding(word1, word2, options)
</code></pre><ul>
<li>词义相似度 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>word_1</td>
<td>是</td>
<td>string</td>
<td>词1（GBK编码），最大64字节</td>
</tr>
<tr>
<td>word_2</td>
<td>是</td>
<td>string</td>
<td>词1（GBK编码），最大64字节  </td>
</tr>
</tbody>
</table>
<ul>
<li>词义相似度 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>描述  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>number</td>
<td>请求唯一标识码,随机数</td>
</tr>
<tr>
<td>score</td>
<td>number</td>
<td>相似度分数</td>
</tr>
<tr>
<td>words</td>
<td>array</td>
<td>输入的词列表</td>
</tr>
<tr>
<td>+word_1</td>
<td>string</td>
<td>输入的word1参数</td>
</tr>
<tr>
<td>+word_2</td>
<td>string</td>
<td>输入的word2参数  </td>
</tr>
</tbody>
</table>
<ul>
<li><p>词义相似度 返回示例    </p>
<pre><code>{
    &quot;score&quot;: 0.456862,
    &quot;words&quot;: {
    &quot;word_1&quot;: &quot;北京&quot;,
    &quot;word_2&quot;: &quot;上海&quot;
    }
}
</code></pre></li>
</ul>
<p><strong>短文本相似度</strong></p>
<p>短文本相似度接口用来判断两个文本的相似度得分。</p>
<pre><code>text1 = &quot;浙富股份&quot;

text2 = &quot;万事通自考网&quot;

&quot;&quot;&quot; 调用短文本相似度 &quot;&quot;&quot;
client.simnet(text1, text2);

&quot;&quot;&quot; 如果有可选参数 &quot;&quot;&quot;
options = {}
options[&quot;model&quot;] = &quot;CNN&quot;

&quot;&quot;&quot; 带参数调用短文本相似度 &quot;&quot;&quot;
client.simnet(text1, text2, options)
</code></pre><ul>
<li>短文本相似度 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>可选值范围</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text_1</td>
<td>是</td>
<td>string</td>
<td></td>
<td>待比较文本1（GBK编码），最大512字节</td>
</tr>
<tr>
<td>text_2</td>
<td>是</td>
<td>string</td>
<td></td>
<td>待比较文本2（GBK编码），最大512字节</td>
</tr>
<tr>
<td>model</td>
<td>否</td>
<td>string</td>
<td>BOW /CNN /GRNN</td>
<td>默认为”BOW”，可选”BOW”、”CNN”与”GRNN”  </td>
</tr>
</tbody>
</table>
<ul>
<li>短文本相似度 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>描述  </th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>number</td>
<td>请求唯一标识</td>
</tr>
<tr>
<td>score</td>
<td>number</td>
<td>两个文本相似度得分</td>
</tr>
<tr>
<td>texts</td>
<td>array</td>
<td>输入文本</td>
</tr>
<tr>
<td>+text_1</td>
<td>string</td>
<td>第一个短文本</td>
</tr>
<tr>
<td>+text_2</td>
<td>string</td>
<td>第二个短文本  </td>
</tr>
</tbody>
</table>
<ul>
<li><p>短文本相似度 返回示例</p>
<pre><code>{
    &quot;log_id&quot;: 12345,
    &quot;texts&quot;:{
    &quot;text_1&quot;:&quot;浙富股份&quot;,
    &quot;text_2&quot;:&quot;万事通自考网&quot;
    },
   &quot;score&quot;:0.3300237655639648 //相似度结果
},  
</code></pre></li>
</ul>
<p><strong>评论观点抽取</strong></p>
<p>评论观点抽取接口用来提取一条评论句子的关注点和评论观点，并输出评论观点标签及评论观点极性。</p>
<pre><code>text = &quot;三星电脑电池不给力&quot;

&quot;&quot;&quot; 调用评论观点抽取 &quot;&quot;&quot;
client.commentTag(text);

&quot;&quot;&quot; 如果有可选参数 &quot;&quot;&quot;
options = {}
options[&quot;type&quot;] = 13

&quot;&quot;&quot; 带参数调用评论观点抽取 &quot;&quot;&quot;
client.commentTag(text, options)
</code></pre><ul>
<li>评论观点抽取 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>可选值范围</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td></td>
<td>评论内容（GBK编码），最大10240字节</td>
</tr>
<tr>
<td>type</td>
<td>否</td>
<td>string</td>
<td>1 - 酒店 2 - KTV 3 - 丽人 4 - 美食餐饮 5 - 旅游 6 - 健康 7 - 教育 8 - 商业 9 - 房产 10 - 汽车 11 - 生活 12 - 购物 13 - 3C</td>
<td>评论行业类型，默认为4（餐饮美食）</td>
</tr>
</tbody>
</table>
<ul>
<li>评论观点抽取 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>log_id</td>
<td>uint64</td>
<td>请求唯一标识码</td>
</tr>
<tr>
<td>prop</td>
<td>string</td>
<td>匹配上的属性词</td>
</tr>
<tr>
<td>adj</td>
<td>string</td>
<td>匹配上的描述词</td>
</tr>
<tr>
<td>sentiment</td>
<td>int</td>
<td>该情感搭配的极性（0表示消极，1表示中性，2表示积极）</td>
</tr>
<tr>
<td>begin_pos</td>
<td>int</td>
<td>该情感搭配在句子中的开始位置</td>
</tr>
<tr>
<td>end_pos</td>
<td>int</td>
<td>该情感搭配在句子中的结束位置</td>
</tr>
<tr>
<td>abstract</td>
<td>string</td>
<td>对应于该情感搭配的短句摘要</td>
</tr>
</tbody>
</table>
<ul>
<li><p>评论观点抽取 返回示例</p>
<pre><code>{
    &quot;items&quot;: [
    {
    &quot;prop&quot;:&quot;电池&quot;,
    &quot;adj&quot;: &quot;不给力&quot;,
    &quot;sentiment&quot;: 0,
    &quot;begin_pos&quot;: 8,
    &quot;end_pos&quot;: 18,
    &quot;abstract&quot;:&quot;三星电脑&lt;span&gt;电池不给力&lt;/span&gt;&quot;
    }
    ]
}  
</code></pre></li>
</ul>
<p><strong>情感倾向分析</strong></p>
<p>对包含主观观点信息的文本进行情感极性类别（积极、消极、中性）的判断，并给出相应的置信度。</p>
<pre><code>text = &quot;苹果是一家伟大的公司&quot;

&quot;&quot;&quot; 调用情感倾向分析 &quot;&quot;&quot;
client.sentimentClassify(text);
</code></pre><ul>
<li>情感倾向分析 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>文本内容（GBK编码），最大2048字节  </td>
</tr>
</tbody>
</table>
<ul>
<li>情感倾向分析 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>是否必须</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>是</td>
<td>string</td>
<td>输入的文本内容</td>
</tr>
<tr>
<td>items</td>
<td>是</td>
<td>array</td>
<td>输入的词列表</td>
</tr>
<tr>
<td>+sentiment</td>
<td>是</td>
<td>number</td>
<td>表示情感极性分类结果, 0:负向，1:中性，2:正向</td>
</tr>
<tr>
<td>+confidence</td>
<td>是</td>
<td>number</td>
<td>表示分类的置信度</td>
</tr>
<tr>
<td>+positive_prob</td>
<td>是</td>
<td>number</td>
<td>表示属于积极类别的概率</td>
</tr>
<tr>
<td>+negative_prob</td>
<td>是</td>
<td>number</td>
<td>表示属于消极类别的概率</td>
</tr>
</tbody>
</table>
<ul>
<li><p>情感倾向分析 返回示例</p>
<pre><code>{
    &quot;text&quot;:&quot;苹果是一家伟大的公司&quot;,
    &quot;items&quot;:[
    {
    &quot;sentiment&quot;:2,//表示情感极性分类结果
    &quot;confidence&quot;:0.40, //表示分类的置信度
    &quot;positive_prob&quot;:0.73, //表示属于积极类别的概率
    &quot;negative_prob&quot;:0.27  //表示属于消极类别的概率
    }
    ]
}
</code></pre></li>
</ul>
<p><strong>文章标签</strong> </p>
<p>文章标签服务能够针对网络各类媒体文章进行快速的内容理解，根据输入含有标题的文章，输出多个内容标签以及对应的置信度，用于个性化推荐、相似文章聚合、文本内容分析等场景。</p>
<pre><code>title = &quot;iphone手机出现“白苹果”原因及解决办法，用苹果手机的可以看下&quot;

content = &quot;如果下面的方法还是没有解决你的问题建议来我们门店看下成都市锦江区红星路三段99号银石广场24层01室。&quot;

&quot;&quot;&quot; 调用文章标签 &quot;&quot;&quot;
client.keyword(title, content);
</code></pre><ul>
<li>文章标签 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>title</td>
<td>是</td>
<td>string</td>
<td>篇章的标题，最大80字节</td>
</tr>
<tr>
<td>content</td>
<td>是</td>
<td>string</td>
<td>篇章的正文，最大65535字节  </td>
</tr>
</tbody>
</table>
<ul>
<li>文章标签 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>是否必选</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>items</td>
<td>是</td>
<td>array(object)</td>
<td>关键词结果数组，每个元素对应抽取到的一个关键词</td>
</tr>
<tr>
<td>+tag</td>
<td>是</td>
<td>string</td>
<td>关注点字符串</td>
</tr>
<tr>
<td>+score</td>
<td>是</td>
<td>number</td>
<td>权重(取值范围0~1)  </td>
</tr>
</tbody>
</table>
<ul>
<li>文章标签 返回示例</li>
</ul>
<pre><code>{
    &quot;log_id&quot;: 4457308639853058292,
    &quot;items&quot;: [
    {
        &quot;score&quot;: 0.997762,
        &quot;tag&quot;: &quot;iphone&quot;
    },
    {
        &quot;score&quot;: 0.861775,
        &quot;tag&quot;: &quot;手机&quot;
    },
    {
        &quot;score&quot;: 0.845657,
        &quot;tag&quot;: &quot;苹果&quot;
    },
    {
        &quot;score&quot;: 0.83649,
        &quot;tag&quot;: &quot;苹果公司&quot;
    },
    {
        &quot;score&quot;: 0.797243,
        &quot;tag&quot;: &quot;数码&quot;
    }
    ]
}  
</code></pre><p><strong>文章分类</strong>  </p>
<p>对文章按照内容类型进行自动分类，首批支持娱乐、体育、科技等26个主流内容类型，为文章聚类、文本内容分析等应用提供基础技术支持。</p>
<pre><code>title = &quot;欧洲冠军杯足球赛&quot;

content = &quot;欧洲冠军联赛是欧洲足球协会联盟主办的年度足球比赛，代表欧洲俱乐部足球最高荣誉和水平，被认为是全世界最高素质、最具影响力以及最高水平的俱乐部赛事，亦是世界上奖金最高的足球赛事和体育赛事之一。&quot;

&quot;&quot;&quot; 调用文章分类 &quot;&quot;&quot;
client.topic(title, content);
</code></pre><ul>
<li>文章分类 请求参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>是否必选</th>
<th>类型</th>
<th>说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>title</td>
<td>是</td>
<td>string</td>
<td>篇章的标题，最大80字节</td>
</tr>
<tr>
<td>content</td>
<td>是</td>
<td>string</td>
<td>篇章的正文，最大65535字节</td>
</tr>
</tbody>
</table>
<ul>
<li>文章分类 返回数据参数详情</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>详细说明  </th>
</tr>
</thead>
<tbody>
<tr>
<td>item</td>
<td>object</td>
<td>分类结果，包含一级与二级分类</td>
</tr>
<tr>
<td>+lv1_tag_list</td>
<td>array of objects</td>
<td>一级分类结果</td>
</tr>
<tr>
<td>+lv2_tag_list</td>
<td>array of objects</td>
<td>二级分类结果</td>
</tr>
<tr>
<td>++score</td>
<td>float</td>
<td>类别标签对应得分，范围0-1</td>
</tr>
<tr>
<td>++tag</td>
<td>string</td>
<td>类别标签</td>
</tr>
</tbody>
</table>
<ul>
<li><p>文章分类 返回示例</p>
<pre><code>{
    &quot;log_id&quot;: 5710764909216517248,
    &quot;item&quot;: {
    &quot;lv2_tag_list&quot;: [
    {
    &quot;score&quot;: 0.895467,
    &quot;tag&quot;: &quot;足球&quot;
    },
    {
    &quot;score&quot;: 0.794878,
    &quot;tag&quot;: &quot;国际足球&quot;
    }
    ],
    &quot;lv1_tag_list&quot;: [
    {
    &quot;score&quot;: 0.88808,
    &quot;tag&quot;: &quot;体育&quot;
    }
    ]
    }
}
</code></pre></li>
</ul>
<p>错误信息</p>
<p><strong>错误返回格式</strong>  </p>
<p>若请求错误，服务器将返回的JSON文本包含以下参数：</p>
<ul>
<li>error_code：错误码。</li>
<li>error_msg：错误描述信息，帮助理解和解决发生的错误。  </li>
</ul>
<p><strong>错误码</strong>  </p>
<table>
<thead>
<tr>
<th>错误码</th>
<th>错误信息</th>
<th>描述  </th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>Open api request limit reached</td>
<td>集群超限额</td>
</tr>
<tr>
<td>14</td>
<td>IAM Certification failed</td>
<td>IAM鉴权失败，建议用户参照文档自查生成sign的方式是否正确，或换用控制台中ak sk的方式调用</td>
</tr>
<tr>
<td>17</td>
<td>Open api daily request limit reached</td>
<td>每天流量超限额</td>
</tr>
<tr>
<td>18</td>
<td>Open api qps request limit reached</td>
<td>QPS超限额</td>
</tr>
<tr>
<td>19</td>
<td>Open api total request limit reached</td>
<td>请求总量超限额</td>
</tr>
<tr>
<td>100</td>
<td>Invalid parameter</td>
<td>无效参数</td>
</tr>
<tr>
<td>110</td>
<td>Access token invalid or no longer valid</td>
<td>Access Token失效</td>
</tr>
<tr>
<td>111</td>
<td>Access token expired</td>
<td>Access token过期</td>
</tr>
<tr>
<td>282000</td>
<td>internal error</td>
<td>服务器内部错误，请再次请求， 如果持续出现此类错误，请通过QQ群（632426386）或工单联系技术支持团队。</td>
</tr>
<tr>
<td>282002</td>
<td>input encoding error</td>
<td>编码错误，请使用GBK编码</td>
</tr>
<tr>
<td>282004</td>
<td>invalid parameter(s)</td>
<td>请求中包含非法参数，请检查后重新尝试</td>
</tr>
<tr>
<td>282130</td>
<td>no result</td>
<td>当前查询无结果返回，出现此问题的原因一般为：参数配置存在问题，请检查后重新尝试</td>
</tr>
<tr>
<td>282131</td>
<td>input text too long</td>
<td>输入长度超限，请查看文档说明</td>
</tr>
<tr>
<td>282133</td>
<td>param {参数名} not exist</td>
<td>接口参数缺失</td>
</tr>
<tr>
<td>282300</td>
<td>word error</td>
<td>word不在算法词典中</td>
</tr>
<tr>
<td>282301</td>
<td>word_1 error</td>
<td>word_1提交的词汇暂未收录，无法比对相似度</td>
</tr>
<tr>
<td>282302</td>
<td>word_2 error</td>
<td>word_2提交的词汇暂未收录，无法比对相似度</td>
</tr>
<tr>
<td>282303</td>
<td>word_1&amp;word_2 error</td>
<td>word_1和word_2暂未收录，无法比对相似度</td>
</tr>
</tbody>
</table>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/11/赵小静_爱汉语语料库/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/11/赵小静_爱汉语语料库/" itemprop="url">爱汉语语料库</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-11T14:37:46+05:00">
                2018-03-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：赵小静</p>
<ul>
<li>地址</li>
<li>简介</li>
<li>使用说明</li>
<li>使用实例</li>
</ul>
<h2 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h2><p><a href="http://www.aihanyu.org/cncorpus/index.aspx" target="_blank" rel="noopener">http://www.aihanyu.org/cncorpus/index.aspx</a></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>引自爱汉语语料库：</p>
<blockquote>
<p>该语料库包含“语料库检索”、“语料分析处理”、“研究资源”三部分，分别用于现代汉语、古代汉语字词索引；分词及词性标注；汉语拼音标注；字词频率统计等功能。</p>
</blockquote>
<blockquote>
<p>其中，现代汉语语料库语料库样本数：9487个（样本数即篇章数）；语料库字符数：19455328个（含汉字、字母、数字、标点等）；语料库总词语数：12842116个（含单字词、多字词、字母词、外文祠、数字串、标点符号等）；语料库总词语个数：162875（指语料库出现的分词单位的个数）</p>
</blockquote>
<blockquote>
<p>语料库总汉字词语个数：151300（含汉字的词语个数，不包括外文词、标点、数字串等）；语料库说明：现代汉语语料库是一个大规模的平衡语料库，语料选材类别广泛，时间跨度大。在线提供检索的语料经过分词和词性标注，可以进行按词检索和分词类的检索。</p>
</blockquote>
<blockquote>
<p>古代汉语语料库语料库字数： 约一亿字；语料库说明：古代汉语语料库包含自周至清各朝代的约1亿字语料，含四库全书中的大部分古籍资料。 部分书目如下：诗经、尚书、周易、老子、论语、孟子、左传、楚辞、礼记、大学、中庸、吕氏春秋、尔雅、淮南子、史记、战国策、三国志、世说新语、文心雕龙、全唐诗、朱子语类、封神演义、三国演义、水浒传、西游记、红楼梦、儒林外史等。；语料库检索：语料库未经标注，支持全文检索、模糊检索，支持语料出处、关键词居中（KWIC）排列显示。</p>
</blockquote>
<blockquote>
<p> 语料分词和词性标注： 在线使用的语料分词和词性标注工具。<br>  语料汉语拼音自动标注： 在线使用的语料汉语拼音自动标注工具。<br>  语料字词频率统计： 在线使用的语料字词频率统计工具。<br>  语料分析处理软件的单机版可在研究资源页面下载。</p>
</blockquote>
<h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><h3 id="现代汉语、古代汉语语料库"><a href="#现代汉语、古代汉语语料库" class="headerlink" title="现代汉语、古代汉语语料库"></a>现代汉语、古代汉语语料库</h3><p>现代汉语语料库</p>
<p>查询模式</p>
<p>整词匹配：使用整词索引进行查询，可带词类，多关键词时忽略顺序，速度快，多关键词查询时任一关键词未被索引则不能返回结果。</p>
<p>模糊匹配：模糊匹配最易查全，可带词类，多关键词时考虑前后顺序，速度较慢。支持查询词类串。</p>
<p>全文检索：使用全文检索方式进行查询，不可带词类，多关键词时忽略前后顺序，速度快，但不能检索“的、了”等极高频词。</p>
<p>查询条件格式</p>
<p>查询条件由一个或多个关键词组成：单一关键词，如： 语言、语言；字或词，如：文、语言；词+词类，如： 语言/n、制定/v；词类标识符为[ / ]，如：语言/n，多关键词，如： 语言 文字，语言/n 文字/n，连续词类串，如： /v /u /m /v。</p>
<p>词性标记代码：</p>
<table>
<thead>
<tr>
<th>n</th>
<th>普通名词</th>
<th>nt</th>
<th>时间名词</th>
<th>nd</th>
<th>方位名词</th>
</tr>
</thead>
<tbody>
<tr>
<td>nl</td>
<td>处所名词</td>
<td>nh</td>
<td>人名</td>
<td>nhf</td>
<td>姓</td>
</tr>
<tr>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>nhs</td>
<td>名</td>
<td>ns</td>
<td>地名</td>
<td>nn</td>
<td>族名</td>
</tr>
<tr>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>ni</td>
<td>机构名</td>
<td>nz</td>
<td>其他专名</td>
<td>v</td>
<td>动词</td>
</tr>
<tr>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>vd</td>
<td>趋向动词</td>
<td>vl</td>
<td>联系动词</td>
<td>vu</td>
<td>能愿动词</td>
</tr>
<tr>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>a</td>
<td>形容词</td>
<td>f</td>
<td>区别词</td>
<td>m</td>
<td>数词</td>
</tr>
<tr>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>q</td>
<td>量词</td>
<td>d</td>
<td>副词</td>
<td>r</td>
<td>代词</td>
</tr>
<tr>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>p</td>
<td>介词</td>
<td>c</td>
<td>连词</td>
<td>u</td>
<td>助词</td>
</tr>
<tr>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>e</td>
<td>叹词</td>
<td>o</td>
<td>拟声词</td>
<td>i</td>
<td>习用语</td>
</tr>
<tr>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>j</td>
<td>缩略语</td>
<td>h</td>
<td>前接成分</td>
<td>k</td>
<td>后接成分</td>
</tr>
<tr>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>g</td>
<td>语素字</td>
<td>x</td>
<td>非语素字</td>
<td>w</td>
<td>标点符号</td>
</tr>
<tr>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>ws</td>
<td>非汉字字符串</td>
<td>wu</td>
<td>其他未知的符号</td>
</tr>
<tr>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
</tbody>
</table>
<p>多关键词逻辑<br>只对[整词匹配]的查询方式有效的标记：空格或 [+] 表示 [与(and)] 关系，如： 语言 文字 或 语言 +文字；[@] 表示 [或(or)] 关系，如： 语言 @文字 ；[-] 表示 [非(not)] 关系，如： 语言 -文字。示例：条件“语言 @文字 研究 -教学”表示检索“包含关键词’语言’或’文字’并且含关键词’研究’但不含关键词’教学’”的例句。</p>
<p>古代汉语语料库</p>
<p>查询模式、查询条件格式与现代汉语语料库相同，此外可以分朝代进行检索。</p>
<h3 id="分词及词性标注-amp-汉语拼音-amp-字词频率统计"><a href="#分词及词性标注-amp-汉语拼音-amp-字词频率统计" class="headerlink" title="分词及词性标注&amp;汉语拼音&amp;字词频率统计"></a>分词及词性标注&amp;汉语拼音&amp;字词频率统计</h3><p>输入文本后可自动进行分词、词性标注、汉语拼音标注及字词频率统计。</p>
<h2 id="使用实例"><a href="#使用实例" class="headerlink" title="使用实例"></a>使用实例</h2><h3 id="现代汉语、古代汉语语料库-1"><a href="#现代汉语、古代汉语语料库-1" class="headerlink" title="现代汉语、古代汉语语料库"></a>现代汉语、古代汉语语料库</h3><p>如，在现代汉语语料库检索栏中输入“调查/v 得”，得到87条符合条件的生语料及87条符合条件的标注语料。全部语料可下载。<br>如，在古代汉语语料库中，将朝代设定为“宋”，输入“何+之”进行检索，得到14264条语料。</p>
<h3 id="分词及词性标注-amp-汉语拼音-amp-字词频率统计。"><a href="#分词及词性标注-amp-汉语拼音-amp-字词频率统计。" class="headerlink" title="分词及词性标注&amp;汉语拼音&amp;字词频率统计。"></a>分词及词性标注&amp;汉语拼音&amp;字词频率统计。</h3><p>分别在检索框中输入“现代汉语”，得到以下结果：</p>
<p>分词及词性标注结果：现代/nt  汉语/n  </p>
<p>汉语拼音标注结果：现代/xiàndài  汉语/hànyǔ  </p>
<p>字频统计结果：得到现代汉语四字的频次及频次。如图：<br><img src="attachment:image.png" alt="image.png"><img src="attachment:image.png" alt="image.png"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/11/郭铭昊_Robobrowser/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/11/郭铭昊_Robobrowser/" itemprop="url">Robobrowser</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-11T14:37:46+05:00">
                2018-03-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：郭铭昊</p>
<h2 id="Robobrowser——一个轻量级爬虫库"><a href="#Robobrowser——一个轻量级爬虫库" class="headerlink" title="Robobrowser——一个轻量级爬虫库"></a>Robobrowser——一个轻量级爬虫库</h2><blockquote>
<p>常用于爬虫和简单的web测试，纯python编写，用起来很方便，语法自然，且易学。另外，robobrowser建立在requests和BeautifulSoup之上，容易被人们接受。官方介绍Robobrowser是：Your friendly neighborhood web scraper。</p>
</blockquote>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><hr>
<h3 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h3><ul>
<li><p>RoboState类里，页面上内容的抓取和处理实际上委托给了BeautifulSoup。RoboState类的_parsed对象实际上就是BeautifulSoup的实例；</p>
</li>
<li><p>RoboState类中保存了每个请求的响应内容——response.content；</p>
</li>
<li><p>RoboBrowser类里，发送请求的方法实际上委托给了requests类——session;</p>
</li>
<li><p>RoboBrowser类里比较复杂就是保存每次访问的状态，以及实现back和forward功能。其主要思想是把所有的访问历史都放在内存里，然后通过游标去访问；</p>
</li>
<li><p>每次页面发生变化，也就是open和submit_form之后都会调用_update_state方法去更新当前状态；</p>
</li>
<li><a href="https://github.com/jmcarp/robobrowser" target="_blank" rel="noopener">点击这里</a> 了解详情.</li>
</ul>
<h3 id="流程梳理"><a href="#流程梳理" class="headerlink" title="流程梳理"></a>流程梳理</h3><ul>
<li><p>RoboBrowser()实例化的时候，会new 1个requests的session用于发送http请求,同时初始化游标为－1并且当前的status列表初始化为空;</p>
</li>
<li><p>RoboBrowser.open(url)方法调用时，session对象会访问具体的url，然后更新游标和status列表。基本思想是往status列表里append 1个新new出来的RoboState对象；</p>
</li>
<li><p>RoboBrowser.find()方法调用时，使用当前游标处的state对象的_parsed对象的find方法去抓取页面内容，实际上就是BeautifulSoup的find方法；</p>
</li>
</ul>
<h2 id="安装Robobrowser"><a href="#安装Robobrowser" class="headerlink" title="安装Robobrowser"></a>安装Robobrowser</h2><hr>
<ul>
<li>使用pip安装：<pre><code>      <pre><code>pip install robobrowser -i http://pypi.douban.com/simple/
</code></pre></code></pre></li>
</ul>
<h2 id="小例子"><a href="#小例子" class="headerlink" title="小例子"></a>小例子</h2><hr>
<ul>
<li><p><strong>新建1个start.py文本文件，代码如下</strong></p>
<pre><code>      
      import re
      from robobrowser import RoboBrowser

      b = RoboBrowser(history=True)
      b.open('http://itest.info/courses/2')

      title = b.select('.headline h2')
      print title[0].text

      infos = b.select('h4')

      for info in infos:
          print info.text
</code></pre>

</li>
</ul>
<h2 id="文档查询"><a href="#文档查询" class="headerlink" title="文档查询"></a>文档查询</h2><hr>
<ul>
<li><strong>robobrowser自带文档shu说明，命令行运行：</strong><pre><code>        
      python -m pydoc -p 1234
</code></pre>

</li>
</ul>
<h2 id="简单的爬虫"><a href="#简单的爬虫" class="headerlink" title="简单的爬虫"></a>简单的爬虫</h2><hr>
<h3 id="代码讲解"><a href="#代码讲解" class="headerlink" title="代码讲解"></a>代码讲解</h3><pre><code>        
        import re
        from robobrowser import RoboBrowser

        url = 'http://itest.info/courses/2'
        b = RoboBrowser(history=True)
        b.open(url)

        class_name = b.select('.headline h2')
        print class_name[0].text

        class_desc = b.select('.tag-box')
        print class_desc[0].text 

        class_time = b.select('h4')
        print class_time[0].text

        teacher = b.select('.thumbnail-style h3')
        print teacher[0].text

        qq = b.find(text=re.compile('QQ'))
        print qq

        qq_group = b.find(text=re.compile('\+selenium'))
        print qq_group
</code></pre>

<ul>
<li>b = RoboBrowser(history=True) b.open(url) 用来创建browser和打开url；</li>
<li>b.select() 方法可以接受css选择器，返回页面上所有符合条件的元素的集合，也就是说返回的是list，可以进行迭代；</li>
<li>b.find()，只返回1个精确的结果；</li>
<li>注意，find和select方法返回的均是Beautiful Soup的tag对象或对象集合；</li>
</ul>
<h2 id="抓取制定内容"><a href="#抓取制定内容" class="headerlink" title="抓取制定内容"></a>抓取制定内容</h2><hr>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p> robobrowser支持Beautiful Soup，一般来说通过下面3个方法获取页面上感兴趣的内容</p>
<pre><code>- find
- find_all
- select
</code></pre><h3 id="find方法"><a href="#find方法" class="headerlink" title="find方法"></a>find方法</h3><p>  find方法是返回页面上符合条件的第1个元素。<pre><code><br>        import re<br>        from robobrowser import RoboBrowser<br>        url = ‘<a href="http://itest.info/courses/2&#39;" target="_blank" rel="noopener">http://itest.info/courses/2&#39;</a><br>        b = RoboBrowser(history=True)<br>        b.open(url)</code></pre></p>
<pre><code>title = b.find(&apos;title&apos;)  
print title.text

img = b.find(id=&apos;logo-header&apos;)
print img[&apos;src&apos;]

print b.find(href=&apos;/courses/4&apos;).text

print b.find(class_=&apos;active&apos;, text=re.compile(&apos;python&apos;)).text
</code></pre><p></p>
<h3 id="find-all方法"><a href="#find-all方法" class="headerlink" title="find_all方法"></a>find_all方法</h3><p> find_all方法的用法跟find基本相同，但是find_all会返回所有符合条件的tag的集合(ResultSet)。<pre><code><br>        import re<br>        from robobrowser import RoboBrowser</code></pre></p>
<pre><code>url = &apos;http://itest.info/courses/2&apos;
b = RoboBrowser(history=True)
b.open(url)

all_links = b.find_all(&apos;a&apos;)  
for link in all_links:
print link.text

divs = b.find_all(class_=&apos;container&apos;)
print divs

first_two_p = b.find_all(&apos;p&apos;, limit=2)
print first_two_p

print b.find_all([&apos;meta&apos;, &apos;img&apos;])
</code></pre><p></p>
<h3 id="select方法"><a href="#select方法" class="headerlink" title="select方法"></a>select方法</h3><p> select方法支持css选择器，返回的是list。<pre><code><br>        import re<br>        from robobrowser import RoboBrowser</code></pre></p>
<pre><code>url = &apos;http://itest.info/courses/2&apos;
b = RoboBrowser(history=True)
b.open(url)

all_links = b.select(&apos;a&apos;)  
for link in all_links:
print link.text

divs = b.select(&apos;.container&apos;)
print len(divs)
</code></pre><p></p>
<h3 id="其他技巧"><a href="#其他技巧" class="headerlink" title="其他技巧"></a>其他技巧</h3><ul>
<li>找到页面上所有具有id属性的元素  b.find_all(id=True)</li>
<li>不递归查找元素。也就是说只在的直接子后代中查找  b.find(‘p’, recursive=False)</li>
</ul>
<h2 id="follow-link"><a href="#follow-link" class="headerlink" title="follow_link"></a>follow_link</h2><hr>
<h3 id="方法介绍"><a href="#方法介绍" class="headerlink" title="方法介绍"></a>方法介绍</h3><p> robobrowser的  follow_link  方法可以点击链接并自动完成跳转。<pre><code><br>        import re<br>        from robobrowser import RoboBrowser<br>        url = ‘<a href="http://www.qq.com/&#39;" target="_blank" rel="noopener">http://www.qq.com/&#39;</a><br>        b = RoboBrowser(history=True)<br>        b.open(url)</code></pre></p>
<pre><code>today_top = b.find(id=&apos;todaytop&apos;).a  
print today_top[&apos;href&apos;]
b.follow_link(today_top)

title = b.select(&apos;.hd h1&apos;)[0]
print &apos;*************************************&apos;
print title.text
print &apos;*************************************&apos;

print b.find(id=&apos;articleContent&apos;).text
</code></pre><p></p>
<ul>
<li>follow_link的用法，一般来说都是用find/select/find_all方法过滤出相应的链接，然后调用b.follow_link(link)的方式去点击该链接。</li>
</ul>
<h2 id="表单操作"><a href="#表单操作" class="headerlink" title="表单操作"></a>表单操作</h2><hr>
<h3 id="方法介绍-1"><a href="#方法介绍-1" class="headerlink" title="方法介绍"></a>方法介绍</h3><pre><code>        
        import re
        from robobrowser import RoboBrowser

        url = 'http://testerhome.com/account/sign_in/'
        b = RoboBrowser(history=True)
        b.open(url)

        login_form = b.get_form(action='/account/sign_in')
        print login_form

        login_form['user[login]'].value = 'your account'
        login_form['user[password]'].value = 'your password'

        b.submit_form(login_form)
        print b.select('.alert.alert-success')[0].text
</code></pre>

<ul>
<li>get_form  方法用来抓取form;</li>
<li>submit_form  方法用来提交表单;</li>
<li>form[name].value=  方法用来给文本框赋值，也就是说往文本框里写内容;</li>
</ul>
<h2 id="Beauiful-Soup的过滤器"><a href="#Beauiful-Soup的过滤器" class="headerlink" title="Beauiful Soup的过滤器"></a>Beauiful Soup的过滤器</h2><hr>
<h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的b标签:<pre><code><br>        soup.find_all(‘b’)<br></code></pre></p>
<h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><p>如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示  body  和  b  标签都应该被找到:<pre><code><br>        import re<br>        for tag in soup.find_all(re.compile(“^b”)):<br>            print(tag.name)<br></code></pre></p>
<p>下面代码找出所有名字中包含”t”的标签:<pre><code><br>        for tag in soup.find_all(re.compile(“t”)):<br>            print(tag.name)<br></code></pre></p>
<h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><p>如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有  a  标签和  b  标签:<pre><code><br>        soup.find_all([“a”, “b”])<br></code></pre></p>
<h3 id="True"><a href="#True" class="headerlink" title="True"></a>True</h3><p>True 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点<pre><code><br>        for tag in soup.find_all(True):<br>            print(tag.name)<br></code></pre></p>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数 ,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False</p>
<p>下面方法校验了当前元素,如果包含 class 属性却不包含 id 属性,那么将返回 True:<pre><code><br>        def has_class_but_no_id(tag):<br>            return tag.has_attr(‘class’) and not tag.has_attr(‘id’)<br></code></pre></p>
<p>将这个方法作为参数传入 find_all() 方法,将得到所有标签：<pre><code><br>        soup.find_all(has_class_but_no_id)<br></code></pre></p>
<blockquote>
<p>常用于爬虫和简单的web测试，纯python编写，用起来很方便。</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/11/于嘉威_jieba/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/11/于嘉威_jieba/" itemprop="url">jieba</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-11T14:37:46+05:00">
                2018-03-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：于嘉威<br>“结巴”中文分词：做最好的 Python 中文分词组件:</p>
<blockquote>
<p>“Jieba” (Chinese for “to stutter”) Chinese text segmentation: built to be the best Python Chinese word segmentation module.</p>
</blockquote>
<h2 id="什么是jieba库？"><a href="#什么是jieba库？" class="headerlink" title="什么是jieba库？"></a>什么是jieba库？</h2><p><img src="https://raw.githubusercontent.com/CSerV/MarkdownPhotos/master/9150e4e5jw1fcbbf6amp6j207p06k3yq.jpg" alt="Aaron Swartz"></p>
<p>jieba 是一个python实现的分词库，对中文有着很强大的分词能力。<br>听到这个解释可能不足以让你了解，到底什么是jieba。所以我们首先要了解下面这些概念：</p>
<h4 id="1）、什么是中文分词？"><a href="#1）、什么是中文分词？" class="headerlink" title="1）、什么是中文分词？"></a>1）、什么是中文分词？</h4><p>即：中文文本，从形式上看是由汉字、标点符号等组成的一个字符串。由字组成词，再组成句子、文章等。那么分词，就是按照一定的规则把字符串重新组合成词序列的过程。</p>
<h4 id="2）、为什么要分词？"><a href="#2）、为什么要分词？" class="headerlink" title="2）、为什么要分词？"></a>2）、为什么要分词？</h4><p>（a）在中文里面，词是最小的能够独立活动的有意义的语言成分</p>
<p>（b）英文中单词以空格作为自然分界，虽然也有短语划分的问题。但中文词没有一个形式上的分界，相对而言难度大了许多</p>
<p>（c）分词作为中文自然语言处理的基础工作，质量的好坏对后面的工作影响很大</p>
<font color="red">因此有了这些概念我们便知jieba就是专门为实现中文分词的强大工具！</font>

<p>这里是jieba的详细文档：<a href="https://pypi.python.org/pypi/jieba/" target="_blank" rel="noopener">https://pypi.python.org/pypi/jieba/</a> </p>
<p>jieba的github主页位于：<a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">https://github.com/fxsjy/jieba</a></p>
<h2 id="jieba特点"><a href="#jieba特点" class="headerlink" title="jieba特点"></a>jieba特点</h2><ul>
<li>支持三种分词模式：  </li>
</ul>
<ul>
<li>精确模式，试图将句子最精确地切开，适合文本分析；  </li>
</ul>
<ul>
<li>全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；  </li>
</ul>
<ul>
<li>搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。  </li>
</ul>
<ul>
<li>支持繁体分词  </li>
</ul>
<ul>
<li>支持自定义词典  </li>
</ul>
<ul>
<li>MIT 授权协议</li>
</ul>
<h2 id="安装及使用说明"><a href="#安装及使用说明" class="headerlink" title="安装及使用说明"></a>安装及使用说明</h2><p>代码对 Python 2/3 均兼容</p>
<ul>
<li>全自动安装：easy_install jieba 或者pip install jieba / pip3 install jieba  </li>
</ul>
<ul>
<li>半自动安装：先下载 <a href="http://pypi.python.org/pypi/jieba/" target="_blank" rel="noopener">http://pypi.python.org/pypi/jieba/</a> ，解压后运行 python setup.py install  </li>
</ul>
<ul>
<li>手动安装：将 jieba 目录放置于当前目录或者 site-packages 目录  </li>
</ul>
<ul>
<li>通过 import jieba 来引用  </li>
</ul>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><ul>
<li>基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG)  </li>
</ul>
<ul>
<li>采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合  </li>
</ul>
<ul>
<li>对于未登录词，采用了基于汉字成词能力的 HMM 模型，使用了 Viterbi 算法  </li>
</ul>
<h2 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h2><blockquote>
<p>jieba的功能十分丰富，限于篇幅原因，这里只介绍两个。</p>
</blockquote>
<h3 id="1、分词"><a href="#1、分词" class="headerlink" title="1、分词"></a>1、分词</h3><hr>
<ul>
<li>jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型  </li>
</ul>
<ul>
<li>jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细  </li>
</ul>
<ul>
<li>待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8  </li>
</ul>
<ul>
<li>jieba.cut以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用  </li>
</ul>
<ul>
<li>jieba.lcut 以及jieba.lcut_for_search 直接返回 list  </li>
</ul>
<ul>
<li>jieba.Tokenizer(dictionary=DEFAULT_DICT) 新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。  </li>
</ul>
<p>代码示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(<span class="string">"我来到北京清华大学"</span>, cut_all=<span class="keyword">True</span>)</span><br><span class="line">print(<span class="string">"Full Mode: "</span> + <span class="string">"/ "</span>.join(seg_list))  <span class="comment"># 全模式</span></span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(<span class="string">"我来到北京清华大学"</span>, cut_all=<span class="keyword">False</span>)</span><br><span class="line">print(<span class="string">"Default Mode: "</span> + <span class="string">"/ "</span>.join(seg_list))  <span class="comment"># 精确模式</span></span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(<span class="string">"他来到了网易杭研大厦"</span>)  <span class="comment"># 默认是精确模式</span></span><br><span class="line">print(<span class="string">", "</span>.join(seg_list))</span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut_for_search(<span class="string">"小明硕士毕业于中国科学院计算所，后在日本京都大学深造"</span>)  <span class="comment"># 搜索引擎模式</span></span><br><span class="line">print(<span class="string">", "</span>.join(seg_list))</span><br></pre></td></tr></table></figure>
<pre><code>Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学
Default Mode: 我/ 来到/ 北京/ 清华大学
他, 来到, 了, 网易, 杭研, 大厦
小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造
</code></pre><h3 id="2、添加自定义词典"><a href="#2、添加自定义词典" class="headerlink" title="2、添加自定义词典"></a>2、添加自定义词典</h3><hr>
<h4 id="载入词典"><a href="#载入词典" class="headerlink" title="载入词典"></a>载入词典</h4><ul>
<li>开发者可以指定自己自定义的词典，以便包含 jieba 词库里没有的词。虽然 jieba 有新词识别能力，但是自行添加新词可以保证更高的正确率  </li>
</ul>
<ul>
<li>用法： jieba.load_userdict(file_name) # file_name 为文件类对象或自定义词典的路径  </li>
</ul>
<ul>
<li>词典格式和 dict.txt 一样，一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。file_name 若为路径或二进制方式打开的文件，则文件必须为 UTF-8 编码。  </li>
</ul>
<ul>
<li>词频省略时使用自动计算的能保证分出该词的词频。  </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">创新办 <span class="number">3</span> i</span><br><span class="line">云计算 <span class="number">5</span></span><br><span class="line">凱特琳 nz</span><br><span class="line">台中</span><br></pre></td></tr></table></figure>
<ul>
<li>更改分词器（默认为jieba.dt）的 tmp_dir 和 cache_file 属性，可分别指定缓存文件所在的文件夹及其文件名，用于受限的文件系统。  </li>
</ul>
<p>范例：</p>
<ul>
<li>自定义词典：<a href="https://github.com/fxsjy/jieba/blob/master/test/userdict.txt" target="_blank" rel="noopener">https://github.com/fxsjy/jieba/blob/master/test/userdict.txt</a>  </li>
</ul>
<ul>
<li>用法示例：<a href="https://github.com/fxsjy/jieba/blob/master/test/test_userdict.py" target="_blank" rel="noopener">https://github.com/fxsjy/jieba/blob/master/test/test_userdict.py</a>  </li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">之前： 李小福 / 是 / 创新 / 办 / 主任 / 也 / 是 / 云 / 计算 / 方面 / 的 / 专家 /</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">加载自定义词库后：　李小福 / 是 / 创新办 / 主任 / 也 / 是 / 云计算 / 方面 / 的 / 专家 /</span><br></pre></td></tr></table></figure>
<h4 id="调整词典"><a href="#调整词典" class="headerlink" title="调整词典"></a>调整词典</h4><ul>
<li>使用 add_word(word, freq=None, tag=None)和 del_word(word) 可在程序中动态修改词典。  </li>
</ul>
<ul>
<li>使用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。  </li>
</ul>
<ul>
<li>注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。  </li>
</ul>
<p>代码示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">'/'</span>.join(jieba.cut(<span class="string">'如果放到post中将出错。'</span>, HMM=<span class="keyword">False</span>)))</span><br><span class="line">如果/放到/post/中将/出错/。</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>jieba.suggest_freq((<span class="string">'中'</span>, <span class="string">'将'</span>), <span class="keyword">True</span>)</span><br><span class="line"><span class="number">494</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">'/'</span>.join(jieba.cut(<span class="string">'如果放到post中将出错。'</span>, HMM=<span class="keyword">False</span>)))</span><br><span class="line">如果/放到/post/中/将/出错/。</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">'/'</span>.join(jieba.cut(<span class="string">'「台中」正确应该不会被切开'</span>, HMM=<span class="keyword">False</span>)))</span><br><span class="line">「/台/中/」/正确/应该/不会/被/切开</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>jieba.suggest_freq(<span class="string">'台中'</span>, <span class="keyword">True</span>)</span><br><span class="line"><span class="number">69</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">'/'</span>.join(jieba.cut(<span class="string">'「台中」正确应该不会被切开'</span>, HMM=<span class="keyword">False</span>)))</span><br><span class="line">「/台中/」/正确/应该/不会/被/切开</span><br></pre></td></tr></table></figure>
<ul>
<li>“通过用户自定义词典来增强歧义纠错能力” — <a href="https://github.com/fxsjy/jieba/issues/14" target="_blank" rel="noopener">https://github.com/fxsjy/jieba/issues/14</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/11/孟杨慧_MLC语料库/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/11/孟杨慧_MLC语料库/" itemprop="url">MLC语料库</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-11T14:37:46+05:00">
                2018-03-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：孟杨慧</p>
<h3 id="点击访问：MLC语料库"><a href="#点击访问：MLC语料库" class="headerlink" title="点击访问：MLC语料库"></a>点击访问：<a href="http://ling.cuc.edu.cn/RawPub/" target="_blank" rel="noopener">MLC语料库</a></h3><h2 id="一-语料库简介"><a href="#一-语料库简介" class="headerlink" title="一.语料库简介"></a>一.语料库简介</h2><hr>
<ol>
<li>中国传媒大学有声媒体文本语料库（Media Language Corpus）是一个开放、免费使用的语料库。</li>
<li>语料库包括2008至2013六年的34,039个广播、电视节目的转写文本，总字符数为241,316,530个，总汉字数为200,071,896个。</li>
<li>语料库所有语料都进行了元数据标注，检索方便</li>
</ol>
<p>各年度语料规模如下表:</p>
<p><img src="https://raw.githubusercontent.com/mengyanghui/Moira/master/微信截图_20180224114047.png" width="50%" height="50%"></p>
<h2 id="二-使用教程"><a href="#二-使用教程" class="headerlink" title="二.使用教程"></a>二.使用教程</h2><hr>
<h3 id="1-关键字检索"><a href="#1-关键字检索" class="headerlink" title="1.关键字检索"></a>1.关键字检索</h3><p>-关键字检索可以在检索页面<strong>选定相应的属性项</strong>，进行特定时间段（如2008年度、2010至2013年度）、特定媒体（广播、电视）、特定单位（如中央电视台、北京电视台、中央人民广播电台）、特定语言形式（独白、对话）、特定语体（独白形式可分为播报、谈话、解说、朗读；对话形式可分为二人谈、三人谈、多人谈）、特定领域（如新闻、经济、军事）、特定栏目（如《新闻联播》《鲁豫有约》《新闻与报纸摘要》）、特定主持人（如白岩松、陈鲁豫、崔永元）等进行关键字检索。</p>
<p>-各属性之间有级联关系，既可以进行单独属性锁定查询，也可以进行<strong>属性间组合查询</strong>。如果“媒体”项选定了“广播”，不选择其他，就意味着下面的检索将在所有的广播语料中进行；如果“媒体”项选定了“广播”，那么在栏目项中只能选择广播的节目，不会再出现“新闻联播”这样的电视中的节目名称。如果所有的属性都没有选择，那就意味着将在全部2亿字次的语料中进行检索查询。</p>
<p><img src="https://raw.githubusercontent.com/mengyanghui/Moira/master/微信截图_20180224123454.png" width="20%" height="10%"></p>
<h3 id="2-特定语言格式查询"><a href="#2-特定语言格式查询" class="headerlink" title="2.特定语言格式查询"></a>2.特定语言格式查询</h3><p>语料库提供了多种查询方式，并且可以进行词性标注，如果查询各种重叠形式，如ABB、AABB、ABAB、A一A、A了A等，可以选择检索页面左边导航中的“检索重叠形式”进行查询。<br>如果需要进行成对词语，如“因为……所以、虽然……但是”等的组合查询，可以选择检索页面左边导航中的“成对字符串检索”</p>
<p><img src="https://raw.githubusercontent.com/mengyanghui/Moira/master/微信截图_20180224132511.png" width="50%" height="50%"></p>
<p>===========================================================================================================</p>
<p><img src="https://raw.githubusercontent.com/mengyanghui/Moira/master/微信截图_20180224133033.png" width="50%" height="50%"></p>
<p>=================================================================================================================</p>
<p><img src="https://raw.githubusercontent.com/mengyanghui/Moira/master/微信截图_20180224133230.png" width="50%" height="50%"></p>
<p>=================================================================================================================</p>
<h3 id="3-正则表达式检索"><a href="#3-正则表达式检索" class="headerlink" title="3.正则表达式检索"></a>3.正则表达式检索</h3><p>常用正则表达式符号的说明如下</p>
<p><img src="https://raw.githubusercontent.com/mengyanghui/Moira/master/微信截图_20180224133410.png" width="50%" height="50%"></p>
<p><img src="https://raw.githubusercontent.com/mengyanghui/Moira/master/微信截图_20180224133410.png" width="50%" height="50%"></p>
<p><img src="https://raw.githubusercontent.com/mengyanghui/Moira/master/微信截图_20180224133423.png" width="50%" height="50%"></p>
<p>========================================================================================================================<br>分词标注说明如下：</p>
<p><img src="https://raw.githubusercontent.com/mengyanghui/Moira/master/微信截图_20180224133547.png" width="50%" height="50%"></p>
<p><img src="https://raw.githubusercontent.com/mengyanghui/Moira/master/微信截图_20180224133621.png" width="50%" height="50%"></p>
<p><img src="https://raw.githubusercontent.com/mengyanghui/Moira/master/微信截图_20180224133652.png" width="50%" height="50%"></p>
<p><img src="https://raw.githubusercontent.com/mengyanghui/Moira/master/微信截图_20180224133705.png" width="50%" height="50%"></p>
<h3 id="4-二次查询"><a href="#4-二次查询" class="headerlink" title="4.二次查询"></a>4.二次查询</h3><p>可以在第一次检索的结果中再设关键字，以得到需要的更精确的检索结果。</p>
<h3 id="5-排序、保存功能"><a href="#5-排序、保存功能" class="headerlink" title="5.排序、保存功能"></a>5.排序、保存功能</h3><p>-为帮助研究者更方便地使用本语料库做统计分析，发现语言使用规律，语料库在检索结果页面设计了排序功能，可以根据需要对检索结果进行以关键字为中心的“左排序”或“右排序”。</p>
<p>-为帮助研究者更方便地使用本语料库写作论文选择例句，语料库专门设计了检索结果保存功能，可以把检索结果全部下载保存在本地机的一个文本中，系统没有对下载的数量进行限制。保存前还设计了两个可选择的项目：是否保存出处、是否需要加序号。如果选中“保存出处”，保存结果如下例所示，其中关键字串用“【】”标出。</p>
<h2 id="三-语料库的局限性"><a href="#三-语料库的局限性" class="headerlink" title="三. 语料库的局限性"></a>三. 语料库的局限性</h2><hr>
<p>1.查询结果中可能会有一些伪词串，如查询“A了A”，可能会出现“八连组建了建筑工程队”“北京西站加开了开往石家庄”“并集中了中亚地区”等，这些只能由自己甄别。</p>
<p>2.由于语料库较大，如果不设置缩小检索范围，检索时间较长。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/07/卢梦依_JRC Names实体专有名词数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/07/卢梦依_JRC Names实体专有名词数据集/" itemprop="url">JRC Names实体专有名词数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-07T17:37:46+05:00">
                2018-03-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依<br>下载地址：<a href="http://dataju.cn/Dataju/web/datasetInstanceDetail/78" target="_blank" rel="noopener">http://dataju.cn/Dataju/web/datasetInstanceDetail/78</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="数据集概述"><a href="#数据集概述" class="headerlink" title="数据集概述"></a>数据集概述</h2><p>JRC Names 是一个跨语言实体名称语料库，该语料库包含了大量跨语言人名和组织名称（称之为“实体”），包括不同语言的实体名称，包括汉语、英语、拉丁语、希腊语、阿拉伯语、斯拉夫语、日本语等。2016年之后，JRC Names还关联了其它附加信息，如每个实体在每种语言中出现的频率和时间段等。</p>
<h2 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h2><p><a href="https://ec.europa.eu/jrc/en/language-technologies/jrc-names。JRC" target="_blank" rel="noopener">https://ec.europa.eu/jrc/en/language-technologies/jrc-names。JRC</a> Names 实体专有名词是欧洲媒体监控（EMM）通过每天分析约22万条新闻报道所产生的。从2004年以来，分析了数以百万计的新闻文章，最多可以使用21种语言，识别实体（主要是人员，组织，事件名称等）的名称，并检测其中的哪一种新发现的名字是彼此的变体拼写。因此，JRC Names 中的大多数命名变体都是在现实生活中采集的（包括频繁的拼写错误）。此外，对于实体集合的一个子集，软件会自动从维基百科的跨语言链接中提取许多其他语言（例如中文，泰语，日语，…）的拼写变体。对于非常频繁或重要的名称，另外手动验证命名实体资源。由于JRC名称主要是自动生成的，所以会包含一些错误。</p>
<h1 id="文件类型"><a href="#文件类型" class="headerlink" title="文件类型"></a>文件类型</h1><p>多个文件</p>
<h1 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h1><p>756.00Mb</p>
<h1 id="用处"><a href="#用处" class="headerlink" title="用处"></a>用处</h1><p>JRC实体专有名词，可用于查找命名实体，即使它们拼写不同，但它在计算机处理文本信息过程中也能识别，可用于例如，用于文本挖掘。该工具具有多种用途并解决了各种问题，其中包括：<br>1.当搜索数据库，互联网和其他存储库时，正确的名称是一个问题，因为通常找不到搜索名称的变体。这导致对文档，图像和视听内容的存储库的非最佳使用和利用。 JRC-Names允许标准化名称，从而改进检索;<br>2.机器翻译在翻译实体专有名词时也存在问题，因为它们不应像其他单词一样翻译;利用JRC-Names可以在翻译过程之前提取名称，并且可以用目标语言重新插入外语变体来解决这个问题;<br>3.两个不同语言中的实体列表通常用于学习音译规则;<br>4.实体可以在文本中识别和标记，以便在训练机器学习命名实体识别系统中直接利用; 5.数据来源于多国国家，可以减少不同国家观点的偏见; 6.命名实体识别对于意见挖掘的计算语言学任务，共同参考解析，总结，主题检测和跟踪，跨语言的相关文档的跨语言链接等都是有用的。</p>
<h1 id="统计信息"><a href="#统计信息" class="headerlink" title="统计信息"></a>统计信息</h1><p>JRC Names包含EMM实体数据库中一些重要的实体，如频繁搜索或手动验证或在维基百科上发现的实体。JRC名称的第一个版本（2011年9月）包含约205,000个不同的已知实体的名称，以及这些实体的大致相同数量的变体拼写。此外，它包含这些名称的许多形态上变形的变体。截至2016年3月，该资源已增至307,000个不同实体，另有333,000个变体。EMM每天都会识别新的名称，还可以从JRC的网页上每天下载包含最近发现的名称和名称拼写的文件。截至2011年7月，数据库包括27个不同脚本中拼写的名称。最常用的是拉丁语（包括英语和大多数其他欧洲语言），西里尔语（例如俄语和保加利亚语），阿拉伯语（包括波斯语），日语（汉语，平假名和片假名）和汉语汉语（简体中文）。JRC名称中的64％的名称没有额外的拼写变体。对于28％的名字，JRC名称有两到三个拼写。有3760个实体有10个拼写或更多，37个实体有超过100个拼写变体。具有最多拼写变体的名字是Muammar Gaddafi（413个拼写），Mikhail Saakashvili（256）和Mahmoud Ahmadinejad（246）。</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>1.Steinberger Ralf,  Bruno Pouliquen, Mijail Kabadjov, Jenya Belyaeva &amp; Erik van der Goot (2011).<br> JRC-Names: A freely available, highly multilingual named entity resource. Proceedings of the 8th International Conference Recent Advances in Natural Language Processing (RANLP). Hissar, Bulgaria, 12-14 September 2011.<br>2.Ehrmann Maud, Guillaume Jacquet &amp; Ralf Steinberger (2016). JRC-Names: Multilingual Entity Name Variants and Titles as Linked Data. Semantic Web Journal (March 2016).<br>3.STEINBERGER Ralf，ATKINSON Martin，GARCIA DOMINGO Teofilo，VAN DER GOOT Erik<br>LINGE Jens，MACMILLAN Charles，TANEV Hristo，VERILE Marco，WAGNER Gerhard（2017）<br>EMM: Supporting the Analyst by Turning Multilingual Text into Structured Data<br>4.JACQUET Guillaume，EHRMANN Maud，STEINBERGER Ralf，VAEYRYNEN Jaakko（2016）.Cross-lingual linking of Multi-word Entities and their corresponding Acronyms.<br>5.王志娟, 李福现. 跨语言命名实体翻译对抽取的研究综述[J]. 计算机科学, 2017, 44(s1):14-18.<br>6.胡亚楠, 舒佳根, 钱龙华,等. 基于机器翻译的跨语言关系抽取[J]. 中文信息学报, 2013, 27(5):191-198.<br>7.吴丹, 何大庆, 陆伟. 跨语言信息检索中的命名实体识别与翻译[J]. 图书情报知识, 2012(3):13-19.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/07/刘晓_THULAC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/07/刘晓_THULAC/" itemprop="url">THULAC</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-07T14:37:46+05:00">
                2018-03-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓</p>
<h2 id="一、下载地址：http-thulac-thunlp-org"><a href="#一、下载地址：http-thulac-thunlp-org" class="headerlink" title="一、下载地址：http://thulac.thunlp.org/"></a>一、下载地址：<a href="http://thulac.thunlp.org/" target="_blank" rel="noopener">http://thulac.thunlp.org/</a></h2><h2 id="二、简介"><a href="#二、简介" class="headerlink" title="二、简介"></a>二、简介</h2><p>THULAC（THU Lexical Analyzer for Chinese）由清华大学自然语言处理与社会人文计算实验室研制推出的一套中文词法分析工具包，具有中文分词和词性标注功能。THULAC集成了目前世界上规模最大的人工分词和词性标注中文语料库（约含5800万字），模型标注能力强大。该工具包在标准数据集Chinese Treebank(CTB5)上分词的F1值可达97.3%，词性标注的F1值可达到92.9%。同时进行分词和词性标注时每秒可处理约15万字，速度较快。  </p>
<h2 id="三、使用教程"><a href="#三、使用教程" class="headerlink" title="三、使用教程"></a>三、使用教程</h2><h3 id="1、编译和安装（基于python版本，兼容2-x和3-x）"><a href="#1、编译和安装（基于python版本，兼容2-x和3-x）" class="headerlink" title="1、编译和安装（基于python版本，兼容2.x和3.x）"></a>1、编译和安装（基于python版本，兼容2.x和3.x）</h3><p><strong>1.1 源代码下载</strong><br>将thulac文件放到目录下，通过import thulac来引用，thulac需要模型的支持，需要将下载的模型放到thulac目录下。<br><strong>1.2 pip下载</strong><br>进入powershell命令行模式，输入pip install thulac，然后回车，通过import thulac来引用。  </p>
<h3 id="2、使用方式"><a href="#2、使用方式" class="headerlink" title="2、使用方式"></a>2、使用方式</h3><p><strong>2.1 分词和词性标注程序</strong><br><strong>2.1.1 命令格式（Python 3.x版）</strong><br>通过python程序导入 thulac包，新建thulac.thulac(args)类，其中args为程序的参数。之后可以通过调用thilac.cut()进行单句分词。注意：thulac只支持GBK和ASII格式文档。代码示例1:    </p>
<pre><code>&gt;&gt;&gt; import thulac  
&gt;&gt;&gt; thu1 = thulac.thulac()  
Model loaded succeed  
&gt;&gt;&gt; text = thu1.cut(&quot;浓眉哥左膝受伤离场新赛季魔咒继续&quot;, text =True)  
&gt;&gt;&gt; print(text)
浓_a 眉哥_n 左膝_n 受伤_v 离_v 场_n 新_a 赛季_n 魔_g 咒_n 继续_v
&gt;&gt;&gt;_
</code></pre><p>代码示例2：  </p>
<pre><code>&gt;&gt;&gt; thu1 = thulac.thulac(seg_only = True)  
Model loaded succeed  
&gt;&gt;&gt; thu1.cut_f(&quot;E:\\input.txt&quot;,&quot;E:\\output.txt&quot;)  
successfully cut file E:\\input.txt!
&gt;&gt;&gt;
</code></pre><h1 id=""><a href="#" class="headerlink" title=" "></a> </h1><p><strong>2.1.2 python版本接口参数</strong></p>
<ul>
<li>thulac(user_dict=None,model_path=None,T2S=False, seg+only=False)初始化程序，进行自定义设置。其中：  </li>
</ul>
<ul>
<li>user_dict：设置用户字典，用户字典中的次会被打上uw标签。词典中每一个词一行，UTF-8编码。</li>
<li>T2S：默认False，是否将句子从繁体转化为简体</li>
<li>Seg_only：默认False,是否只进行分词，不进行词性标注</li>
<li>Filt：默认False,是否使用过滤器去除一些没有意义的词语，例如“可以”。</li>
<li>model_path：设置模型文件所在文件夹，默认为models/  </li>
</ul>
<ul>
<li>cut(文本，text=False)：对一句话进行分词<ul>
<li>text：默认为False,是否返回文本，不返回文本则返回一个二维数组（[[word,tag]…]）,tag_only模式下tag为空字符。</li>
</ul>
</li>
<li>cut_f：(输入文件，输出文件)对文件进行分词  </li>
<li>run()：命令行交互式分词（屏幕输入、屏幕输出）,如图：   </li>
</ul>
<ul>
<li><blockquote>
<blockquote>
<blockquote>
<p>thu1 = thulac.thulac()<br>Model loaded succeed<br>thu1.run()<br>工信处女干事每月经过下属科室查看口接口器等技术性器件<br>工信处_n 女_a 干事_n 每月_r 经过_p 下属_v 科室_n 查看_v 24_m 口_q 接口器_n 等_u 技术性_n 器件_n   </p>
</blockquote>
</blockquote>
</blockquote>
</li>
</ul>
<p><strong>2.1.3 分词和词性标注模型的使用</strong>  </p>
<p>THULAC需要分词和词性标注模型的支持，用户可以下载THULAC模型Models_v1.zip，并放到THULAC的根目录下即可，或者使用参数——model_dir dir指定模型的位置。</p>
<h3 id="2-词性标记集"><a href="#2-词性标记集" class="headerlink" title="2.词性标记集"></a>2.词性标记集</h3><p><strong>2.2.1 通用标记集：</strong>   </p>
<p>n/名词 np/人名 ns/地名  ni/机构名 nz/其它专名m/数词 q/量词<br>mq/数量词 t/时间词 f/方位词 s/处所词v/动词 a/形容词 d/副词<br>h/前接成分 k/后接成分 i/习语 j/简称 r/代词 c/连词 p/介词<br>u/助词 y/语气助词 e/叹词 o/拟声词 g/语素 w/标点 x/其它  </p>
<p><strong>2.2.2 特殊标记集(适用于lite_v1_2版)</strong>    </p>
<p>需要下载使用：<br>vm/能愿动词  vd/趋向动词  </p>
<h2 id="四、相关论文"><a href="#四、相关论文" class="headerlink" title="四、相关论文"></a>四、相关论文</h2><p>Zhongguo Li, Maosong Sun. Punctuation as Implicit Annotations for Chinese Word Segmentation. Computational Linguistics, vol. 35, no. 4, pp. 505-512, 2009.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/6/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/8/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CNLR</p>
              <p class="site-description motion-element" itemprop="description">语料库、数据集及工具资源和教程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">96</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CNLR</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
