<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="语料库、数据集及工具资源和教程">
<meta property="og:type" content="website">
<meta property="og:title" content="世界语言资源平台">
<meta property="og:url" content="http://yoursite.com/page/7/index.html">
<meta property="og:site_name" content="世界语言资源平台">
<meta property="og:description" content="语料库、数据集及工具资源和教程">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="世界语言资源平台">
<meta name="twitter:description" content="语料库、数据集及工具资源和教程">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/7/"/>





  <title>世界语言资源平台</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">世界语言资源平台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/03/朱述承_内阁大库档案/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/03/朱述承_内阁大库档案/" itemprop="url">内阁大库档案</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-03T15:37:46+05:00">
                2018-06-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：朱述承<br>访问地址：<a href="http://archive.ihp.sinica.edu.tw/mctkm2/index.html" target="_blank" rel="noopener">http://archive.ihp.sinica.edu.tw/mctkm2/index.html</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>内阁大库档案原藏于清宫内阁大库，宣统元年(1909)因大库整修而被移出。清亡后几经转手，一度被卖入同懋增纸厂作还魂纸，最后在首任所长傅斯年先生的奔走下，于民国十八年(1929)自李盛铎手中购入。这批档案有四千多件明代(1368-1644)文书，三十多万件清代(1644-1911)档册，包括内阁收贮的制诏诰敕、题奏本章、朝贡国表章、内阁各厅房处的档案、修书各馆档案、试题、试卷、渖阳旧档等，而以题奏本章佔最大宗。内阁大库档案内容多涉及一般行政事务，而许多案例并不见于会典或则例，是研究制度史的重要材料，同时对于社会史、经济史或法制史等的研究也极具价值。 </p>
<h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>分为“免费使用”和“授权使用”两种使用方式。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/03/杜成玉_大连理工大学情感词汇本体库/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/03/杜成玉_大连理工大学情感词汇本体库/" itemprop="url">大连理工大学情感词汇本体库</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-03T15:37:46+05:00">
                2018-06-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：杜成玉<br>下载地址：<a href="http://ir.dlut.edu.cn/file/emotionontology/2918938192" target="_blank" rel="noopener">http://ir.dlut.edu.cn/file/emotionontology/2918938192</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>中文情感词汇本体库是大连理工大学信息检索研究室在林鸿飞教授的指导下经过全体教研室成员的努力整理和标注的一个中文本体资源。该资源从不同角度描述一个中文词汇或者短语，包括词语词性种类、情感类别、情感强度及极性等信息。中文情感词汇本体的情感分类体系是在国外比较有影响的Ekman的6大类情感分类体系的基础上构建的。在Ekman的基础上，词汇本体加入情感类别“好”对褒义情感进行了更细致的划分。最终词汇本体中的情感共分为7大类21小类。构造该资源的宗旨是在情感计算领域，为中文文本情感分析和倾向性分析提供一个便捷可靠的辅助手段。中文情感词汇本体可以用于解决多类别情感分类的问题，同时也可以用于解决一般的倾向性分析的问题。</p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]卓敏,吴建平.当代青年雾霾情感的可视化分析——以微博用户为例[J].青年研究,2015(04):47-56+95.<br>[2]林明明. 基于三维坐标的多元量化消费情感分类研究[D].辽宁工程技术大学,2015.<br>[3]夏南强,肖琴.微博群体信息及其主观倾向性分析[J].情报科学,2014,32(09):22-29.<br>[4]肖琴. 基于主观倾向性分析的微博群体信息采集研究[D].华中师范大学,2013.<br>[5]王洪伟,郑丽娟,尹裴,史伟.在线评论的情感极性分类研究综述[J].情报科学,2012,30(08):1263-1271+1276.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/03/杜成玉_Antconc3.21语料库分析统计软件/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/03/杜成玉_Antconc3.21语料库分析统计软件/" itemprop="url">Antconc3.21语料库分析统计软件</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-03T15:37:46+05:00">
                2018-06-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：杜成玉<br>下载地址：<a href="http://www.laurenceanthony.net/software/antconc/" target="_blank" rel="noopener">http://www.laurenceanthony.net/software/antconc/</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>该语料库工具是语料库检索软件，具有以下特点：<br>（1）能识别txt，html，htm，xml这四种格式；<br>（2）可以统计出关键词在文本中出现的次数；<br>（3）能列出文本中的词项数和词形，还能将词项数按出现的频率高低排列；<br>（4）文本去重；<br>（5）能够将某个词的搭配按照统计数据从高到低或者反向排序。<br>（6）模糊检索</p>
<h1 id="使用教程："><a href="#使用教程：" class="headerlink" title="使用教程："></a>使用教程：</h1><p>（1）从file菜单的openfile（打开文件）或opendir（打开目录）选择一个或多个要处理的文件，选出来的文件按顺序在主窗户的左边框里显示出来。<br>（2）在左边的按钮条的输入框里输入一个检索词<br>（3）使用右边”SearchWindowSize”（检索窗口大小）的按钮条的增加和减少按钮来选择在检索词两边显示的字符数。<br>（4）按“Start”（开始）键开始产生索引行的检索结果。检索过程中可按“stop”(停止）键随时停止检索。<br>（5）使用KwicSort（上下文关键词分类）下的按钮条选择一个目标词来重排索引行,0是检索词，1L，2L是检索词左边的第一，第二个单词，1R，2R是检索词右边第一，第二个单词。<br>（6）按“Sort”（分类）键开始分类处理。<br>（7）将指针移到其中一行索引行的突出的检索词之上，系统默认为蓝色。指针会转变成一个手形的图标。点击突出的检索词，可以看到检索词在原文中出现的情况。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/卢梦依_SVHN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/卢梦依_SVHN/" itemprop="url">SVHN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T21:23:00+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>SVHN数据来源于 Google 街景视图中房屋信息，它是一个真实世界的图像数据集，用于开发机器学习和对象识别算法，对数据预处理和格式化的要求最低。它跟MNIST相似，但是包含更多数量级的标签数据（超过60万个数字图像），并且来源更加多样，用来识别自然场景图像中的数字。</p>
<h1 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h1><p><a href="http://ufldl.stanford.edu/housenumbers/" target="_blank" rel="noopener">http://ufldl.stanford.edu/housenumbers/</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Shuai Li,Wenfeng Song,Hong Qin,Aimin Hao. Deep variance network: An iterative, improved CNN framework for unbalanced training datasets[J]. Pattern Recognition,2018,81.<br>[2]Andrey V. Savchenko,Natalya S. Belova. Unconstrained face identification using maximum likelihood of distances between deep off-the-shelf features[J]. Expert Systems With Applications,2018,108.<br>[3]Alistair Peter McGeorge. An Urban Partnership for Inner Sydney Social Inclusion, Health and Well-being[J]. International Journal of Integrated Care,2017,17(3).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/卢梦依_Labeled Faces in the Wild数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/卢梦依_Labeled Faces in the Wild数据集/" itemprop="url">Labeled Faces in the Wild数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T21:19:00+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>该数据集是用于研究无约束面部识别问题的面部照片数据库。数据集包含从网络收集的13000多张图像。每张脸都贴上了所画的人的名字，图片中的1680人在数据集中有两个或更多不同的照片。</p>
<h1 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h1><p><a href="http://vis-www.cs.umass.edu/lfw/" target="_blank" rel="noopener">http://vis-www.cs.umass.edu/lfw/</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]David Rim,Md Kamrul Hasan,Fannie Puech,Christopher J. Pal. Learning from weakly labeled faces and video in the wild[J]. Pattern Recognition,2015,48(3).<br>[2]Davide Lombardo. An explicit open image theorem for products of elliptic curves[J]. Journal of Number Theory,2016,168.<br>[3]M. Nazir,A. Majid-Mirza,S. Ali-Khan. PSO-GA Based Optimized Feature Selection Using Facial and Clothing Information for Gender Classification[J]. Journal of Applied Research and Technology,2014,12(1).<br>[4]Jiang-Jing Lv,Cheng Cheng,Guo-Dong Tian,Xiang-Dong Zhou,Xi Zhou. Landmark perturbation-based data augmentation for unconstrained face recognition[J]. Signal Processing: Image Communication,2016,47.<br>[5]Blondin , John M.,Kallman , Timothy R.,Pereyra , Nicolas Antonio. Hydrodynamic Models of Line-Driven Accretion Disk Winds in Cataclysmic Variables[J]. Revista Mexicana de Astronomía y Astrofísica : Universidad Nacional Autónoma de México. Instituto de Astronomía,2001(11).<br>[6]Ian W. Roxburgh. Challenges to Theories of the Structure of Moderate-Mass Stars[M].Springer Berlin Heidelberg:2005-07-19.<br>[7]Andrey V. Savchenko,Natalya S. Belova. Unconstrained face identification using maximum likelihood of distances between deep off-the-shelf features[J]. Expert Systems With Applications,2018,108. </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/卢梦依_LSUN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/卢梦依_LSUN/" itemprop="url">LSUN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T21:14:00+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：卢梦依</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>国外的PASCAL VOC和ImageNet ILSVRC比赛使用的数据集，数据领域包括卧室、冰箱、教师、厨房、起居室、酒店等多个主题。</p>
<h1 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h1><p><a href="http://lsun.cs.princeton.edu/2017/" target="_blank" rel="noopener">http://lsun.cs.princeton.edu/2017/</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]Blondin , John M.,Kallman , Timothy R.,Pereyra , Nicolas Antonio. Hydrodynamic Models of Line-Driven Accretion Disk Winds in Cataclysmic Variables[J]. Revista Mexicana de Astronomía y Astrofísica : Universidad Nacional Autónoma de México. Instituto de Astronomía,2001(11).<br>[2]Ian W. Roxburgh. Challenges to Theories of the Structure of Moderate-Mass Stars[M].Springer Berlin Heidelberg:2005-07-19.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/刘唯_Labelme/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/刘唯_Labelme/" itemprop="url">Labelme</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T20:10:00+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p> Labelme是斯坦福一个学生的母亲利用休息时间帮儿子做的标注，后来便发展为一个数据集。该数据集的主要特点包括<br>（1）专门为物体分类识别设计，而非仅仅是实例识别<br>（2）专门为学习嵌入在一个场景中的对象而设计<br>（3）高质量的像素级别标注，包括多边形框（polygons）和背景标注（segmentation masks）<br>（4）物体类别多样性大，每种物体的差异性，多样性也大。<br>（5）所有图像都是自己通过相机拍摄，而非copy<br>（6）公开的，免费的</p>
<h1 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h1><p>图像如下图所示，需要通过matlab来下载，一种奇特的下载方式。<br>下载链接为<a href="http://labelme2.csail.mit.edu/Release3.0/index.php" target="_blank" rel="noopener">http://labelme2.csail.mit.edu/Release3.0/index.php</a><br><img src="https://i.loli.net/2018/05/24/5b06ac87bd99e.jpg" alt=""></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]吉江燕,方挺.基于Labelme的参考图像的手工分割[J].微型机与应用,2015,34(17):49-51+56.<br>[2]Bryan C. Russell,  Antonio Torralba,  Kevin P. Murphy,  William T. Freeman.International Journal of Computer Vision[J].LabelMe: A Database and Web-Based Tool for Image Annotation.<br>[3]</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/刘唯_Open Image/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/刘唯_Open Image/" itemprop="url">Open Image</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T20:10:00+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘唯</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>过去几年机器学习的发展使得计算机视觉有了快速的进步，系统能够自动描述图片，对共享的图片创造自然语言回应。其中大部分的进展都可归因于 ImageNet 、COCO这样的数据集的公开使用。谷歌作为一家伟大的公司，自然也要做出些表示，于是乎就有了Open Image。</p>
<p>Open Image是一个包含~900万张图像URL的数据集，里面的图片通过标签注释被分为6000多类。该数据集中的标签要比ImageNet（1000类）包含更真实生活的实体存在，它足够让我们从头开始训练深度神经网络。</p>
<p>谷歌出品，必属精品！唯一不足的可能就是它只是提供图片URL，使用起来可能不如直接提供图片方便。</p>
<h1 id="数据集大小"><a href="#数据集大小" class="headerlink" title="数据集大小"></a>数据集大小</h1><p>~1.5GB（不包括图片）</p>
<h1 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h1><p><a href="https://github.com/openimages/dataset" target="_blank" rel="noopener">https://github.com/openimages/dataset</a></p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1]M. Hu&amp;scaron,ek. Open images of orderable spaces[J]. proc,1983,88(4).<br>[2]Davide Lombardo. An explicit open image theorem for products of elliptic curves[J]. Journal of Number Theory,2016,168.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/刘晓_百度BROAD-Video Highlights视频精彩片段数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/刘晓_百度BROAD-Video Highlights视频精彩片段数据集/" itemprop="url">百度BROAD-Video Highlights视频精彩片段数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T10:31:58+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓</p>
<p>地址：<a href="http://ai.baidu.com/broad" target="_blank" rel="noopener">http://ai.baidu.com/broad</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>该数据集（下文中简称为BROAD-VH数据集）在介绍中将其定义为视频精彩片段提取任务。具体而言，就是提取视频中可能包含精彩片段的时间区域，而不需要对精彩片段的类别进行分类。该任务实际上与我之前介绍过的temporal action proposal 任务（相关介绍和算法可以参考<a href="https://zhuanlan.zhihu.com/p/31501316" target="_blank" rel="noopener">Temporal Action Detection (时序动作检测)方向2017年会议论文整理）</a>是完全相同的。</p>
<h1 id="视频及数据信息"><a href="#视频及数据信息" class="headerlink" title="视频及数据信息"></a>视频及数据信息</h1><p>BROAD-VH数据集主要来源于爱奇艺视频。视频类型为综艺节目，目前包括1500个长视频，视频总时长约1200小时。该数据集的视频时长分布图如下图所示（长度单位为帧）。按照总帧数和总时长的比例，估计采样的fps大概为1.5吧，算是比较低的采样频率了。</p>
<p>训练/验证/测试集的视频数量划分为1262/120/117。</p>
<p>该数据集通过爱奇艺网页link的方式提供了原始视频（即需要爬虫下载或手动下载），此外还提供了提取好的image feature和audio feature。这两种特征均在视频的每一帧上提取，维度均为2048。比如对于一个长度为1000帧的视频，image和audio特征矩阵的大小均为1000*2048。</p>
<h1 id="标签信息及分布"><a href="#标签信息及分布" class="headerlink" title="标签信息及分布"></a>标签信息及分布</h1><p>该数据集中一共有18000个精彩片段的时序标注，平均一个视频有12个时序标注。这些精彩片段的总时长占1500个小时中的750个小时，即有一半左右的视频时长被标注为了精彩片段。</p>
<p>我对训练集的标签信息进行了分析，分析的主要内容为精彩片段时长的分布，分布直方图如下图所示。</p>
<p>可以看出，大部分精彩片段的长度都在30-300帧的范围。</p>
<h1 id="测评方式"><a href="#测评方式" class="headerlink" title="测评方式"></a>测评方式</h1><p>测评方式部分与通常temporal action proposal任务中不同，并没有使用average recall (平均召回率），而是同detection任务一样使用了mAP，此处将所有highlights片段都看作为了一个动作类别。比较有趣的是，BROAD-VH基本上直接使用了ActivityNet Challenge的detection任务测评代码（略有改动）。</p>
<h1 id="简要分析"><a href="#简要分析" class="headerlink" title="简要分析"></a>简要分析</h1><p>根据上面的介绍以及分析内容，可以对这个数据集进行一些简单的评价：</p>
<ul>
<li>单个视频的时长可能很长（小时级别），单个视频中包含的精彩片段也比较多，这点与THUMOS数据集很像，而与单个视频时长短且包含片段少的ActivityNet数据集差异大</li>
<li>数据集标注的格式，测评代码等方面应该是直接参考的ActivityNet 数据集做的</li>
<li>数据的规模还是比较大的，从时长方面看比ActivityNet要长（ActivityNet时长大约为700小时）</li>
<li>视频的来源均为综艺视频，这点表明这个数据集的来源多样性比较单一</li>
<li>提供特征，其目的应该是节省研究者的计算开销。估计1500小时的视频，提取一遍特需要很长的时间。。根本没法玩。所以有现成的特征挺不错的。</li>
</ul>
<h1 id="简单的尝试"><a href="#简单的尝试" class="headerlink" title="简单的尝试"></a>简单的尝试</h1><p>下完数据集我就先跑了一个最简单的baseline方法，即activitynet challenge 2017 proposal task中的baseline：uniform random 方法。代码主要参考了activitynet官方提供的代码：<a href="https://link.zhihu.com/?target=https%3A//github.com/activitynet/ActivityNet/blob/master/Notebooks/ActivityNet-Release1.3.Proposals.ipynb" target="_blank" rel="noopener">activitynet/proposals</a></p>
<p>简单而言，就是在视频随机的位置产生随机长度的proposals，并给予随机的confidence score。在验证集中，对于每个视频我生成了200个proposals，得到的mAP大概在0.027 左右。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/刘晓_AVA（atomic visual actions）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/刘晓_AVA（atomic visual actions）/" itemprop="url">AVA（atomic visual actions）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T10:31:58+05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓</p>
<p>地址：<a href="http://research.google.com/ava/" target="_blank" rel="noopener">http://research.google.com/ava/</a>  </p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>教机器理解视频中的人的行为是计算机视觉中的一个基本研究问题，谷歌blog发布了一个堪比“视频版”ImageNet的数据集-AVA（A Finely Labeled Video Dataset for Human Action Understanding ），旨在教机器理解人的活动。 该数据集以人类为中心进行标注，包含80类动作的 57600 个视频片段，有助于人类行为识别系统的研究。
　　  </p>
<p>教机器理解视频中的人的行为是计算机视觉中的一个基本研究问题，对个人视频搜索和发现、运动分析和手势界面等应用十分重要。尽管在过去的几年里，对图像进行分类和在图像中寻找目标对象方面取得了令人兴奋的突破，但识别人类的动作仍然是一个巨大的挑战。这是因为动作的定义比视频中的对象的定义要差，因此很难构造一个精细标记的动作视频数据集。许多基准数据集，例如 UCF101、activitynet 和DeepMind 的 Kinetics，都是采用图像分类的标记方案，在数据集中为每个视频或视频片段分配一个标签，而没有数据集能用于包含多个可能执行不同动作的人的复杂场景。</p>
<p>谷歌上周发布一个新的电影片段数据集，旨在教机器理解人的活动。这个数据集被称为 AVA（atomic visual action），这些视频对人类来说并不是很特别的东西——仅仅是 YouTube 上人们喝水、做饭等等的3秒钟视频片段。但每段视频都与一个文件捆绑在一起，这个文件勾勒了机器学习算法应该观察的人，描述他们的姿势，以及他们是否正在与另一个人或物进行互动。就像指着一只狗狗给一个小孩看，并教他说“狗！”，这个数据集是这类场景的数字版本。</p>
<h1 id="数据集特点"><a href="#数据集特点" class="headerlink" title="数据集特点"></a>数据集特点</h1><p>相比其他的动作数据集，AVA数据集有以下这些特点：</p>
<p><strong>以人为中心进行标注</strong>：每个动作标签都基于人物本身，而不是一段视频或者剪辑片段。因此，我们能够为不同动作中的各类人加上不同的标签，这一点非常常见。</p>
<p><strong>原子级视觉动作</strong>：我们对需要标注的动作进行了合理的时间限制（3秒钟），以确保动作符合人的生理机能，同时有明显的视觉特征。</p>
<p><strong>真实视频作为视觉材料</strong>：我们使用不同题材和国家的电影作为AVA的标注材料，进而确保数据库中包含各类型的人类行为。  </p>
<p><img src="http://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/wc7YNPm3YxVcUeMuMHYKbUFVF2ibGkUgw490HgjQfU5kN8NVYbPBNbJgZR9pJ1BN8Mc5iaPIdAicKLtwmsONEDvYg/0?wx_fmt=gif" alt="">  </p>
<p>视频来源中的3秒视觉片段标签，用方框标注出每个动作素材（为确保清晰，每个例子中只出现了一个框。）</p>
<p>为创建 AVA，我们首先从 YouTube 上收集了大量多样化的数据，主要集中在「电影」和「电视」类别，选择来自不同国家的专业演员。我们对每个视频抽取 15 分钟进行分析，并统一将 15 分钟视频分割成 300 个非重叠的 3 秒片段。采样遵循保持动作序列的时间顺序这一策略。</p>
<p>接下来，我们为每个 3 秒片段中间帧的人物手动标注边界框。对标注框中的每个人，标注者从预制的原子动作词汇表（80 个类别）中选择适当数量的标签来描述人物动作。这些动作可分为三组：姿势／移动动作、人-物互动和人-人互动。我们对执行动作的所有人进行了全部标注，因此 AVA 的标签频率遵循长尾分布，如下图所示。 </p>
<p><img src="http://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxVcUeMuMHYKbUFVF2ibGkUgwH3wDtoVY30WySELT8FopyRb1C7X31BoDib7OKBmKVDa2CDlx8HUtkQQ/0?wx_fmt=png" alt="">  </p>
<p>AVA 的原子动作标签分布。x 轴所示标签只是词汇表的一部分。</p>
<p>AVA 的独特设计使我们能够获取其他现有数据集中所没有的一些有趣数据。例如，给出大量至少带有两个标签的人物，我们可以判断动作标签的共现模式（co-occurrence pattern）。下图显示 AVA 中共现频率最高的动作对及其共现得分。我们确定的期望模式有：人们边唱歌边弹奏乐器、拥吻等。<br> <img src="http://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxVcUeMuMHYKbUFVF2ibGkUgwsojISBHw3F5O3pGhnDIDB6MNXe72falLbIWcbicgCdQhEIULVlSmZ1A/0?wx_fmt=png" alt=""><br>AVA 中共现频率最高的动作对。</p>
<p>为评估基于 AVA 数据集的人类动作识别系统的高效性，我们使用一个现有的基线深度学习模型在规模稍小一些的 JHMDB dataset 上取得了具备高竞争性的性能。由于存在可变焦距、背景杂乱、摄影和外观的不同情况，该模型在 JHMDB dataset 上的性能与在 AVA 上准确识别动作的性能（18.4% mAP）相比稍差。这表明，未来 AVA 可以作为开发和评估新的动作识别架构和算法的测试平台。  </p>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>[1] Chunhui Gu, Chen Sun, David A. Ross, Carl Vondrick, Caroline Pantofaru, Yeqing Li, Sudheendra Vijayanarasimhan, George Toderici, Susanna Ricco, Rahul Sukthankar, Cordelia Schmid, Jitendra Malik, AVA: A Video Dataset of Spatio-temporally Localized Atomic Visual Actions, 2017</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/6/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><a class="extend next" rel="next" href="/page/8/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CNLR</p>
              <p class="site-description motion-element" itemprop="description">语料库、数据集及工具资源和教程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">214</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CNLR</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
