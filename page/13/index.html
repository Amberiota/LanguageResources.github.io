<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="语料库、数据集及工具资源和教程">
<meta property="og:type" content="website">
<meta property="og:title" content="世界语言资源平台">
<meta property="og:url" content="http://yoursite.com/page/13/index.html">
<meta property="og:site_name" content="世界语言资源平台">
<meta property="og:description" content="语料库、数据集及工具资源和教程">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="世界语言资源平台">
<meta name="twitter:description" content="语料库、数据集及工具资源和教程">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/13/"/>





  <title>世界语言资源平台</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">世界语言资源平台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/01/李华勇_腾讯文智自然语言处理NLP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/01/李华勇_腾讯文智自然语言处理NLP/" itemprop="url">腾讯文智自然语言处理NLP</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-01T17:37:46+05:00">
                2018-05-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="https://cloud.tencent.com/product/nlp#features" target="_blank" rel="noopener">https://cloud.tencent.com/product/nlp#features</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>腾讯文智自然语言处理（Natural Language Processing）基于并行计算、分布式爬虫系统，结合独特的语义分析技术，一站满足NLP、转码、抽取、数据抓取等需求。基于文智API可实现搜索、推荐、舆情、挖掘等功能。文智同时支持定制化语义分析方案。</p>
<h1 id="功能说明"><a href="#功能说明" class="headerlink" title="功能说明"></a>功能说明</h1><h2 id="词法分析"><a href="#词法分析" class="headerlink" title="词法分析"></a>词法分析</h2><p>提供智能分词、词性标注、命名实体识别功能。用户无需担心诸如新词发现、歧义消除、调用性能等词法分析难题。</p>
<h2 id="句法分析"><a href="#句法分析" class="headerlink" title="句法分析"></a>句法分析</h2><p>支持短串纠错、同义词扩展。依存文法，长文本纠错也即将推出。纠错同义词可实现定制化服务，打造专属词库。</p>
<h2 id="篇章分析"><a href="#篇章分析" class="headerlink" title="篇章分析"></a>篇章分析</h2><p>支持短文关键词提取、情感分析、自动摘要、分类，以及批量文本的聚类分析。在舆情监控、话题监督、口碑分析等商业分析领域有非常重要的应用价值。</p>
<h2 id="下载抽取转码"><a href="#下载抽取转码" class="headerlink" title="下载抽取转码"></a>下载抽取转码</h2><p>帮助用户一站式实现网页抓取、转码、结构化抽取功能。分布式爬虫系统可实现自动路由、url作弊识别、智能主题抓取等功能。</p>
<h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><p>腾讯文智自然语言处理（Natural Language Processing）基于并行计算、分布式爬虫系统，结合独特的语义分析技术，一站满足NLP、转码、抽取、数据抓取等需求。基于文智API可实现搜索、推荐、舆情、挖掘等功能。文智同时支持定制化语义分析方案。</p>
<p>腾讯云文智中文语义平台以SDK模块的方式提供服务，多种编程语言都可以轻松使用。在正式使用之前，您需要首先在腾讯云上注册文智账号。</p>
<h2 id="公共参数"><a href="#公共参数" class="headerlink" title="公共参数"></a>公共参数</h2><p>公共参数是用于标识用户和接口鉴权的参数, 每次请求均需要携带这些参数, 才能正常发起请求<br><img src="https://i.loli.net/2018/05/06/5aee6a5359ef8.jpg" alt=""></p>
<h2 id="调用demo"><a href="#调用demo" class="headerlink" title="调用demo"></a>调用demo</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line">error_reporting(E_ALL ^ E_NOTICE);</span><br><span class="line"><span class="keyword">require_once</span> <span class="string">'./src/QcloudApi/QcloudApi.php'</span>;</span><br><span class="line"></span><br><span class="line">$config = <span class="keyword">array</span>(<span class="string">'SecretId'</span>        =&gt; <span class="string">'你在腾讯云上的SecretId'</span>,</span><br><span class="line">             <span class="string">'SecretKey'</span>       =&gt; <span class="string">'你在腾讯云上的SecretKey'</span>,</span><br><span class="line">             <span class="string">'RequestMethod'</span>  =&gt; <span class="string">'POST'</span>,</span><br><span class="line">             <span class="string">'DefaultRegion'</span>    =&gt; <span class="string">'gz'</span>);</span><br><span class="line"></span><br><span class="line">$wenzhi = QcloudApi::load(QcloudApi::MODULE_WENZHI, $config);</span><br><span class="line"></span><br><span class="line">$package = <span class="keyword">array</span>(<span class="string">"content"</span>=&gt;<span class="string">"李亚鹏挺王菲：加油！孩儿他娘。"</span>);</span><br><span class="line"></span><br><span class="line">$a = $wenzhi-&gt;TextSentiment($package);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> ($a === <span class="keyword">false</span>) &#123;</span><br><span class="line">    $error = $wenzhi-&gt;getError();</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"Error code:"</span> . $error-&gt;getCode() . <span class="string">".n"</span>;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"message:"</span> . $error-&gt;getMessage() . <span class="string">".n"</span>;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"ext:"</span> . var_export($error-&gt;getExt(), <span class="keyword">true</span>) . <span class="string">".n"</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    var_dump($a);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">"nRequest :"</span> . $wenzhi-&gt;getLastRequest();</span><br><span class="line"><span class="keyword">echo</span> <span class="string">"nResponse :"</span> . $wenzhi-&gt;getLastResponse();</span><br><span class="line"><span class="keyword">echo</span> <span class="string">"n"</span>;</span><br></pre></td></tr></table></figure>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p>暂无</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/01/李华勇_中文文本分类数据集THUCNews/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/01/李华勇_中文文本分类数据集THUCNews/" itemprop="url">中文文本分类数据集THUCNews</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-01T17:37:46+05:00">
                2018-05-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="http://thuctc.thunlp.org/" target="_blank" rel="noopener">http://thuctc.thunlp.org/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>THUCNews是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档（2.19 GB），均为UTF-8纯文本格式。</p>
<p>我们在原始新浪新闻分类体系的基础上，重新整合划分出14个候选分类类别：财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐。</p>
<p>使用THUCTC工具包在此数据集上进行评测，准确率可以达到88.6%。</p>
<h1 id="数据集构成"><a href="#数据集构成" class="headerlink" title="数据集构成"></a>数据集构成</h1><ul>
<li>THUCTC_java_v1_run.zip<blockquote>
<p>THUCTC可执行的jar包(Java版)    1.2MB    2016-01-25</p>
</blockquote>
</li>
<li>THUCTC_java_v1.zip<blockquote>
<p>THUCTC可导入的jar包，包括源代码(Java版)    1.1MB    2016-01-25</p>
</blockquote>
</li>
<li>THUCNews.zip<blockquote>
<p>THUCNews中文文本数据集    1.56GB    2016-01-25</p>
</blockquote>
</li>
<li>THUCNews_model.zip<blockquote>
<p>使用THUCNews中文文本数据集训练出来的THUCTC模型，可直接使用；参数为-d1 0.8 -d2 0.2 -f 20000    2.6MB    2016-12-18</p>
</blockquote>
<h1 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h1><a href="http://thuctc.thunlp.org/message" target="_blank" rel="noopener">http://thuctc.thunlp.org/message</a><h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1></li>
<li><p>Jingyang Li, Maosong Sun. Scalable Term Selection for Text Categorization. Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), Prague, Czech Republic, 2007, pp. 774-782.</p>
</li>
<li><p>Jingyang Li, Maosong Sun, Xian Zhang. A Comparison and Semi-Quantitative Analysis of Words and Character-Bigrams as Features in Chinese Text Categorization. Proc. of the 2006 Joint Conference of the International Committee on Computational Linguistics and the Association for Computational Linguistics (COLING-ACL 2006), Sydney, Australia, 2006, pp. 545-552.</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/01/李华勇_THUCTC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/01/李华勇_THUCTC/" itemprop="url">THUCTC</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-01T17:37:46+05:00">
                2018-05-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<p>地址：<a href="http://thuctc.thunlp.org/" target="_blank" rel="noopener">http://thuctc.thunlp.org/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>THUCTC(THU Chinese Text Classification)是由清华大学自然语言处理实验室推出的中文文本分类工具包，能够自动高效地实现用户自定义的文本分类语料的训练、评测、分类功能。</p>
<p>文本分类通常包括特征选取、特征降维、分类模型学习三个步骤。</p>
<p>如何选取合适的文本特征并进行降维，是中文文本分类的挑战性问题。我组根据多年在中文文本分类的研究经验，在THUCTC中选取二字串bigram作为特征单元，特征降维方法为Chi-square，权重计算方法为tfidf，分类模型使用的是LibSVM或LibLinear。</p>
<p>THUCTC对于开放领域的长文本具有良好的普适性，不依赖于任何中文分词工具的性能，具有准确率高、测试速度快的优点。</p>
<h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p>我们提供了两种方式运行工具包：</p>
<ol>
<li><p>使用java开发工具，例如eclipse，将包括lib\THUCTC_java_v1.jar在内的lib文件夹下的包导入自己的工程中，仿照Demo.java程序调用函数即可。</p>
</li>
<li><p>使用根目录下的THUCTC_java_v1_run.jar运行工具包。</p>
<blockquote>
<p>使用命令 java -jar THUCTC_java_v1_run.jar + 程序参数</p>
</blockquote>
</li>
</ol>
<h2 id="运行参数"><a href="#运行参数" class="headerlink" title="运行参数"></a>运行参数</h2><ul>
<li>[-c CATEGORY_LIST_FILE_PATH] 从文件中读入类别信息。该文件中每行包含且仅包含一个类别名称。</li>
<li>[-train TRAIN_PATH] 进行训练，并设置训练语料文件夹路径。该文件夹下每个子文件夹的名称都对应一个类别名称，内含属于该类别的训练语料。若不设置，则不进行训练。</li>
<li>[-test EVAL_PATH] 进行评测，并设置评测语料文件夹路径。该文件夹下每个子文件夹的名称都对应一个类别名称，内含属于该类别的评测语料。若不设置，则不进行评测。也可以使用-eval。</li>
<li>[-classify FILE_PATH] 对一个文件进行分类。</li>
<li>[-n topN] 设置返回候选分类数，按得分大小排序。默认为1，即只返回最可能的分类。</li>
<li>[-svm libsvm or liblinear] 选择使用libsvm还是liblinear进行训练和测试，默认使用liblinear。</li>
<li>[-l LOAD_MODEL_PATH] 设置读取模型路径。</li>
<li>[-s SAVE_MODEL_PATH] 设置保存模型路径。</li>
<li>[-f FEATURE_SIZE] 设置保留特征数目，默认为5000。</li>
<li>[-d1 RATIO] 设置训练集占总文件数比例，默认为0.8。</li>
<li>[-d2 RATIO] 设置测试集占总文件数比例，默认为0.2。</li>
<li>[-e ENCODING] 设置训练及测试文件编码，默认为UTF-8。</li>
<li>[-filter SUFFIX] 设置文件后缀过滤。例如设置“-filter .txt”，则训练和测试时仅考虑文件名后缀为.txt的文件。<h1 id="样例程序"><a href="#样例程序" class="headerlink" title="样例程序"></a>样例程序</h1>我们随工具包提供了一个调用THUCTC的样例代码Demo.java，其中实现了三种功能：</li>
</ul>
<ol>
<li>对文本进行训练并测试(runTrainAndTest)；</li>
<li>读取已经训练好的模型，对文件进行分类(runLoadModelAndUse)；</li>
<li>按照自己的想法添加训练文件，训练模型(AddFilesManuallyAndTrain)；</li>
</ol>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><ul>
<li><p>Jingyang Li, Maosong Sun. Scalable Term Selection for Text Categorization. Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), Prague, Czech Republic, 2007, pp. 774-782.</p>
</li>
<li><p>Jingyang Li, Maosong Sun, Xian Zhang. A Comparison and Semi-Quantitative Analysis of Words and Character-Bigrams as Features in Chinese Text Categorization. Proc. of the 2006 Joint Conference of the International Committee on Computational Linguistics and the Association for Computational Linguistics (COLING-ACL 2006), Sydney, Australia, 2006, pp. 545-552.</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/01/李华勇_BosonNLP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/01/李华勇_BosonNLP/" itemprop="url">BosonNLP</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-01T17:37:46+05:00">
                2018-05-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：李华勇</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>玻森中文语义开放平台提供使用简单、功能强大、性能可靠的中文自然语言分析云服务。</p>
<p>互联网时代信息无处不在，我们日常所接触的大量信息例如微博、社交媒体网站的帖子、消费者点评、新闻、销售人员的拜访记录以及可以转换成文本的语音内容，这些都是常见的非结构化数据来源。</p>
<p>根据2011年IDC的调查，非结构化数据将占未来十年所创造数据的90%。作为一个尚未得到充分开发的信息源，非结构化数据分析可以揭示之前很难或无法确定的重要相互关系。</p>
<p>非结构化数据分析能够揭示潜藏在文本当中的趋势和关联，为商业决策、研究行业趋势和热点内容分析提供有力支持。</p>
<p>玻森团队致力于打造最出色的中文语义分析技术，通过自主研发的中文分词、句法分析、语义联想和实体识别技术，结合海量行业语料的不断积累，为企业和广大开发者提供简单、强大、可靠的中文语义分析云端API。</p>
<h1 id="功能说明"><a href="#功能说明" class="headerlink" title="功能说明"></a>功能说明</h1><h2 id="情感分析Sentiment-Analysis"><a href="#情感分析Sentiment-Analysis" class="headerlink" title="情感分析Sentiment Analysis"></a>情感分析Sentiment Analysis</h2><p>情感分析指的是对文本中情感的倾向性和评价对象进行提取的过程。</p>
<p>玻森NLP情感引擎提供行业领先的篇章级情感分析。基于上百万条社交网络平衡语料和数十万条新闻平衡语料的机器学习模型，结合自主开发的半监督学习技术，正负面情感分析准确度达到80%~85% 。经过行业数据标注学习后准确率可达85%~90%。</p>
<h2 id="信息分类Classification"><a href="#信息分类Classification" class="headerlink" title="信息分类Classification"></a>信息分类Classification</h2><p>文本信息分类将文本按照预设的分类体系进行自动区分。</p>
<p>玻森提供定制的文本分类API服务，有着广泛的商业应用前景。</p>
<p>例如，通过社交网络挖掘商业情报和潜在销售机会，企业内文本数据分析，海量数据筛选，资讯分类和自动标签预测等。</p>
<p>基于玻森自主研发的语义联想、句法分析等技术，通过半监督学习引擎的训练，只需要进行少量的代表性数据标注，就可以达到商用级别的预测准确率。</p>
<h2 id="实体识别Named-Entity-Recognition"><a href="#实体识别Named-Entity-Recognition" class="headerlink" title="实体识别Named Entity Recognition"></a>实体识别Named Entity Recognition</h2><p>实体识别用于从文本中发现有意义的信息，例如人名、公司名、产品名、时间、地点等。 实体识别是语义分析中的重要的基础，是情感分析、机器翻译、语义理解等任务中的重要步骤。</p>
<p>BosonNLP实体识别引擎基于自主研发的结构化信息抽取算法，F1分数达到81%，相比于StanfordNER高出7个百分点。通过对行业语料的进一步学习，可以达到更高的准确率。</p>
<h2 id="典型意见Opinion-Extraction"><a href="#典型意见Opinion-Extraction" class="headerlink" title="典型意见Opinion Extraction"></a>典型意见Opinion Extraction</h2><p>典型意见引擎将消费者意见进行单句级别的语义聚合，提取出有代表性的意见。可用于消费者调研、电商点评分析和社会热点事件的意见整理。</p>
<p>基于语义的分析引擎在准确率上有较大的突破，能将含义接近但表述不同的意见聚合在一起，并可通过参数调节聚类的大小获得更好的效果，与人工整理相比更加快速、准确 。</p>
<h2 id="文本聚类Clustering"><a href="#文本聚类Clustering" class="headerlink" title="文本聚类Clustering"></a>文本聚类Clustering</h2><p>相似文本聚类指的是机器自动对给定的文本进行话题聚类，将语义上相似的内容归为一类，有助于海量文档、资讯的整理，和话题级别的统计分析。</p>
<p>玻森自主研发的文本聚类算法：</p>
<p>一方面加入了对语义的扩展，保证同一个意见的不同表述可以被归纳在一起。</p>
<p>另一方面又避免了传统的K-means等算法需要预先设定聚类总数的困难，基于数据的分布自动选择合适的阈值。</p>
<h2 id="关键词提取Keyword-Extraction"><a href="#关键词提取Keyword-Extraction" class="headerlink" title="关键词提取Keyword Extraction"></a>关键词提取Keyword Extraction</h2><p>关键词提取引擎从一篇或多篇文本中提取出有代表性的关键词。</p>
<p>玻森的关键词提取技术综合考虑词语在文本中的频率，和词语在千万级背景数据中的频率，选择出最具有代表性的关键词并给出相应权重。</p>
<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p>BosonNLP引擎以REST API的方式提供服务，任何编程语言都可以轻松使用。</p>
<p>在正式开始前，您需要首先 注册玻森账号。完成后，您将在 控制台 的底部看到您的API Token （密钥），该密钥将用于身份验证。</p>
<p>这里将以一个简单的情感分析任务为例，介绍BosonNLP的使用。</p>
<p>我们从 cURL 开始。</p>
<p>打开一个命令行窗口并输入以下命令（不包含 $ ），将 YOUR_API_TOKEN 替换为您注册后获得的API密钥。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ curl http://api.bosonnlp.com/sentiment/analysis \</span><br><span class="line">    -X POST -H <span class="string">"Content-Type: application/json"</span> -H <span class="string">"X-Token: YOUR_API_TOKEN"</span> \</span><br><span class="line">    --data <span class="string">"[\"自由思考比畅所欲言更重要。\", \"公司最大的困扰，就是无法测量每个员工的贡献度。\"]"</span></span><br><span class="line"></span><br><span class="line">[[<span class="number">0.9730778829163206</span>, <span class="number">0.026922117083679472</span>], [<span class="number">0.4668568874082243</span>, <span class="number">0.5331431125917757</span>]]</span><br></pre></td></tr></table></figure></p>
<p>以上这段代码使用了玻森的 情感分析 引擎，传入了两段短文本内容进行分析。返回的内容为 json 格式，情感分析结果分别为 非负面 和 负面 概率组成的列表。</p>
<h2 id="HTTP-Header详解"><a href="#HTTP-Header详解" class="headerlink" title="HTTP Header详解"></a>HTTP Header详解</h2><p>在 cURL 命令中加入 -i 参数，会看到类似下面的结果。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ curl http://api.bosonnlp.com/sentiment/analysis -i \</span><br><span class="line">    -X POST -H <span class="string">"Content-Type: application/json"</span> -H <span class="string">"X-Token: YOUR_API_TOKEN"</span>\</span><br><span class="line">    --data <span class="string">"[\"自由思考比畅所欲言更重要。\", \"公司最大的困扰，就是无法测量每个员工的贡献度。\"]"</span></span><br><span class="line"></span><br><span class="line">HTTP/<span class="number">1.1</span> <span class="number">200</span> OK</span><br><span class="line">Date: Sun, <span class="number">04</span> May <span class="number">2014</span> <span class="number">08</span>:<span class="number">21</span>:<span class="number">01</span> GMT</span><br><span class="line">Content-Type: application/json</span><br><span class="line">Content-Length: <span class="number">6</span></span><br><span class="line">Connection: keep-alive</span><br><span class="line">X-Rate-Limit-Limit: <span class="number">100</span></span><br><span class="line">X-Rate-Limit-Remaining: <span class="number">97</span></span><br><span class="line">X-Rate-Limit-Reset: <span class="number">1399192200</span></span><br><span class="line">X-Count-Limit-Limit: <span class="number">500</span></span><br><span class="line">X-Count-Limit-Remaining: <span class="number">480</span></span><br><span class="line">X-Count-Limit-Reset: <span class="number">1399219200</span></span><br><span class="line">Server: nginx/<span class="number">1.5</span><span class="number">.11</span></span><br><span class="line">X-Request-Id: <span class="number">0</span>ae45f04<span class="number">-701</span>d<span class="number">-48</span>d8-a84e-d08f18e489ef</span><br><span class="line"></span><br><span class="line">[[<span class="number">0.9730778829163206</span>, <span class="number">0.026922117083679472</span>], [<span class="number">0.4668568874082243</span>, <span class="number">0.5331431125917757</span>]]</span><br></pre></td></tr></table></figure></p>
<p>在返回的 HTTP Header 当中，有一些很有趣的内容。和你想的一样，BosonNLP 的返回内容为 JSON 格式，因此 Content-Type 是 application/json 。</p>
<p>X- 开头的是自定义HTTP头，由BosonNLP生成，其中的信息非常有用。例如，</p>
<p>X-Request-Id 是对每个请求生成的唯一ID，用于在引擎内部跟踪请求。</p>
<p>X-Count-Limit-Remaining 是当前可用的调用次数。</p>
<p>X-Count-Limit-Reset 是调用次数重置的时间。当前时间窗口中调用次数用尽时，等待到这里指定的时间才可以恢复使用。</p>
<h2 id="使用-Python-SDK"><a href="#使用-Python-SDK" class="headerlink" title="使用 Python SDK"></a>使用 Python SDK</h2><p>如果您使用 Python 语言，建议通过 SDK 的方式使用 BosonNLP。</p>
<p>BosonNLP Python SDK 是由 BOSON 官方支持的开发者工具包，提供了对 REST 接口的简化封装。</p>
<p>最简便的安装方式是通过 pip 。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install -U bosonnlp</span><br></pre></td></tr></table></figure></p>
<p>安装成功后，编写以下Python脚本，并保存为 sentiment.py 。在代码中，将 YOUR_API_TOKEN 更换为您的API密钥。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function, unicode_literals</span><br><span class="line"><span class="keyword">from</span> bosonnlp <span class="keyword">import</span> BosonNLP</span><br><span class="line"></span><br><span class="line">nlp = BosonNLP(<span class="string">'YOUR_API_TOKEN'</span>)</span><br><span class="line">print(nlp.sentiment(<span class="string">'大众深陷断轴门事件'</span>))</span><br></pre></td></tr></table></figure></p>
<p>运行。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ python sentiment.py</span><br><span class="line">[[<span class="number">0.28867338699939415</span>, <span class="number">0.7113266130006058</span>]]</span><br></pre></td></tr></table></figure></p>
<p>通过SDK调用，对以上内容的情感分析结果为 负面概率较大。</p>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p>暂无</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/29/朱述承_CorpusWordFrequencyApp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/29/朱述承_CorpusWordFrequencyApp/" itemprop="url">CorpusWordFrequencyApp</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-29T20:16:00+05:00">
                2018-04-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：朱述承</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>CorpusWordFrequencyApp是一款免费的语料库统计工具，也是由“语料库在线“这一网站提供。CorpusWordFrequencyApp继承了该网站组织设计的工具简洁易操作的特点，十分适合普通用户的操作和使用。CorpusWordFrequencyApp可以统计文件或者批量统计文件夹中的字频或者词频，分别计算出出现次数和出现频率，并可保存字频或者词频数据，方便进一步的统计分析。</p>
<h1 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h1><p><a href="http://www.aihanyu.org/cncorpus/Resources.aspx" target="_blank" rel="noopener">http://www.aihanyu.org/cncorpus/Resources.aspx</a></p>
<h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p>A．通过文给出的官方下载地址下载工具包的压缩文件，下载过后解压缩就可以直接看到CorpusWordFrequencyApp的应用程序。<br>B．成功打开CorpusWordFrequencyApp应用程序后通过左侧的“按文件选择“或者“按文件夹选择”选择需要进行统计的文件或这文件夹。同时在左侧的“文件列表”中还可以选择对文件进行移除。<br>C．中间可以选择字频统计或者词频统计，以及是否只统计汉字。<br>D．中间的下方给出了一些统计的系统信息。<br>E．右侧给出了字频统计和词频统计的统计结果，并可选择对统计数据进行保存。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/29/朱述承_BFSU PowerConc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/29/朱述承_BFSU PowerConc/" itemprop="url">BFSU PowerConc</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-29T20:16:00+05:00">
                2018-04-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：朱述承</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>BFSU PowerConc是由北京外国语大学语料库团队开发的一款免费的语料库检索工具软件，基于Windows系统。BFSU PowerConc支持英语和汉语两种语言，且功能十分齐全——支持基于正则表达式的关键词索引，包括单词及词块检索、单词曲折词形检索、词性检索、任意词检索、混合检索、正则表达式检索、区分大小写的检索、批量检索、Intergraph检索、搭配共现检索、二次检索等多种检索方式；支持生语料和标注过的熟语料两种形式的语料检索；支持语料库定量研究方面的各类统计分析功能，如主题词的计算、结果抽样等。BFSU PowerConc下载时提供配套的说明文档。</p>
<h1 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h1><p><a href="http://www.bfsu-corpus.org/static/PowerConc.html" target="_blank" rel="noopener">http://www.bfsu-corpus.org/static/PowerConc.html</a></p>
<h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p>A．通过上面介绍的官方网站下载BFSU PowerConc的工具压缩包，然后进行解压缩，选择相应的应用程序便可以运行。<br>B．载入语料库。在Settings栏目下点击Folder(s)，找到目标语料库文件夹，然后点击OK按钮。语料库载入完毕后，语料库目标信息会显示在界面上。<br>C．如需进行“词性”检索，需要在Settings栏目下点击Load List选择加载赋码归类词表。<br>D．在Concordance栏目下可以按照规则进行一系列的检索。<br>E．在N-gram List栏目下可以对相应的字词进行统计。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/29/朱述承_CorpusWordParse/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/29/朱述承_CorpusWordParse/" itemprop="url">CorpusWordParser</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-29T20:16:00+05:00">
                2018-04-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：朱述承</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>CorpusWordParser是一款免费的语料库标注工具，是由“语料库在线“这一网站提供的。CorpusWordParser分为在线版和下载的工具包版。CorpusWordParser的操作界面十分简洁，会使用计算机的普通人员都可以直接上手使用。CorpusWordParser是根据软件自带的标注集或者用户导入的标注集进行标注，可以做到对语句先分词，后标注，其标注效率和准确率都较高。</p>
<h1 id="在线地址"><a href="#在线地址" class="headerlink" title="在线地址"></a>在线地址</h1><p><a href="http://www.aihanyu.org/cncorpus/CpsWParser.aspx" target="_blank" rel="noopener">http://www.aihanyu.org/cncorpus/CpsWParser.aspx</a></p>
<h1 id="工具包下载地址"><a href="#工具包下载地址" class="headerlink" title="工具包下载地址"></a>工具包下载地址</h1><p><a href="http://www.aihanyu.org/cncorpus/Resources.aspx" target="_blank" rel="noopener">http://www.aihanyu.org/cncorpus/Resources.aspx</a></p>
<h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p>A．通过上文给出的官方下载地址下载工具包的压缩文件，下载过后解压缩就可以直接看到CorpusWordParser的应用程序。<br>B．使用CorpusWordParser之前可能需要对电脑进行相关配置，系统会自动弹出需要配置的内容，按照系统指示一步步配置即可。<br>C．成功打开CorpusWordParser应用程序后通过“文件“下的”打开文件“选择需要进行分词或者标注的文件。注意该软件只支持打开文本格式(.txt)的文件，其他类型文件需先另存为文本文件格式后再处理。软件可以自动识别、处理文本文件的不同字符编码（GB或Unicode等）。<br>D．用户还可以在“设置”中根据自身需求勾选其他的附加功能进行配置。<br>E．配置完成后点击“切分标注”即可看到结果。点击“文件”下的“保存文件”可对已经分词标注完毕的文本结果进行保存。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/29/刘晓_CIFAR10 CIFAR100数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/29/刘晓_CIFAR10 CIFAR100数据集/" itemprop="url">CIFAR-10/CIFAR-100数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-29T11:27:39+05:00">
                2018-04-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓</p>
<p>地址：<a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">http://www.cs.toronto.edu/~kriz/cifar.html</a>  </p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>CIFAR-10和CIFAR-100被标记为8000万个微小图像数据集的子集。他们由Alex Krizhevsky，Vinod Nair和Geoffrey Hinton收集。</p>
<h1 id="主要功能与内容"><a href="#主要功能与内容" class="headerlink" title="主要功能与内容"></a>主要功能与内容</h1><h2 id="CIFAR-10数据集"><a href="#CIFAR-10数据集" class="headerlink" title="CIFAR-10数据集"></a>CIFAR-10数据集</h2><p>CIFAR-10数据集由10个类的60000个32x32彩色图像组成，每个类有6000个图像。有50000个训练图像和10000个测试图像。<br>数据集分为五个训练批次和一个测试批次，每个批次有10000个图像。测试批次包含来自每个类别的恰好1000个随机选择的图像。训练批次以随机顺序包含剩余图像，但一些训练批次可能包含来自一个类别的图像比另一个更多。总体来说，五个训练集之和包含来自每个类的正好5000张图像。<br>以下是数据集中的类，以及来自每个类的10个随机图像：<br><img src="https://i.loli.net/2018/04/29/5ae528469d19f.jpg" alt=""></p>
<p>这些类完全相互排斥。汽车和卡车之间没有重叠。“汽车”包括轿车，SUV，这类东西。“卡车”只包括大卡车。都不包括皮卡车。<br>airplane/automobile/bird/cat/deer/dog/frog/horse/ship/truck  </p>
<h2 id="CIFAR-100数据集"><a href="#CIFAR-100数据集" class="headerlink" title="CIFAR-100数据集"></a>CIFAR-100数据集</h2><p>这个数据集就像CIFAR-10，除了它有100个类，每个类包含600个图像。，每类各有500个训练图像和100个测试图像。CIFAR-100中的100个类被分成20个超类。每个图像都带有一个“精细”标签（它所属的类）和一个“粗糙”标签（它所属的超类）<br>以下是CIFAR-100中的类别列表： </p>
<table>
<thead>
<tr>
<th>Superclass</th>
<th>Classes  </th>
</tr>
</thead>
<tbody>
<tr>
<td>aquatic</td>
<td>mammals beaver, dolphin, otter, seal, whale</td>
</tr>
<tr>
<td>fish</td>
<td>aquarium fish, flatfish, ray, shark, trout</td>
</tr>
<tr>
<td>flowers</td>
<td>orchids, poppies, roses, sunflowers, tulips</td>
</tr>
<tr>
<td>food</td>
<td>containers bottles, bowls, cans, cups, plates</td>
</tr>
<tr>
<td>fruit and vegetables</td>
<td>apples, mushrooms, oranges, pears, sweet peppers</td>
</tr>
<tr>
<td>household electrical devices</td>
<td>clock, computer keyboard, lamp, telephone, television</td>
</tr>
<tr>
<td>household</td>
<td>furniture bed, chair, couch, table, wardrobe</td>
</tr>
<tr>
<td>insects</td>
<td>bee, beetle, butterfly, caterpillar, cockroach</td>
</tr>
<tr>
<td>large carnivores</td>
<td>bear, leopard, lion, tiger, wolf</td>
</tr>
<tr>
<td>large man-made outdoor things</td>
<td>bridge, castle, house, road, skyscraper</td>
</tr>
<tr>
<td>large natural outdoor scenes</td>
<td>cloud, forest, mountain, plain, sea</td>
</tr>
<tr>
<td>large omnivores and herbivores</td>
<td>camel, cattle, chimpanzee, elephant, kangaroo</td>
</tr>
<tr>
<td>medium-sized mammals</td>
<td>fox, porcupine, possum, raccoon, skunk</td>
</tr>
<tr>
<td>non-insect invertebrates</td>
<td>crab, lobster, snail, spider, worm</td>
</tr>
<tr>
<td>people</td>
<td>baby, boy, girl, man, woman</td>
</tr>
<tr>
<td>reptiles</td>
<td>crocodile, dinosaur, lizard, snake, turtle</td>
</tr>
<tr>
<td>small mammals</td>
<td>hamster, mouse, rabbit, shrew, squirrel</td>
</tr>
<tr>
<td>trees</td>
<td>maple, oak, palm, pine, willow</td>
</tr>
<tr>
<td>vehicles 1</td>
<td>bicycle, bus, motorcycle, pickup truck, train</td>
</tr>
<tr>
<td>vehicles 2</td>
<td>lawn-mower, rocket, streetcar, tank, tractor</td>
</tr>
</tbody>
</table>
<h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><h2 id="数据及下载"><a href="#数据及下载" class="headerlink" title="数据及下载"></a>数据及下载</h2><p><a href="http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz" target="_blank" rel="noopener">CIFAR-10 Python版本</a><br><a href="http://www.cs.toronto.edu/~kriz/cifar-10-matlab.tar.gz" target="_blank" rel="noopener">CIFAR-10 Matlab版本</a><br><a href="http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz" target="_blank" rel="noopener">CIFAR-10二进制版本（适用于C程序）</a><br><a href="http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz" target="_blank" rel="noopener">CIFAR-100 python版本  </a><br><a href="http://www.cs.toronto.edu/~kriz/cifar-100-matlab.tar.gz" target="_blank" rel="noopener">CIFAR-100 Matlab版本</a><br><a href="http://www.cs.toronto.edu/~kriz/cifar-100-binary.tar.gz" target="_blank" rel="noopener">CIFAR-100二进制版本（适用于C程序）</a></p>
<h2 id="数据集布局"><a href="#数据集布局" class="headerlink" title="数据集布局"></a>数据集布局</h2><p>CIFAR-100的python和Matlab版本的布局与CIFAR-10相同。  </p>
<p><strong>Python / Matlab版本</strong><br>我将描述数据集的Python版本的布局。Matlab版本的布局是相同的。<br>该存档包含文件data_batch_1，data_batch_2，…，data_batch_5以及test_batch。这些文件中的每一个都是用cPickle生成的Python“pickled”对象。这里是一个python2例程，它将打开这样的文件并返回一个字典：  </p>
<pre><code>def unpickle(file):
    import cPickle
    with open(file, &apos;rb&apos;) as fo:
    dict = cPickle.load(fo)
    return dict
</code></pre><p>下面是一个python3实例</p>
<pre><code>def unpickle(file):
    import pickle
    with open(file, &apos;rb&apos;) as fo:
        dict = pickle.load(fo, encoding=&apos;bytes&apos;)
    return dict
</code></pre><p><img src="https://i.loli.net/2018/04/29/5ae52ad2435a4.jpg" alt=""></p>
<p>以这种方式加载的每个批处理文件都包含一个包含以下元素的字典：<br><strong>数据</strong> - 一个10000x3072 uint8的numpy数组。阵列的每一行存储32x32彩色图像即每一行存储32323=3072个数字信息。前1024个条目包含红色通道值，下一个1024个绿色，最后1024个蓝色。图像以行优先顺序存储，以便数组的前32个条目是图像第一行的红色通道值。<br><strong>标签</strong> - 范围为0-9的10000个数字的列表。索引i处的数字表示阵列数据中第i个图像的标签。<br>该数据集包含另一个名为batches.meta的文件。它也包含一个Python字典对象。它有以下条目：<br>label_names - 一个10个元素的列表，它为上述标签数组中的数字标签赋予了有意义的名称。例如，label_names [0] ==“飞机”，label_names [1] ==“汽车”等</p>
<p><strong>二进制版本</strong><br>CIFAR-10二进制版本包含文件data_batch_1.bin，data_batch_2.bin，…，data_batch_5.bin以及test_batch.bin。这些文件中的每一个格式如下：  </p>
<pre><code>&lt;1×标签&gt; &lt;3072×像素&gt;
...
&lt;1×标签&gt; &lt;3072×像素&gt;
</code></pre><p>换句话说，第一个字节是第一个图像的标签，它是一个0-9范围内的数字。接下来的3072个字节是图像像素的值。前1024个字节是红色通道值，下1024个绿色，最后1024个蓝色。值以行优先顺序存储，因此前32个字节是图像第一行的红色通道值。<br>每个文件都包含10000个这样的3073字节的“行”图像，但没有任何分隔行的限制。因此每个文件应该完全是30730000字节长。<br>还有另一个文件，称为batches.meta.txt。这是一个ASCII文件，它将0-9范围内的数字标签映射到有意义的类名称。它仅仅是10个类名的列表，每行一个。第i行的类名称对应于数字标签i。<br><img src="https://i.loli.net/2018/04/29/5ae52bdc05e29.jpg" alt=""></p>
<p>CIFAR-100的二进制版本与CIFAR-10的二进制版本相似，只是每个图像都有两个标签字节（粗略和细小）和3072像素字节，所以二进制文件如下所示：</p>
<pre><code>&lt;1 x粗标签&gt; &lt;1 x精标签&gt; &lt;3072 x像素&gt;
...
&lt;1 x粗标签&gt; &lt;1 x精标签&gt; &lt;3072 x像素&gt;
</code></pre><h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p>[1] <a href="http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf" target="_blank" rel="noopener">Alex Krizhevsky. Learning Multiple Layers of Features from Tiny Images. 2009.</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/29/刘晓_80 Million Tiny Image 图像数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/29/刘晓_80 Million Tiny Image 图像数据/" itemprop="url">80 Million Tiny Image 图像数据</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-29T10:31:58+05:00">
                2018-04-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓</p>
<p>地址：<a href="http://groups.csail.mit.edu/vision/TinyImages/" target="_blank" rel="noopener">http://groups.csail.mit.edu/vision/TinyImages/</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>80 Million Tiny Image 是一个图像数据集，包括 79302017张 分辨率为 32x32 的小图片。全部文件过大（约400GB）。<br>下载时包含了5个文件,网站上也提供了示例代码教你如何加载这些数据!</p>
<ul>
<li>Image binary (227GB) <a href="http://horatio.cs.nyu.edu/mit/tiny/data/tiny_images.bin" target="_blank" rel="noopener">Download</a></li>
<li>Metadata binary (57GB) <a href="http://horatio.cs.nyu.edu/mit/tiny/data/tiny_metadata.bin" target="_blank" rel="noopener">Download</a></li>
<li>Gist binary (114GB) <a href="http://horatio.cs.nyu.edu/mit/tiny/data/tinygist80million.bin" target="_blank" rel="noopener">Download</a></li>
<li>Index data (7MB) <a href="http://horatio.cs.nyu.edu/mit/tiny/data/tiny_index.mat" target="_blank" rel="noopener">Download</a></li>
<li>Matlab Tiny Images toolbox (150kB) <a href="http://horatio.cs.nyu.edu/mit/tiny/data/tiny_code.zip" target="_blank" rel="noopener">Download</a></li>
</ul>
<p><img src="https://i.loli.net/2018/04/29/5ae53df3aa375.jpg" alt=""><br><img src="https://i.loli.net/2018/04/29/5ae53e6d09043.jpg" alt=""></p>
<h1 id="主要内容与使用"><a href="#主要内容与使用" class="headerlink" title="主要内容与使用"></a>主要内容与使用</h1><h2 id="数据集详情"><a href="#数据集详情" class="headerlink" title="数据集详情"></a>数据集详情</h2><table>
<thead>
<tr>
<th>原始数据名称:</th>
<th>80 Million Tiny Image 图像数据   </th>
</tr>
</thead>
<tbody>
<tr>
<td>数据介绍:</td>
<td>80 Million Tiny Image 是一个图像数据集，包括 79302017张 分辨率为 32x32 的小图片。</td>
</tr>
<tr>
<td>属性数:</td>
<td></td>
</tr>
<tr>
<td>记录数:</td>
<td></td>
</tr>
<tr>
<td>无缺失值记录数:</td>
<td></td>
</tr>
<tr>
<td>数据来源:</td>
<td><a href="http://horatio.cs.nyu.edu/mit/tiny/data/index.html" target="_blank" rel="noopener">http://horatio.cs.nyu.edu/mit/tiny/data/index.html</a></td>
</tr>
<tr>
<td>文件类型:</td>
<td>二进制压缩文件</td>
</tr>
<tr>
<td>文件大小:</td>
<td>372.53 Gb  </td>
</tr>
</tbody>
</table>
<p>7900万图像存储在一个巨大的二进制文件中，大小为227Gb。每幅图像附带的元数据也位于一个巨大的文件中，大小为57Gb。为了从这些文件中读取图像/元数据，官网提供了一些Matlab包装函数。 有两种读取图像数据的功能版本： （i）loadTinyImages.m - 普通Matlab函数（无MEX），在32/64位下运行。按图像编号加载图像。默认使用这个。 （ii）read_tiny_big_binary.m - 用于64位MEX函数的Matlab封装。比（i）更快更灵活，但需要64位机器。 有两种类型的注释数据： （i）在annotations.txt中排序的手动注释数据，该数据保存手动检查的图像标签以查看图像内容是否与用于收集它的名词一致。一些其他信息，例如搜索引擎，也被存储。这些数据仅适用于很小一部分图像。 （ii）存储在tiny_metadata.bin中的自动注释数据，包括与图像聚集有关的信息，例如搜索引擎，哪个页面，网址缩略图等。这些数据适用于所有7900万图像。  </p>
<h2 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h2><p>.tgz文件应该包含10个文件：  </p>
<ul>
<li>loadTinyImages.m – 读取微型图像数据，纯粹的Matlab版本</li>
<li>loadGroundTruth.m – 读取保存手动注释的annotations.txt文件</li>
<li>read_tiny_big_binary.m – 读取微小图像数据，64位Matlab / MEX版本</li>
<li>read_tiny_big_metadata.m – 读取微小图像元数据，64位Matlab / MEX版本</li>
<li>read_tiny_gist_binary.m – 读取微小的Gist，64位的Matlab / MEX版本</li>
<li>read_tiny_binary_big_core.c – 用于图像读取的64位MEX源代码</li>
<li>read_tiny_metadata_big_core.c – 用于读取元数据的64位MEX源代码</li>
<li>read_tiny_binary_gist_core.c – 供读者阅读的64位MEX源代码</li>
<li>compute_hash_function.m – 用于执行快速字符串搜索的效用函数，如read_tiny_big_binary.m和read_tiny_big_metadata.m</li>
<li>fast_str2num.m – 用于 - read_tiny_big_metadata.m的实用程序函数</li>
<li>annotations.txt – 保存注释图像列表的文本文件</li>
<li>README.txt – this file</li>
</ul>
<p>同时下载的包括以下文件：</p>
<ul>
<li>tiny_images.bin - 包含79,302,017张图像的227Gb文件</li>
<li>tiny_metadata.bin - 57Gb file holding metadata for all 79,302,017 images保存所有79,302,017张图像的元数据的57Gb文件</li>
<li>tinygist80million.bin - 114Gb文件为所有79,302,017张图像保存384-dim Gist描述符</li>
</ul>
<ol>
<li>tiny_index.mat - 持有索引信息的7Mb文件，包括： 我们在tiny_images.bin中有图像的所有75,846个名词的word-cell数组 num_imgs - 所有75,846个名词的每个名词的#images矢量</li>
</ol>
<h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><p>在使用之，你必须做两件事： </p>
<ul>
<li><p>在Matlab函数中设置绝对路径为二进制文件。总共需要设置7行：<br>（i）loadTinyImages.m，第14行 - 设置tiny_images.bin文件的路径<br>（ii）read_tiny_big_binary.m，第40行 - 设置tiny_images.bin文件的路径<br>（iii）read_tiny_big_binary.m，第42行 - 设置tiny_index.mat文件的路径<br>（iv）read_tiny_big_metadata.m，第63行 - 设置tiny_metadata.bin文件的路径<br>（v）read_tiny_big_metadata.m，第65行 - 设置tiny_index.mat文件的路径<br>（vi）read_tiny_gist_binary.m，第36行 - 设置tiny_index.mat文件的路径<br>（vii）read_tiny_gist_binary.m，第38行 - 设置tiny_metadata.bin文件的路径   </p>
</li>
<li><p>如果使用MEX版本，则必须使用以下命令编译它们：<br>（i）mex read_tiny_binary_big_core.c<br>（ii）mex read_tiny_metadata_big_core.c<br>（iii）mex read_tiny_binary_gist_core.c</p>
</li>
</ul>
<p>以下是一些正在使用的脚本示例。请查看每个文件顶部的注释以获得更详细的解释。 </p>
<pre><code>loadTinyImages.m
---------------

% load in first 10 images from 79,302,017 images
img = loadTinyImages([1:10]);

% load in 10 images at random q = randperm(79302017);
img = loadTinyImages(q(1:10));
%% N.B. function does NOT sort indices, so sorting beforehand would
%% improve speed.




loadGroundTruth.m
-----------------

% read in contents of annotation.txt file
[imageFileName, keyword, correct, engine, ind_engine, image_ndx]=loadGroundTruth;
%%% the labeling convention in correct is:
% -1 = Incorrect, 0 = Skipped, 1 = Correct
% Note that this different to the &apos;label&apos; field produced by % read_tiny_big_metadata below (meaning of -1 and 0 are swapped)
% but the annotation.txt file information should be used in preference to
% that from read_tiny_big_metadata.m


   64-bit MEX versions: 
-------------------- 

read_tiny_big_metadata.m
----------------------

% load in filenames of first 10 images
data = read_tiny_big_metadata([1:10],{&apos;filename&apos;});

% load in search engine used for
% first 10 images from noun &apos;aardvark&apos;;

data = read_tiny_big_metadata(&apos;aardvark&apos;,[1:10],{&apos;engine&apos;});

read_tiny_big_binary.m
----------------------

% load in first 10 images from 79,302,017 images
img = read_tiny_big_binary([1:10]);
% note output dimension is 3072x10, rather than 32x32x3x10 % as for loadTinyImages.m

% load in first 10 images from noun &apos;dog&apos;;
q = randperm(79302017);
img = read_tiny_big_binary(&apos;dog&apos;,q(1:10));
% function sorts indices internally for speed

% load in images for different nouns
img = read_tiny_big_binary({&apos;dog&apos;,&apos;cat&apos;,&apos;mouse&apos;,&apos;pig&apos;},{[1:5],[1:2:10],[8 13],[4:-1:1]});
</code></pre>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/29/刘晓_MINIST/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CNLR">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界语言资源平台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/29/刘晓_MINIST/" itemprop="url">MINIST</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-29T10:31:58+05:00">
                2018-04-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提供者：刘晓</p>
<p>地址：<a href="https://blog.csdn.net/amusi1994/article/details/75331115" target="_blank" rel="noopener">https://blog.csdn.net/amusi1994/article/details/75331115</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>MNIST（维基百科）是一个最大的手写字符数据集，其经常被应用在机器学习领域，用于训练和测试。</p>
<p>MNIST对于机器学习，就好比于Hello world相比于编程学习。</p>
<p>MNIST是一个简单的计算机视觉数据库，其包含了很多张手写数字图像，如:<br><img src="https://i.loli.net/2018/04/29/5ae5374eba69a.jpg" alt="">  </p>
<p>来自NIST的原始黑白（双色）图像尺寸标准化，以适应20×20像素Box，同时保持其长宽比。由于归一化算法使用的抗混叠技术，所得图像包含灰度级。通过计算像素的质心并转换图像以使该点位于28x28场的中心，图像以28×28图像为中心。</p>
<p>通过一些分类方法（特别是基于模板的方法，例如SVM和K-最近邻），当数字以边界框为中心而不是质心时，错误率提高。</p>
<p>MNIST数据库由NIST的特殊数据库3和特殊数据库1构成，其中包含手写数字的二进制图像。 NIST原来指定为SD-3作为训练集，SD-1作为其测试集。然而，SD-3比SD-1更cleaner和更容易识别。其原因是在普查局员工（Census Bureau employees）中收集SD-3，在高中生（high-school students）中收集SD-1。从学习实验中得出明确的结论要求，结果与完整的样本集中的训练集和测试的选择无关。因此，有必要通过混合NIST的数据集来构建一个新的数据库。</p>
<p>MNIST训练集由SD-3的30,000个模式和来自SD-1的30,000个模式组成。我们的测试套件由SD-3的5,000个模式和来自SD-1的5,000个模式组成。 60,000个模式训练集包含大约250位作家的例子。我们确保训练集和测试集的作者集合是不相交的。</p>
<p>SD-1包含由500个不同作者撰写的58,527位数字图像。与SD-3相反，其中来自每个写入器的数据块按顺序出现，SD-1中的数据被加扰。 SD-1的作者身份可用，我们使用这些信息来解读作者。然后我们将SD-1分成两部分：由前250位作家撰写的角色进入我们的新的训练集。剩下的250位作家被放在我们的测试集中。因此，我们有两套，每套有近30,000个例子。新的训练集完成了SD-3的例子，从模式＃0开始，全面训练了6万个训练模式。类似地，新的测试集完成了SD-3示例，从模式＃35,000开始，以全面设置6万个测试模式。只有10,000个测试图像的子集（来自SD-1的5,000个和来自SD-3的5,000个）在本网站上可用。完整的6万个样本训练集可用。</p>
<p>已经通过该训练集和测试集测试了许多方法。这里有几个例子。有关方法的详细信息将在即将发布的论文中给出。其中一些实验使用数据库版本，其中将去偏移的输入图像（通过计算最靠近垂直线的形状的主轴，并移动线条使其垂直）。在其他一些实验中，训练集增加了原始训练样本的人为扭曲版本。失真是移位，缩放，偏移和压缩的随机组合。</p>
<p>在这篇文章中，通过读取MNIST数据集（图像和标签数据），显示图像。  </p>
<h1 id="主要内容与使用教程"><a href="#主要内容与使用教程" class="headerlink" title="主要内容与使用教程"></a>主要内容与使用教程</h1><p>手写数字的MNIST数据库可从<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">官网</a>获得，其中包含60,000个示例的训练集以及10,000个示例的测试集。它是NIST提供的更大集合的子集。这些数字已经过尺寸标准化并以固定尺寸的图像为中心。 对于那些想要在实际数据上尝试学习技术和模式识别方法，同时在预处理和格式化上花费最少的人，这是一个很好的数据库。</p>
<h2 id="下载MNIST数据集"><a href="#下载MNIST数据集" class="headerlink" title="下载MNIST数据集"></a>下载MNIST数据集</h2><p>官网下载四个文件，分别是t10k-images-idx3-ubyte（训练集–图像） 、t10k-labels-idx1-ubyte（训练集–标签）、t10k-images-idx3-ubyte（测试集–图像）、t10k-labels.idx1-ubyte（测试集–标签）：<br><img src="https://i.loli.net/2018/04/29/5ae538ee216ad.jpg" alt=""></p>
<h2 id="MNIST结构分析"><a href="#MNIST结构分析" class="headerlink" title="MNIST结构分析"></a>MNIST结构分析</h2><p>mnist的结构如下，选取train-images</p>
<p>TRAINING SET IMAGE FILE (train-images-idx3-ubyte):<br><img src="https://i.loli.net/2018/04/29/5ae5392d8f2c9.jpg" alt=""></p>
<h2 id="读取图像数据"><a href="#读取图像数据" class="headerlink" title="读取图像数据"></a>读取图像数据</h2><p><strong>先使用二进制方式读取文件</strong>  </p>
<pre><code>filename = &apos;路径名/train-images.idx3-ubyte&apos;  
binfile = open(filename , &apos;rb&apos;)  # python3 &apos;r&apos;  but python2 &apos;rd&apos;  
buf = binfile.read()  
</code></pre><p><strong>使用struct解包</strong></p>
<pre><code>index = 0  
magic, numImages, numRows, numColumns = struct.unpack_from(&apos;&gt;IIII&apos; , buf , index)  
index += struct.calcsize(&apos;&gt;IIII&apos;)  
</code></pre><p>‘&gt;IIII’是指使用大端法读取4个unsigned int32  </p>
<p><strong>读取图像测试</strong></p>
<pre><code>im = struct.unpack_from(&apos;&gt;784B&apos; , buf , index)  
index += struct.calcsize(&apos;&gt;784B&apos;)  

im = np.array(im)  
im = im.reshape(28,28)  

fig = plt.figure()  
plotwindow = fig.add_subplot(111)  
plt.imshow(im , cmap = &apos;gray&apos;)  
plt.show()  
</code></pre><p>(28,28)是MNIST图像的固定格式；<br>‘&gt;7894B’是指用大端法读取784个unsigned byte字节，因为28*28 = 784</p>
<p><strong>读取标签数据</strong><br>每次读入2个unsigned int的元数据，并且相应的调整位置，代码如下：</p>
<pre><code>&lt;span style=&quot;font-size:14px;&quot;&gt;magic, self.train_label_num = struct.unpack_from(&apos;&gt;II&apos;, buf, index)  
    index += struct.calcsize(&apos;&gt;II&apos;)  

    for i in range(self.train_label_num):  
        # for x in xrange(2000):  
        label_item = int(struct.unpack_from(&apos;&gt;B&apos;, buf, index)[0])  
        self.train_label_list[ i , : ] = label_item  
        index += struct.calcsize(&apos;&gt;B&apos;)&lt;/span&gt;  
</code></pre><p>代码：</p>
<pre><code>import numpy as np  
import struct  
import matplotlib.pyplot as plt  

filename = &apos;F:/Pro_Data/Deep&amp;Machine Learning/Deep Learning/MNIST/Data Sets/train-images.idx3-ubyte&apos;  
binfile = open(filename , &apos;rb&apos;)  # python3 &apos;r&apos;  but python2 &apos;rd&apos;  
buf = binfile.read()  

index = 0  
magic, numImages, numRows, numColumns = struct.unpack_from(&apos;&gt;IIII&apos; , buf , index)  
index += struct.calcsize(&apos;&gt;IIII&apos;)  

im = struct.unpack_from(&apos;&gt;784B&apos; , buf , index)  
index += struct.calcsize(&apos;&gt;784B&apos;)  

im = np.array(im)  
im = im.reshape(28,28)  

fig = plt.figure()  
plotwindow = fig.add_subplot(111)  
plt.imshow(im , cmap = &apos;gray&apos;)  
plt.show()  
</code></pre><p>输出结果：</p>
<p><img src="https://i.loli.net/2018/04/29/5ae53aa8b42ee.jpg" alt=""></p>
<h1 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h1><p>官网:  <a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist/</a></p>
<p>维基百科:   <a href="https://en.wikipedia.org/wiki/MNIST_database" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/MNIST_database</a></p>
<p>ConvNetJS MNIST demo:  <a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html" target="_blank" rel="noopener">https://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html</a></p>
<p>Tensorflow:  <a href="https://www.tensorflow.org/get_started/mnist/beginners" target="_blank" rel="noopener">https://www.tensorflow.org/get_started/mnist/beginners</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/12/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><span class="page-number current">13</span><a class="page-number" href="/page/14/">14</a><span class="space">&hellip;</span><a class="page-number" href="/page/20/">20</a><a class="extend next" rel="next" href="/page/14/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CNLR</p>
              <p class="site-description motion-element" itemprop="description">语料库、数据集及工具资源和教程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">192</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CNLR</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
